{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cornell Demo\n",
    "DB Seminar, Spring 2022.\n",
    "Rolando Garcia, UC Berkeley.\n",
    "rogarcia@berkeley.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <- What's in the repo?\n",
    "0. This is a vanilla Jupyter Notebook, running on VSCode\n",
    "1. Show README\n",
    "2. Let's see some code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -> Lets see train_rnn.py\n",
    "\n",
    "We can also characterize the train_rnn.py code as follows:\n",
    "```python\n",
    "import flor\n",
    "import torch\n",
    "\n",
    "trainloader: torch.utils.data.DataLoader\n",
    "testloader:  torch.utils.data.DataLoader\n",
    "optimizer:   torch.optim.Optimizer\n",
    "net:         torch.nn.Module\n",
    "criterion:   torch.nn._Loss\n",
    "\n",
    "for epoch in flor.it(range(...)):\n",
    "    if flor.SkipBlock.step_into('training_loop'):\n",
    "        for data in trainloader:\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print(f\"loss: {loss.item()}\")\n",
    "    flor.SkipBlock.end(net, optimizer)\n",
    "    eval(net, testloader)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brief overview of Record-Replay.\n",
    "* Record:\n",
    "    * `flor.SkipBlock.end` serializes and writes partial checkpoint\n",
    "    * auto-commit changes to repository (special branch)\n",
    "* Replay:\n",
    "    * `flor.it` restores its starting state from checkpoint (parallelism)\n",
    "    * `flor.SkipBlock` may skip, and load side-effects instead from disk (memoization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"I don't want to learn a new API\"\n",
    "# -> flor has hands-free mode\n",
    "Side-by-side comparison. I want to show you what I'm doing.\n",
    "```bash\n",
    "python -c \"import flor; flor.transformer.Transform('...')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"I don't want this to slow training\"\n",
    "# -> Overhead is negligible\n",
    "Fast Record (<6% overhead): Buffering, Write-Behind, Background Serialization/IO, Physiological Logging\n",
    "![Record Plot](doc/img/record.png)\n",
    "Figure from [Garcia et al. VLDB'21]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flor & Git\n",
    "Model developers iterate quickly to try many ideas. We want to store every version of model training tried. Autocommit\n",
    "* Show timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git branch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's explore the Model Training History\n",
    "Exploratory model development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fact table with all the data logged so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = flor.load_kvs()\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -> The table is populated with logged data\n",
    "Let's see the logging statements in train_rnn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = raw_df[['tstamp', 'epoch', 'step', 'name', 'alpha', 'value']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_df = df[['tstamp', 'epoch', 'step', 'name', 'value']][df['alpha'] == 'a']\n",
    "replay_df = df[['tstamp', 'epoch', 'step', 'name', 'value']][df['alpha'] == 'b']\n",
    "record_df['name'].unique(), replay_df['name'].unique() # What did I log in the past? What did the other students log?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = record_df\n",
    "avg_train_loss = df[df['name'] == 'avg_train_loss']\n",
    "avg_train_loss_agg = avg_train_loss.groupby(['tstamp', 'epoch']).agg({'value': 'mean'}).reset_index()\n",
    "avg_train_loss_agg['tstamp'] = avg_train_loss_agg['tstamp'].map(str)\n",
    "avg_train_loss_agg # Rollup\n",
    "\n",
    "fig = px.scatter_3d(avg_train_loss_agg, x='tstamp', y='epoch', z='value', color='tstamp')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = record_df\n",
    "avg_val_loss = df[df['name'] == 'average_valid_loss']\n",
    "avg_valid_loss_agg = avg_val_loss.groupby(['tstamp', 'epoch']).agg({'value': 'mean'}).reset_index()\n",
    "avg_valid_loss_agg['tstamp'] = avg_valid_loss_agg['tstamp'].map(str)\n",
    "avg_valid_loss_agg\n",
    "\n",
    "m_df =  avg_train_loss_agg.merge(avg_valid_loss_agg, on=['tstamp', 'epoch'])\n",
    "m_df['diff'] = m_df['value_x'] - m_df['value_y']                                # train_loss - val_loss\n",
    "m_df\n",
    "\n",
    "fig = px.scatter_3d(m_df, x='tstamp', y='epoch', z='diff', color='tstamp')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's do some hindsight logging\n",
    "* Skip Retraining when possible\n",
    "    * Use memoization: observe physical-logical equivalence\n",
    "* Parallelize Retraining otherwise\n",
    "    * Enable resuming from a checkpoint\n",
    "    * Work Partitioning: Control the epoch sub-range from the command-line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -> Add print statement and replay latest version\n",
    "And show mechanics of code below.\n",
    "What does it do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"train_rnn.py\", line 10, in <module>\n",
      "    from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
      "ModuleNotFoundError: No module named 'sklearn'\n"
     ]
    }
   ],
   "source": [
    "!python train_rnn.py --replay_flor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = raw_df = flor.load_kvs()\n",
    "record_df = df[['tstamp', 'epoch', 'step', 'name', 'value']][df['alpha'] == 'a']\n",
    "replay_df = df[['tstamp', 'epoch', 'step', 'name', 'value']][df['alpha'] == 'b']\n",
    "record_df['name'].unique(), replay_df['name'].unique() # What did I log in the past? What did the other students log?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which versions have I replayed?\n",
    "replay_df[replay_df['name'] == 'learning_rate']['tstamp'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -> Propagate logging statements back in time\n",
    "And show mechanics of code below.\n",
    "What does it do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df[['tstamp', 'vid']][\n",
    "    raw_df['tstamp'] >= np.Datetime64('2022-02-10')\n",
    "    ].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m flor stage train_rnn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git checkout d9973057cb00a470ab29763679fd8d7f84eec1b0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m flor propagate train_rnn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train_rnn.py --replay_flor"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
