{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to run your experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rogarcia/anaconda3/envs/kaggle-nlp-dist/lib/python3.9/site-packages/torchtext/data/utils.py:123: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
      "  warnings.warn(f'Spacy model \"{language}\" could not be loaded, trying \"{OLD_MODEL_SHORTCUTS[language]}\" instead')\n",
      "Epoch [1/20], LR: 0.000, Step [4/1920], Train Loss: 0.7705, Valid Loss: 0.7136\n",
      "Epoch [1/20], LR: 0.000, Step [8/1920], Train Loss: 0.7312, Valid Loss: 0.7136\n",
      "Epoch [1/20], LR: 0.000, Step [12/1920], Train Loss: 0.7345, Valid Loss: 0.7136\n",
      "Epoch [1/20], LR: 0.000, Step [16/1920], Train Loss: 0.7110, Valid Loss: 0.7136\n",
      "Epoch [1/20], LR: 0.000, Step [20/1920], Train Loss: 0.7053, Valid Loss: 0.7136\n",
      "Epoch [1/20], LR: 0.000, Step [24/1920], Train Loss: 0.7130, Valid Loss: 0.7136\n",
      "Epoch [1/20], LR: 0.000, Step [28/1920], Train Loss: 0.7237, Valid Loss: 0.7136\n",
      "Epoch [1/20], LR: 0.000, Step [32/1920], Train Loss: 0.7166, Valid Loss: 0.7136\n",
      "Epoch [1/20], LR: 0.000, Step [36/1920], Train Loss: 0.7378, Valid Loss: 0.7136\n",
      "Epoch [1/20], LR: 0.000, Step [40/1920], Train Loss: 0.7272, Valid Loss: 0.7135\n",
      "Epoch [1/20], LR: 0.000, Step [44/1920], Train Loss: 0.7067, Valid Loss: 0.7135\n",
      "Epoch [1/20], LR: 0.000, Step [48/1920], Train Loss: 0.7224, Valid Loss: 0.7135\n",
      "Epoch [1/20], LR: 0.000, Step [52/1920], Train Loss: 0.7062, Valid Loss: 0.7135\n",
      "Epoch [1/20], LR: 0.000, Step [56/1920], Train Loss: 0.7091, Valid Loss: 0.7135\n",
      "Epoch [1/20], LR: 0.000, Step [60/1920], Train Loss: 0.7058, Valid Loss: 0.7135\n",
      "Epoch [1/20], LR: 0.000, Step [64/1920], Train Loss: 0.7030, Valid Loss: 0.7135\n",
      "Epoch [1/20], LR: 0.000, Step [68/1920], Train Loss: 0.7013, Valid Loss: 0.7135\n",
      "Epoch [1/20], LR: 0.000, Step [72/1920], Train Loss: 0.7241, Valid Loss: 0.7135\n",
      "Epoch [1/20], LR: 0.000, Step [76/1920], Train Loss: 0.7209, Valid Loss: 0.7135\n",
      "Epoch [1/20], LR: 0.000, Step [80/1920], Train Loss: 0.7204, Valid Loss: 0.7135\n",
      "Epoch [1/20], LR: 0.000, Step [84/1920], Train Loss: 0.7048, Valid Loss: 0.7135\n",
      "Epoch [1/20], LR: 0.000, Step [88/1920], Train Loss: 0.7254, Valid Loss: 0.7135\n",
      "Epoch [1/20], LR: 0.000, Step [92/1920], Train Loss: 0.7401, Valid Loss: 0.7134\n",
      "Epoch [1/20], LR: 0.000, Step [96/1920], Train Loss: 0.7617, Valid Loss: 0.7134\n",
      "time elapsed in epoch: 1.9084186553955078\n",
      "Epoch [2/20], LR: 0.000, Step [100/1920], Train Loss: 0.7641, Valid Loss: 0.7134\n",
      "Epoch [2/20], LR: 0.000, Step [104/1920], Train Loss: 0.7225, Valid Loss: 0.7134\n",
      "Epoch [2/20], LR: 0.000, Step [108/1920], Train Loss: 0.7202, Valid Loss: 0.7134\n",
      "Epoch [2/20], LR: 0.000, Step [112/1920], Train Loss: 0.7233, Valid Loss: 0.7134\n",
      "Epoch [2/20], LR: 0.000, Step [116/1920], Train Loss: 0.7012, Valid Loss: 0.7134\n",
      "Epoch [2/20], LR: 0.000, Step [120/1920], Train Loss: 0.7213, Valid Loss: 0.7133\n",
      "Epoch [2/20], LR: 0.000, Step [124/1920], Train Loss: 0.6984, Valid Loss: 0.7133\n",
      "Epoch [2/20], LR: 0.000, Step [128/1920], Train Loss: 0.7013, Valid Loss: 0.7133\n",
      "Epoch [2/20], LR: 0.000, Step [132/1920], Train Loss: 0.7254, Valid Loss: 0.7133\n",
      "Epoch [2/20], LR: 0.000, Step [136/1920], Train Loss: 0.7241, Valid Loss: 0.7133\n",
      "Epoch [2/20], LR: 0.000, Step [140/1920], Train Loss: 0.7313, Valid Loss: 0.7133\n",
      "Epoch [2/20], LR: 0.000, Step [144/1920], Train Loss: 0.7246, Valid Loss: 0.7133\n",
      "Epoch [2/20], LR: 0.000, Step [148/1920], Train Loss: 0.7100, Valid Loss: 0.7133\n",
      "Epoch [2/20], LR: 0.000, Step [152/1920], Train Loss: 0.7141, Valid Loss: 0.7133\n",
      "Epoch [2/20], LR: 0.000, Step [156/1920], Train Loss: 0.7156, Valid Loss: 0.7133\n",
      "Epoch [2/20], LR: 0.000, Step [160/1920], Train Loss: 0.7024, Valid Loss: 0.7133\n",
      "Epoch [2/20], LR: 0.000, Step [164/1920], Train Loss: 0.7088, Valid Loss: 0.7133\n",
      "Epoch [2/20], LR: 0.000, Step [168/1920], Train Loss: 0.7249, Valid Loss: 0.7133\n",
      "Epoch [2/20], LR: 0.000, Step [172/1920], Train Loss: 0.7267, Valid Loss: 0.7132\n",
      "Epoch [2/20], LR: 0.000, Step [176/1920], Train Loss: 0.7023, Valid Loss: 0.7132\n",
      "Epoch [2/20], LR: 0.000, Step [180/1920], Train Loss: 0.7183, Valid Loss: 0.7132\n",
      "Epoch [2/20], LR: 0.000, Step [184/1920], Train Loss: 0.7304, Valid Loss: 0.7132\n",
      "Epoch [2/20], LR: 0.000, Step [188/1920], Train Loss: 0.7352, Valid Loss: 0.7132\n",
      "Epoch [2/20], LR: 0.000, Step [192/1920], Train Loss: 0.7455, Valid Loss: 0.7132\n",
      "time elapsed in epoch: 1.8721485137939453\n",
      "Epoch [3/20], LR: 0.004, Step [196/1920], Train Loss: 0.7651, Valid Loss: 0.7121\n",
      "Epoch [3/20], LR: 0.004, Step [200/1920], Train Loss: 0.7473, Valid Loss: 0.7113\n",
      "Epoch [3/20], LR: 0.004, Step [204/1920], Train Loss: 0.7090, Valid Loss: 0.7109\n",
      "Epoch [3/20], LR: 0.004, Step [208/1920], Train Loss: 0.7131, Valid Loss: 0.7105\n",
      "Epoch [3/20], LR: 0.004, Step [212/1920], Train Loss: 0.7096, Valid Loss: 0.7104\n",
      "Epoch [3/20], LR: 0.004, Step [216/1920], Train Loss: 0.7434, Valid Loss: 0.7099\n",
      "Epoch [3/20], LR: 0.004, Step [220/1920], Train Loss: 0.7183, Valid Loss: 0.7097\n",
      "Epoch [3/20], LR: 0.004, Step [224/1920], Train Loss: 0.7062, Valid Loss: 0.7096\n",
      "Epoch [3/20], LR: 0.004, Step [228/1920], Train Loss: 0.7114, Valid Loss: 0.7093\n",
      "Epoch [3/20], LR: 0.004, Step [232/1920], Train Loss: 0.7159, Valid Loss: 0.7088\n",
      "Epoch [3/20], LR: 0.004, Step [236/1920], Train Loss: 0.7047, Valid Loss: 0.7084\n",
      "Epoch [3/20], LR: 0.004, Step [240/1920], Train Loss: 0.7072, Valid Loss: 0.7082\n",
      "Epoch [3/20], LR: 0.004, Step [244/1920], Train Loss: 0.7031, Valid Loss: 0.7081\n",
      "Epoch [3/20], LR: 0.004, Step [248/1920], Train Loss: 0.7224, Valid Loss: 0.7078\n",
      "Epoch [3/20], LR: 0.004, Step [252/1920], Train Loss: 0.7089, Valid Loss: 0.7076\n",
      "Epoch [3/20], LR: 0.004, Step [256/1920], Train Loss: 0.7006, Valid Loss: 0.7074\n",
      "Epoch [3/20], LR: 0.004, Step [260/1920], Train Loss: 0.7150, Valid Loss: 0.7073\n",
      "Epoch [3/20], LR: 0.004, Step [264/1920], Train Loss: 0.7193, Valid Loss: 0.7070\n",
      "Epoch [3/20], LR: 0.004, Step [268/1920], Train Loss: 0.7129, Valid Loss: 0.7068\n",
      "Epoch [3/20], LR: 0.004, Step [272/1920], Train Loss: 0.7077, Valid Loss: 0.7066\n",
      "Epoch [3/20], LR: 0.004, Step [276/1920], Train Loss: 0.6976, Valid Loss: 0.7064\n",
      "Epoch [3/20], LR: 0.004, Step [280/1920], Train Loss: 0.7018, Valid Loss: 0.7060\n",
      "Epoch [3/20], LR: 0.004, Step [284/1920], Train Loss: 0.7248, Valid Loss: 0.7054\n",
      "Epoch [3/20], LR: 0.004, Step [288/1920], Train Loss: 0.7321, Valid Loss: 0.7046\n",
      "time elapsed in epoch: 1.9080567359924316\n",
      "Epoch [4/20], LR: 0.008, Step [292/1920], Train Loss: 0.7351, Valid Loss: 0.7029\n",
      "Epoch [4/20], LR: 0.008, Step [296/1920], Train Loss: 0.7140, Valid Loss: 0.7019\n",
      "Epoch [4/20], LR: 0.008, Step [300/1920], Train Loss: 0.7104, Valid Loss: 0.7013\n",
      "Epoch [4/20], LR: 0.008, Step [304/1920], Train Loss: 0.7073, Valid Loss: 0.7009\n",
      "Epoch [4/20], LR: 0.008, Step [308/1920], Train Loss: 0.6993, Valid Loss: 0.7008\n",
      "Epoch [4/20], LR: 0.008, Step [312/1920], Train Loss: 0.7111, Valid Loss: 0.7003\n",
      "Epoch [4/20], LR: 0.008, Step [316/1920], Train Loss: 0.7049, Valid Loss: 0.7001\n",
      "Epoch [4/20], LR: 0.008, Step [320/1920], Train Loss: 0.7080, Valid Loss: 0.7000\n",
      "Epoch [4/20], LR: 0.008, Step [324/1920], Train Loss: 0.7072, Valid Loss: 0.6996\n",
      "Epoch [4/20], LR: 0.008, Step [328/1920], Train Loss: 0.7049, Valid Loss: 0.6990\n",
      "Epoch [4/20], LR: 0.008, Step [332/1920], Train Loss: 0.6988, Valid Loss: 0.6986\n",
      "Epoch [4/20], LR: 0.008, Step [336/1920], Train Loss: 0.7021, Valid Loss: 0.6985\n",
      "Epoch [4/20], LR: 0.008, Step [340/1920], Train Loss: 0.7069, Valid Loss: 0.6984\n",
      "Epoch [4/20], LR: 0.008, Step [344/1920], Train Loss: 0.6869, Valid Loss: 0.6981\n",
      "Epoch [4/20], LR: 0.008, Step [348/1920], Train Loss: 0.6928, Valid Loss: 0.6980\n",
      "Epoch [4/20], LR: 0.008, Step [352/1920], Train Loss: 0.6999, Valid Loss: 0.6979\n",
      "Epoch [4/20], LR: 0.008, Step [356/1920], Train Loss: 0.6946, Valid Loss: 0.6979\n",
      "Epoch [4/20], LR: 0.008, Step [360/1920], Train Loss: 0.7106, Valid Loss: 0.6973\n",
      "Epoch [4/20], LR: 0.008, Step [364/1920], Train Loss: 0.7002, Valid Loss: 0.6971\n",
      "Epoch [4/20], LR: 0.008, Step [368/1920], Train Loss: 0.6977, Valid Loss: 0.6970\n",
      "Epoch [4/20], LR: 0.008, Step [372/1920], Train Loss: 0.6958, Valid Loss: 0.6968\n",
      "Epoch [4/20], LR: 0.008, Step [376/1920], Train Loss: 0.7085, Valid Loss: 0.6963\n",
      "Epoch [4/20], LR: 0.008, Step [380/1920], Train Loss: 0.7052, Valid Loss: 0.6956\n",
      "Epoch [4/20], LR: 0.008, Step [384/1920], Train Loss: 0.6967, Valid Loss: 0.6947\n",
      "time elapsed in epoch: 2.1381654739379883\n",
      "Epoch [5/20], LR: 0.013, Step [388/1920], Train Loss: 0.7073, Valid Loss: 0.6931\n",
      "Epoch [5/20], LR: 0.013, Step [392/1920], Train Loss: 0.6792, Valid Loss: 0.6923\n",
      "Epoch [5/20], LR: 0.013, Step [396/1920], Train Loss: 0.6950, Valid Loss: 0.6919\n",
      "Epoch [5/20], LR: 0.013, Step [400/1920], Train Loss: 0.6990, Valid Loss: 0.6917\n",
      "Epoch [5/20], LR: 0.013, Step [404/1920], Train Loss: 0.7086, Valid Loss: 0.6917\n",
      "Epoch [5/20], LR: 0.013, Step [408/1920], Train Loss: 0.7008, Valid Loss: 0.6914\n",
      "Epoch [5/20], LR: 0.013, Step [412/1920], Train Loss: 0.7043, Valid Loss: 0.6914\n",
      "Epoch [5/20], LR: 0.013, Step [416/1920], Train Loss: 0.6925, Valid Loss: 0.6914\n",
      "Epoch [5/20], LR: 0.013, Step [420/1920], Train Loss: 0.6911, Valid Loss: 0.6912\n",
      "Epoch [5/20], LR: 0.013, Step [424/1920], Train Loss: 0.6841, Valid Loss: 0.6908\n",
      "Epoch [5/20], LR: 0.013, Step [428/1920], Train Loss: 0.6996, Valid Loss: 0.6905\n",
      "Epoch [5/20], LR: 0.013, Step [432/1920], Train Loss: 0.6946, Valid Loss: 0.6905\n",
      "Epoch [5/20], LR: 0.013, Step [436/1920], Train Loss: 0.6991, Valid Loss: 0.6906\n",
      "Epoch [5/20], LR: 0.013, Step [440/1920], Train Loss: 0.6955, Valid Loss: 0.6905\n",
      "Epoch [5/20], LR: 0.013, Step [444/1920], Train Loss: 0.6850, Valid Loss: 0.6904\n",
      "Epoch [5/20], LR: 0.013, Step [448/1920], Train Loss: 0.7028, Valid Loss: 0.6904\n",
      "Epoch [5/20], LR: 0.013, Step [452/1920], Train Loss: 0.7014, Valid Loss: 0.6906\n",
      "Epoch [5/20], LR: 0.013, Step [456/1920], Train Loss: 0.6864, Valid Loss: 0.6903\n",
      "Epoch [5/20], LR: 0.013, Step [460/1920], Train Loss: 0.7008, Valid Loss: 0.6902\n",
      "Epoch [5/20], LR: 0.013, Step [464/1920], Train Loss: 0.6978, Valid Loss: 0.6901\n",
      "Epoch [5/20], LR: 0.013, Step [468/1920], Train Loss: 0.6987, Valid Loss: 0.6901\n",
      "Epoch [5/20], LR: 0.013, Step [472/1920], Train Loss: 0.7004, Valid Loss: 0.6898\n",
      "Epoch [5/20], LR: 0.013, Step [476/1920], Train Loss: 0.6848, Valid Loss: 0.6892\n",
      "Epoch [5/20], LR: 0.013, Step [480/1920], Train Loss: 0.6858, Valid Loss: 0.6884\n",
      "time elapsed in epoch: 2.125608444213867\n",
      "Epoch [6/20], LR: 0.017, Step [484/1920], Train Loss: 0.6668, Valid Loss: 0.6872\n",
      "Epoch [6/20], LR: 0.017, Step [488/1920], Train Loss: 0.6703, Valid Loss: 0.6867\n",
      "Epoch [6/20], LR: 0.017, Step [492/1920], Train Loss: 0.6858, Valid Loss: 0.6864\n",
      "Epoch [6/20], LR: 0.017, Step [496/1920], Train Loss: 0.6962, Valid Loss: 0.6864\n",
      "Epoch [6/20], LR: 0.017, Step [500/1920], Train Loss: 0.7065, Valid Loss: 0.6865\n",
      "Epoch [6/20], LR: 0.017, Step [504/1920], Train Loss: 0.6849, Valid Loss: 0.6863\n",
      "Epoch [6/20], LR: 0.017, Step [508/1920], Train Loss: 0.7051, Valid Loss: 0.6865\n",
      "Epoch [6/20], LR: 0.017, Step [512/1920], Train Loss: 0.6878, Valid Loss: 0.6866\n",
      "Epoch [6/20], LR: 0.017, Step [516/1920], Train Loss: 0.6927, Valid Loss: 0.6865\n",
      "Epoch [6/20], LR: 0.017, Step [520/1920], Train Loss: 0.6770, Valid Loss: 0.6863\n",
      "Epoch [6/20], LR: 0.017, Step [524/1920], Train Loss: 0.6919, Valid Loss: 0.6861\n",
      "Epoch [6/20], LR: 0.017, Step [528/1920], Train Loss: 0.7047, Valid Loss: 0.6862\n",
      "Epoch [6/20], LR: 0.017, Step [532/1920], Train Loss: 0.7057, Valid Loss: 0.6863\n",
      "Epoch [6/20], LR: 0.017, Step [536/1920], Train Loss: 0.6951, Valid Loss: 0.6863\n",
      "Epoch [6/20], LR: 0.017, Step [540/1920], Train Loss: 0.6952, Valid Loss: 0.6863\n",
      "Epoch [6/20], LR: 0.017, Step [544/1920], Train Loss: 0.6952, Valid Loss: 0.6864\n",
      "Epoch [6/20], LR: 0.017, Step [548/1920], Train Loss: 0.6988, Valid Loss: 0.6867\n",
      "Epoch [6/20], LR: 0.017, Step [552/1920], Train Loss: 0.6861, Valid Loss: 0.6865\n",
      "Epoch [6/20], LR: 0.017, Step [556/1920], Train Loss: 0.6920, Valid Loss: 0.6864\n",
      "Epoch [6/20], LR: 0.017, Step [560/1920], Train Loss: 0.6986, Valid Loss: 0.6865\n",
      "Epoch [6/20], LR: 0.017, Step [564/1920], Train Loss: 0.6972, Valid Loss: 0.6866\n",
      "Epoch [6/20], LR: 0.017, Step [568/1920], Train Loss: 0.6866, Valid Loss: 0.6863\n",
      "Epoch [6/20], LR: 0.017, Step [572/1920], Train Loss: 0.6778, Valid Loss: 0.6859\n",
      "Epoch [6/20], LR: 0.017, Step [576/1920], Train Loss: 0.6610, Valid Loss: 0.6853\n",
      "time elapsed in epoch: 2.0420126914978027\n",
      "Epoch [7/20], LR: 0.021, Step [580/1920], Train Loss: 0.6423, Valid Loss: 0.6845\n",
      "Epoch [7/20], LR: 0.021, Step [584/1920], Train Loss: 0.6618, Valid Loss: 0.6842\n",
      "Epoch [7/20], LR: 0.021, Step [588/1920], Train Loss: 0.6827, Valid Loss: 0.6841\n",
      "Epoch [7/20], LR: 0.021, Step [592/1920], Train Loss: 0.6931, Valid Loss: 0.6841\n",
      "Epoch [7/20], LR: 0.021, Step [596/1920], Train Loss: 0.7060, Valid Loss: 0.6842\n",
      "Epoch [7/20], LR: 0.021, Step [600/1920], Train Loss: 0.6830, Valid Loss: 0.6841\n",
      "Epoch [7/20], LR: 0.021, Step [604/1920], Train Loss: 0.7039, Valid Loss: 0.6842\n",
      "Epoch [7/20], LR: 0.021, Step [608/1920], Train Loss: 0.6963, Valid Loss: 0.6844\n",
      "Epoch [7/20], LR: 0.021, Step [612/1920], Train Loss: 0.6914, Valid Loss: 0.6843\n",
      "Epoch [7/20], LR: 0.021, Step [616/1920], Train Loss: 0.6770, Valid Loss: 0.6842\n",
      "Epoch [7/20], LR: 0.021, Step [620/1920], Train Loss: 0.6838, Valid Loss: 0.6841\n",
      "Epoch [7/20], LR: 0.021, Step [624/1920], Train Loss: 0.7044, Valid Loss: 0.6842\n",
      "Epoch [7/20], LR: 0.021, Step [628/1920], Train Loss: 0.7100, Valid Loss: 0.6843\n",
      "Epoch [7/20], LR: 0.021, Step [632/1920], Train Loss: 0.6887, Valid Loss: 0.6844\n",
      "Epoch [7/20], LR: 0.021, Step [636/1920], Train Loss: 0.6963, Valid Loss: 0.6844\n",
      "Epoch [7/20], LR: 0.021, Step [640/1920], Train Loss: 0.7046, Valid Loss: 0.6846\n",
      "Epoch [7/20], LR: 0.021, Step [644/1920], Train Loss: 0.7119, Valid Loss: 0.6848\n",
      "Epoch [7/20], LR: 0.021, Step [648/1920], Train Loss: 0.6815, Valid Loss: 0.6847\n",
      "Epoch [7/20], LR: 0.021, Step [652/1920], Train Loss: 0.7021, Valid Loss: 0.6847\n",
      "Epoch [7/20], LR: 0.021, Step [656/1920], Train Loss: 0.6975, Valid Loss: 0.6848\n",
      "Epoch [7/20], LR: 0.021, Step [660/1920], Train Loss: 0.6947, Valid Loss: 0.6848\n",
      "Epoch [7/20], LR: 0.021, Step [664/1920], Train Loss: 0.6771, Valid Loss: 0.6846\n",
      "Epoch [7/20], LR: 0.021, Step [668/1920], Train Loss: 0.6575, Valid Loss: 0.6842\n",
      "Epoch [7/20], LR: 0.021, Step [672/1920], Train Loss: 0.6498, Valid Loss: 0.6838\n",
      "time elapsed in epoch: 2.066152334213257\n",
      "Epoch [8/20], LR: 0.025, Step [676/1920], Train Loss: 0.6269, Valid Loss: 0.6833\n",
      "Epoch [8/20], LR: 0.025, Step [680/1920], Train Loss: 0.6564, Valid Loss: 0.6832\n",
      "Epoch [8/20], LR: 0.025, Step [684/1920], Train Loss: 0.6877, Valid Loss: 0.6832\n",
      "Epoch [8/20], LR: 0.025, Step [688/1920], Train Loss: 0.6891, Valid Loss: 0.6832\n",
      "Epoch [8/20], LR: 0.025, Step [692/1920], Train Loss: 0.7071, Valid Loss: 0.6832\n",
      "Epoch [8/20], LR: 0.025, Step [696/1920], Train Loss: 0.6869, Valid Loss: 0.6832\n",
      "Epoch [8/20], LR: 0.025, Step [700/1920], Train Loss: 0.7010, Valid Loss: 0.6832\n",
      "Epoch [8/20], LR: 0.025, Step [704/1920], Train Loss: 0.7044, Valid Loss: 0.6833\n",
      "Epoch [8/20], LR: 0.025, Step [708/1920], Train Loss: 0.6836, Valid Loss: 0.6833\n",
      "Epoch [8/20], LR: 0.025, Step [712/1920], Train Loss: 0.6733, Valid Loss: 0.6832\n",
      "Epoch [8/20], LR: 0.025, Step [716/1920], Train Loss: 0.6801, Valid Loss: 0.6831\n",
      "Epoch [8/20], LR: 0.025, Step [720/1920], Train Loss: 0.7045, Valid Loss: 0.6832\n",
      "Epoch [8/20], LR: 0.025, Step [724/1920], Train Loss: 0.6983, Valid Loss: 0.6833\n",
      "Epoch [8/20], LR: 0.025, Step [728/1920], Train Loss: 0.6919, Valid Loss: 0.6834\n",
      "Epoch [8/20], LR: 0.025, Step [732/1920], Train Loss: 0.7067, Valid Loss: 0.6834\n",
      "Epoch [8/20], LR: 0.025, Step [736/1920], Train Loss: 0.6952, Valid Loss: 0.6836\n",
      "Epoch [8/20], LR: 0.025, Step [740/1920], Train Loss: 0.7050, Valid Loss: 0.6838\n",
      "Epoch [8/20], LR: 0.025, Step [744/1920], Train Loss: 0.6796, Valid Loss: 0.6837\n",
      "Epoch [8/20], LR: 0.025, Step [748/1920], Train Loss: 0.6902, Valid Loss: 0.6837\n",
      "Epoch [8/20], LR: 0.025, Step [752/1920], Train Loss: 0.6990, Valid Loss: 0.6838\n",
      "Epoch [8/20], LR: 0.025, Step [756/1920], Train Loss: 0.6864, Valid Loss: 0.6838\n",
      "Epoch [8/20], LR: 0.025, Step [760/1920], Train Loss: 0.6775, Valid Loss: 0.6836\n",
      "Epoch [8/20], LR: 0.025, Step [764/1920], Train Loss: 0.6692, Valid Loss: 0.6833\n",
      "Epoch [8/20], LR: 0.025, Step [768/1920], Train Loss: 0.6455, Valid Loss: 0.6829\n",
      "time elapsed in epoch: 2.111098289489746\n",
      "Epoch [9/20], LR: 0.029, Step [772/1920], Train Loss: 0.6212, Valid Loss: 0.6828\n",
      "Epoch [9/20], LR: 0.029, Step [776/1920], Train Loss: 0.6564, Valid Loss: 0.6828\n",
      "Epoch [9/20], LR: 0.029, Step [780/1920], Train Loss: 0.6802, Valid Loss: 0.6828\n",
      "Epoch [9/20], LR: 0.029, Step [784/1920], Train Loss: 0.6888, Valid Loss: 0.6828\n",
      "Epoch [9/20], LR: 0.029, Step [788/1920], Train Loss: 0.7083, Valid Loss: 0.6827\n",
      "Epoch [9/20], LR: 0.029, Step [792/1920], Train Loss: 0.6836, Valid Loss: 0.6827\n",
      "Epoch [9/20], LR: 0.029, Step [796/1920], Train Loss: 0.7048, Valid Loss: 0.6826\n",
      "Epoch [9/20], LR: 0.029, Step [800/1920], Train Loss: 0.7034, Valid Loss: 0.6826\n",
      "Epoch [9/20], LR: 0.029, Step [804/1920], Train Loss: 0.6909, Valid Loss: 0.6826\n",
      "Epoch [9/20], LR: 0.029, Step [808/1920], Train Loss: 0.6718, Valid Loss: 0.6825\n",
      "Epoch [9/20], LR: 0.029, Step [812/1920], Train Loss: 0.6792, Valid Loss: 0.6825\n",
      "Epoch [9/20], LR: 0.029, Step [816/1920], Train Loss: 0.7010, Valid Loss: 0.6825\n",
      "Epoch [9/20], LR: 0.029, Step [820/1920], Train Loss: 0.7007, Valid Loss: 0.6826\n",
      "Epoch [9/20], LR: 0.029, Step [824/1920], Train Loss: 0.6890, Valid Loss: 0.6826\n",
      "Epoch [9/20], LR: 0.029, Step [828/1920], Train Loss: 0.6979, Valid Loss: 0.6826\n",
      "Epoch [9/20], LR: 0.029, Step [832/1920], Train Loss: 0.7018, Valid Loss: 0.6827\n",
      "Epoch [9/20], LR: 0.029, Step [836/1920], Train Loss: 0.7062, Valid Loss: 0.6830\n",
      "Epoch [9/20], LR: 0.029, Step [840/1920], Train Loss: 0.6805, Valid Loss: 0.6829\n",
      "Epoch [9/20], LR: 0.029, Step [844/1920], Train Loss: 0.6899, Valid Loss: 0.6829\n",
      "Epoch [9/20], LR: 0.029, Step [848/1920], Train Loss: 0.6946, Valid Loss: 0.6829\n",
      "Epoch [9/20], LR: 0.029, Step [852/1920], Train Loss: 0.6905, Valid Loss: 0.6830\n",
      "Epoch [9/20], LR: 0.029, Step [856/1920], Train Loss: 0.6789, Valid Loss: 0.6829\n",
      "Epoch [9/20], LR: 0.029, Step [860/1920], Train Loss: 0.6646, Valid Loss: 0.6826\n",
      "Epoch [9/20], LR: 0.029, Step [864/1920], Train Loss: 0.6341, Valid Loss: 0.6823\n",
      "time elapsed in epoch: 2.1550002098083496\n",
      "Epoch [10/20], LR: 0.033, Step [868/1920], Train Loss: 0.6179, Valid Loss: 0.6824\n",
      "Epoch [10/20], LR: 0.033, Step [872/1920], Train Loss: 0.6511, Valid Loss: 0.6825\n",
      "Epoch [10/20], LR: 0.033, Step [876/1920], Train Loss: 0.6753, Valid Loss: 0.6824\n",
      "Epoch [10/20], LR: 0.033, Step [880/1920], Train Loss: 0.6930, Valid Loss: 0.6823\n",
      "Epoch [10/20], LR: 0.033, Step [884/1920], Train Loss: 0.7046, Valid Loss: 0.6822\n",
      "Epoch [10/20], LR: 0.033, Step [888/1920], Train Loss: 0.6860, Valid Loss: 0.6822\n",
      "Epoch [10/20], LR: 0.033, Step [892/1920], Train Loss: 0.7046, Valid Loss: 0.6821\n",
      "Epoch [10/20], LR: 0.033, Step [896/1920], Train Loss: 0.6987, Valid Loss: 0.6821\n",
      "Epoch [10/20], LR: 0.033, Step [900/1920], Train Loss: 0.6872, Valid Loss: 0.6821\n",
      "Epoch [10/20], LR: 0.033, Step [904/1920], Train Loss: 0.6702, Valid Loss: 0.6821\n",
      "Epoch [10/20], LR: 0.033, Step [908/1920], Train Loss: 0.6820, Valid Loss: 0.6820\n",
      "Epoch [10/20], LR: 0.033, Step [912/1920], Train Loss: 0.7006, Valid Loss: 0.6821\n",
      "Epoch [10/20], LR: 0.033, Step [916/1920], Train Loss: 0.7036, Valid Loss: 0.6822\n",
      "Epoch [10/20], LR: 0.033, Step [920/1920], Train Loss: 0.6889, Valid Loss: 0.6822\n",
      "Epoch [10/20], LR: 0.033, Step [924/1920], Train Loss: 0.6980, Valid Loss: 0.6823\n",
      "Epoch [10/20], LR: 0.033, Step [928/1920], Train Loss: 0.6961, Valid Loss: 0.6824\n",
      "Epoch [10/20], LR: 0.033, Step [932/1920], Train Loss: 0.7028, Valid Loss: 0.6826\n",
      "Epoch [10/20], LR: 0.033, Step [936/1920], Train Loss: 0.6834, Valid Loss: 0.6826\n",
      "Epoch [10/20], LR: 0.033, Step [940/1920], Train Loss: 0.6942, Valid Loss: 0.6826\n",
      "Epoch [10/20], LR: 0.033, Step [944/1920], Train Loss: 0.7005, Valid Loss: 0.6827\n",
      "Epoch [10/20], LR: 0.033, Step [948/1920], Train Loss: 0.6962, Valid Loss: 0.6827\n",
      "Epoch [10/20], LR: 0.033, Step [952/1920], Train Loss: 0.6752, Valid Loss: 0.6825\n",
      "Epoch [10/20], LR: 0.033, Step [956/1920], Train Loss: 0.6604, Valid Loss: 0.6822\n",
      "Epoch [10/20], LR: 0.033, Step [960/1920], Train Loss: 0.6301, Valid Loss: 0.6818\n",
      "time elapsed in epoch: 1.8438069820404053\n",
      "Epoch [11/20], LR: 0.038, Step [964/1920], Train Loss: 0.6152, Valid Loss: 0.6819\n",
      "Epoch [11/20], LR: 0.038, Step [968/1920], Train Loss: 0.6551, Valid Loss: 0.6820\n",
      "Epoch [11/20], LR: 0.038, Step [972/1920], Train Loss: 0.6778, Valid Loss: 0.6820\n",
      "Epoch [11/20], LR: 0.038, Step [976/1920], Train Loss: 0.6871, Valid Loss: 0.6819\n",
      "Epoch [11/20], LR: 0.038, Step [980/1920], Train Loss: 0.7098, Valid Loss: 0.6817\n",
      "Epoch [11/20], LR: 0.038, Step [984/1920], Train Loss: 0.6794, Valid Loss: 0.6817\n",
      "Epoch [11/20], LR: 0.038, Step [988/1920], Train Loss: 0.7001, Valid Loss: 0.6815\n",
      "Epoch [11/20], LR: 0.038, Step [992/1920], Train Loss: 0.7029, Valid Loss: 0.6816\n",
      "Epoch [11/20], LR: 0.038, Step [996/1920], Train Loss: 0.6892, Valid Loss: 0.6816\n",
      "Epoch [11/20], LR: 0.038, Step [1000/1920], Train Loss: 0.6702, Valid Loss: 0.6815\n",
      "Epoch [11/20], LR: 0.038, Step [1004/1920], Train Loss: 0.6808, Valid Loss: 0.6815\n",
      "Epoch [11/20], LR: 0.038, Step [1008/1920], Train Loss: 0.7012, Valid Loss: 0.6816\n",
      "Epoch [11/20], LR: 0.038, Step [1012/1920], Train Loss: 0.6965, Valid Loss: 0.6816\n",
      "Epoch [11/20], LR: 0.038, Step [1016/1920], Train Loss: 0.6884, Valid Loss: 0.6816\n",
      "Epoch [11/20], LR: 0.038, Step [1020/1920], Train Loss: 0.6978, Valid Loss: 0.6817\n",
      "Epoch [11/20], LR: 0.038, Step [1024/1920], Train Loss: 0.7030, Valid Loss: 0.6818\n",
      "Epoch [11/20], LR: 0.038, Step [1028/1920], Train Loss: 0.7044, Valid Loss: 0.6821\n",
      "Epoch [11/20], LR: 0.038, Step [1032/1920], Train Loss: 0.6877, Valid Loss: 0.6820\n",
      "Epoch [11/20], LR: 0.038, Step [1036/1920], Train Loss: 0.6898, Valid Loss: 0.6820\n",
      "Epoch [11/20], LR: 0.038, Step [1040/1920], Train Loss: 0.6941, Valid Loss: 0.6821\n",
      "Epoch [11/20], LR: 0.038, Step [1044/1920], Train Loss: 0.6931, Valid Loss: 0.6822\n",
      "Epoch [11/20], LR: 0.038, Step [1048/1920], Train Loss: 0.6781, Valid Loss: 0.6820\n",
      "Epoch [11/20], LR: 0.038, Step [1052/1920], Train Loss: 0.6640, Valid Loss: 0.6817\n",
      "Epoch [11/20], LR: 0.038, Step [1056/1920], Train Loss: 0.6385, Valid Loss: 0.6813\n",
      "time elapsed in epoch: 2.022855758666992\n",
      "Epoch [12/20], LR: 0.042, Step [1060/1920], Train Loss: 0.6138, Valid Loss: 0.6815\n",
      "Epoch [12/20], LR: 0.042, Step [1064/1920], Train Loss: 0.6448, Valid Loss: 0.6817\n",
      "Epoch [12/20], LR: 0.042, Step [1068/1920], Train Loss: 0.6802, Valid Loss: 0.6817\n",
      "Epoch [12/20], LR: 0.042, Step [1072/1920], Train Loss: 0.6873, Valid Loss: 0.6816\n",
      "Epoch [12/20], LR: 0.042, Step [1076/1920], Train Loss: 0.7108, Valid Loss: 0.6813\n",
      "Epoch [12/20], LR: 0.042, Step [1080/1920], Train Loss: 0.6762, Valid Loss: 0.6812\n",
      "Epoch [12/20], LR: 0.042, Step [1084/1920], Train Loss: 0.6992, Valid Loss: 0.6811\n",
      "Epoch [12/20], LR: 0.042, Step [1088/1920], Train Loss: 0.7035, Valid Loss: 0.6810\n",
      "Epoch [12/20], LR: 0.042, Step [1092/1920], Train Loss: 0.6845, Valid Loss: 0.6810\n",
      "Epoch [12/20], LR: 0.042, Step [1096/1920], Train Loss: 0.6719, Valid Loss: 0.6810\n",
      "Epoch [12/20], LR: 0.042, Step [1100/1920], Train Loss: 0.6748, Valid Loss: 0.6809\n",
      "Epoch [12/20], LR: 0.042, Step [1104/1920], Train Loss: 0.6975, Valid Loss: 0.6809\n",
      "Epoch [12/20], LR: 0.042, Step [1108/1920], Train Loss: 0.7031, Valid Loss: 0.6810\n",
      "Epoch [12/20], LR: 0.042, Step [1112/1920], Train Loss: 0.6878, Valid Loss: 0.6811\n",
      "Epoch [12/20], LR: 0.042, Step [1116/1920], Train Loss: 0.6918, Valid Loss: 0.6811\n",
      "Epoch [12/20], LR: 0.042, Step [1120/1920], Train Loss: 0.6972, Valid Loss: 0.6813\n",
      "Epoch [12/20], LR: 0.042, Step [1124/1920], Train Loss: 0.7060, Valid Loss: 0.6816\n",
      "Epoch [12/20], LR: 0.042, Step [1128/1920], Train Loss: 0.6822, Valid Loss: 0.6815\n",
      "Epoch [12/20], LR: 0.042, Step [1132/1920], Train Loss: 0.6929, Valid Loss: 0.6815\n",
      "Epoch [12/20], LR: 0.042, Step [1136/1920], Train Loss: 0.6933, Valid Loss: 0.6817\n",
      "Epoch [12/20], LR: 0.042, Step [1140/1920], Train Loss: 0.6975, Valid Loss: 0.6819\n",
      "Epoch [12/20], LR: 0.042, Step [1144/1920], Train Loss: 0.6805, Valid Loss: 0.6816\n",
      "Epoch [12/20], LR: 0.042, Step [1148/1920], Train Loss: 0.6610, Valid Loss: 0.6813\n",
      "Epoch [12/20], LR: 0.042, Step [1152/1920], Train Loss: 0.6410, Valid Loss: 0.6809\n",
      "time elapsed in epoch: 2.0726778507232666\n",
      "Epoch [13/20], LR: 0.046, Step [1156/1920], Train Loss: 0.6161, Valid Loss: 0.6811\n",
      "Epoch [13/20], LR: 0.046, Step [1160/1920], Train Loss: 0.6490, Valid Loss: 0.6814\n",
      "Epoch [13/20], LR: 0.046, Step [1164/1920], Train Loss: 0.6736, Valid Loss: 0.6814\n",
      "Epoch [13/20], LR: 0.046, Step [1168/1920], Train Loss: 0.6864, Valid Loss: 0.6812\n",
      "Epoch [13/20], LR: 0.046, Step [1172/1920], Train Loss: 0.7067, Valid Loss: 0.6809\n",
      "Epoch [13/20], LR: 0.046, Step [1176/1920], Train Loss: 0.6787, Valid Loss: 0.6808\n",
      "Epoch [13/20], LR: 0.046, Step [1180/1920], Train Loss: 0.7026, Valid Loss: 0.6807\n",
      "Epoch [13/20], LR: 0.046, Step [1184/1920], Train Loss: 0.6996, Valid Loss: 0.6807\n",
      "Epoch [13/20], LR: 0.046, Step [1188/1920], Train Loss: 0.6885, Valid Loss: 0.6807\n",
      "Epoch [13/20], LR: 0.046, Step [1192/1920], Train Loss: 0.6669, Valid Loss: 0.6806\n",
      "Epoch [13/20], LR: 0.046, Step [1196/1920], Train Loss: 0.6792, Valid Loss: 0.6806\n",
      "Epoch [13/20], LR: 0.046, Step [1200/1920], Train Loss: 0.7053, Valid Loss: 0.6807\n",
      "Epoch [13/20], LR: 0.046, Step [1204/1920], Train Loss: 0.6996, Valid Loss: 0.6808\n",
      "Epoch [13/20], LR: 0.046, Step [1208/1920], Train Loss: 0.6915, Valid Loss: 0.6808\n",
      "Epoch [13/20], LR: 0.046, Step [1212/1920], Train Loss: 0.6917, Valid Loss: 0.6809\n",
      "Epoch [13/20], LR: 0.046, Step [1216/1920], Train Loss: 0.6948, Valid Loss: 0.6810\n",
      "Epoch [13/20], LR: 0.046, Step [1220/1920], Train Loss: 0.7012, Valid Loss: 0.6813\n",
      "Epoch [13/20], LR: 0.046, Step [1224/1920], Train Loss: 0.6787, Valid Loss: 0.6812\n",
      "Epoch [13/20], LR: 0.046, Step [1228/1920], Train Loss: 0.6926, Valid Loss: 0.6813\n",
      "Epoch [13/20], LR: 0.046, Step [1232/1920], Train Loss: 0.6892, Valid Loss: 0.6813\n",
      "Epoch [13/20], LR: 0.046, Step [1236/1920], Train Loss: 0.7011, Valid Loss: 0.6814\n",
      "Epoch [13/20], LR: 0.046, Step [1240/1920], Train Loss: 0.6789, Valid Loss: 0.6811\n",
      "Epoch [13/20], LR: 0.046, Step [1244/1920], Train Loss: 0.6533, Valid Loss: 0.6807\n",
      "Epoch [13/20], LR: 0.046, Step [1248/1920], Train Loss: 0.6303, Valid Loss: 0.6804\n",
      "time elapsed in epoch: 2.0763468742370605\n",
      "Epoch [14/20], LR: 0.050, Step [1252/1920], Train Loss: 0.6149, Valid Loss: 0.6809\n",
      "Epoch [14/20], LR: 0.050, Step [1256/1920], Train Loss: 0.6438, Valid Loss: 0.6812\n",
      "Epoch [14/20], LR: 0.050, Step [1260/1920], Train Loss: 0.6722, Valid Loss: 0.6811\n",
      "Epoch [14/20], LR: 0.050, Step [1264/1920], Train Loss: 0.6848, Valid Loss: 0.6810\n",
      "Epoch [14/20], LR: 0.050, Step [1268/1920], Train Loss: 0.7039, Valid Loss: 0.6805\n",
      "Epoch [14/20], LR: 0.050, Step [1272/1920], Train Loss: 0.6733, Valid Loss: 0.6805\n",
      "Epoch [14/20], LR: 0.050, Step [1276/1920], Train Loss: 0.7000, Valid Loss: 0.6803\n",
      "Epoch [14/20], LR: 0.050, Step [1280/1920], Train Loss: 0.7026, Valid Loss: 0.6802\n",
      "Epoch [14/20], LR: 0.050, Step [1284/1920], Train Loss: 0.6855, Valid Loss: 0.6802\n",
      "Epoch [14/20], LR: 0.050, Step [1288/1920], Train Loss: 0.6648, Valid Loss: 0.6802\n",
      "Epoch [14/20], LR: 0.050, Step [1292/1920], Train Loss: 0.6726, Valid Loss: 0.6801\n",
      "Epoch [14/20], LR: 0.050, Step [1296/1920], Train Loss: 0.7033, Valid Loss: 0.6801\n",
      "Epoch [14/20], LR: 0.050, Step [1300/1920], Train Loss: 0.7001, Valid Loss: 0.6802\n",
      "Epoch [14/20], LR: 0.050, Step [1304/1920], Train Loss: 0.6864, Valid Loss: 0.6802\n",
      "Epoch [14/20], LR: 0.050, Step [1308/1920], Train Loss: 0.6946, Valid Loss: 0.6803\n",
      "Epoch [14/20], LR: 0.050, Step [1312/1920], Train Loss: 0.7015, Valid Loss: 0.6805\n",
      "Epoch [14/20], LR: 0.050, Step [1316/1920], Train Loss: 0.7061, Valid Loss: 0.6809\n",
      "Epoch [14/20], LR: 0.050, Step [1320/1920], Train Loss: 0.6814, Valid Loss: 0.6807\n",
      "Epoch [14/20], LR: 0.050, Step [1324/1920], Train Loss: 0.6889, Valid Loss: 0.6808\n",
      "Epoch [14/20], LR: 0.050, Step [1328/1920], Train Loss: 0.6895, Valid Loss: 0.6809\n",
      "Epoch [14/20], LR: 0.050, Step [1332/1920], Train Loss: 0.6947, Valid Loss: 0.6811\n",
      "Epoch [14/20], LR: 0.050, Step [1336/1920], Train Loss: 0.6736, Valid Loss: 0.6808\n",
      "Epoch [14/20], LR: 0.050, Step [1340/1920], Train Loss: 0.6551, Valid Loss: 0.6803\n",
      "Epoch [14/20], LR: 0.050, Step [1344/1920], Train Loss: 0.6214, Valid Loss: 0.6799\n",
      "time elapsed in epoch: 2.020301580429077\n",
      "Epoch [15/20], LR: 0.054, Step [1348/1920], Train Loss: 0.6045, Valid Loss: 0.6804\n",
      "Epoch [15/20], LR: 0.054, Step [1352/1920], Train Loss: 0.6519, Valid Loss: 0.6809\n",
      "Epoch [15/20], LR: 0.054, Step [1356/1920], Train Loss: 0.6722, Valid Loss: 0.6808\n",
      "Epoch [15/20], LR: 0.054, Step [1360/1920], Train Loss: 0.6824, Valid Loss: 0.6805\n",
      "Epoch [15/20], LR: 0.054, Step [1364/1920], Train Loss: 0.7133, Valid Loss: 0.6800\n",
      "Epoch [15/20], LR: 0.054, Step [1368/1920], Train Loss: 0.6793, Valid Loss: 0.6800\n",
      "Epoch [15/20], LR: 0.054, Step [1372/1920], Train Loss: 0.6999, Valid Loss: 0.6798\n",
      "Epoch [15/20], LR: 0.054, Step [1376/1920], Train Loss: 0.7037, Valid Loss: 0.6796\n",
      "Epoch [15/20], LR: 0.054, Step [1380/1920], Train Loss: 0.6804, Valid Loss: 0.6796\n",
      "Epoch [15/20], LR: 0.054, Step [1384/1920], Train Loss: 0.6643, Valid Loss: 0.6796\n",
      "Epoch [15/20], LR: 0.054, Step [1388/1920], Train Loss: 0.6818, Valid Loss: 0.6796\n",
      "Epoch [15/20], LR: 0.054, Step [1392/1920], Train Loss: 0.7061, Valid Loss: 0.6797\n",
      "Epoch [15/20], LR: 0.054, Step [1396/1920], Train Loss: 0.6994, Valid Loss: 0.6797\n",
      "Epoch [15/20], LR: 0.054, Step [1400/1920], Train Loss: 0.6843, Valid Loss: 0.6797\n",
      "Epoch [15/20], LR: 0.054, Step [1404/1920], Train Loss: 0.6898, Valid Loss: 0.6798\n",
      "Epoch [15/20], LR: 0.054, Step [1408/1920], Train Loss: 0.7001, Valid Loss: 0.6801\n",
      "Epoch [15/20], LR: 0.054, Step [1412/1920], Train Loss: 0.7034, Valid Loss: 0.6804\n",
      "Epoch [15/20], LR: 0.054, Step [1416/1920], Train Loss: 0.6849, Valid Loss: 0.6802\n",
      "Epoch [15/20], LR: 0.054, Step [1420/1920], Train Loss: 0.6878, Valid Loss: 0.6803\n",
      "Epoch [15/20], LR: 0.054, Step [1424/1920], Train Loss: 0.6991, Valid Loss: 0.6805\n",
      "Epoch [15/20], LR: 0.054, Step [1428/1920], Train Loss: 0.6911, Valid Loss: 0.6806\n",
      "Epoch [15/20], LR: 0.054, Step [1432/1920], Train Loss: 0.6828, Valid Loss: 0.6803\n",
      "Epoch [15/20], LR: 0.054, Step [1436/1920], Train Loss: 0.6569, Valid Loss: 0.6798\n",
      "Epoch [15/20], LR: 0.054, Step [1440/1920], Train Loss: 0.6342, Valid Loss: 0.6796\n",
      "time elapsed in epoch: 2.212411403656006\n",
      "Epoch [16/20], LR: 0.058, Step [1444/1920], Train Loss: 0.6070, Valid Loss: 0.6802\n",
      "Epoch [16/20], LR: 0.058, Step [1448/1920], Train Loss: 0.6421, Valid Loss: 0.6809\n",
      "Epoch [16/20], LR: 0.058, Step [1452/1920], Train Loss: 0.6758, Valid Loss: 0.6806\n",
      "Epoch [16/20], LR: 0.058, Step [1456/1920], Train Loss: 0.6854, Valid Loss: 0.6803\n",
      "Epoch [16/20], LR: 0.058, Step [1460/1920], Train Loss: 0.7105, Valid Loss: 0.6796\n",
      "Epoch [16/20], LR: 0.058, Step [1464/1920], Train Loss: 0.6766, Valid Loss: 0.6796\n",
      "Epoch [16/20], LR: 0.058, Step [1468/1920], Train Loss: 0.6992, Valid Loss: 0.6793\n",
      "Epoch [16/20], LR: 0.058, Step [1472/1920], Train Loss: 0.6981, Valid Loss: 0.6792\n",
      "Epoch [16/20], LR: 0.058, Step [1476/1920], Train Loss: 0.6833, Valid Loss: 0.6792\n",
      "Epoch [16/20], LR: 0.058, Step [1480/1920], Train Loss: 0.6654, Valid Loss: 0.6791\n",
      "Epoch [16/20], LR: 0.058, Step [1484/1920], Train Loss: 0.6809, Valid Loss: 0.6791\n",
      "Epoch [16/20], LR: 0.058, Step [1488/1920], Train Loss: 0.6988, Valid Loss: 0.6791\n",
      "Epoch [16/20], LR: 0.058, Step [1492/1920], Train Loss: 0.6980, Valid Loss: 0.6792\n",
      "Epoch [16/20], LR: 0.058, Step [1496/1920], Train Loss: 0.6837, Valid Loss: 0.6792\n",
      "Epoch [16/20], LR: 0.058, Step [1500/1920], Train Loss: 0.6887, Valid Loss: 0.6793\n",
      "Epoch [16/20], LR: 0.058, Step [1504/1920], Train Loss: 0.7033, Valid Loss: 0.6796\n",
      "Epoch [16/20], LR: 0.058, Step [1508/1920], Train Loss: 0.6996, Valid Loss: 0.6800\n",
      "Epoch [16/20], LR: 0.058, Step [1512/1920], Train Loss: 0.6810, Valid Loss: 0.6798\n",
      "Epoch [16/20], LR: 0.058, Step [1516/1920], Train Loss: 0.6818, Valid Loss: 0.6798\n",
      "Epoch [16/20], LR: 0.058, Step [1520/1920], Train Loss: 0.6979, Valid Loss: 0.6800\n",
      "Epoch [16/20], LR: 0.058, Step [1524/1920], Train Loss: 0.6925, Valid Loss: 0.6802\n",
      "Epoch [16/20], LR: 0.058, Step [1528/1920], Train Loss: 0.6809, Valid Loss: 0.6798\n",
      "Epoch [16/20], LR: 0.058, Step [1532/1920], Train Loss: 0.6637, Valid Loss: 0.6793\n",
      "Epoch [16/20], LR: 0.058, Step [1536/1920], Train Loss: 0.6232, Valid Loss: 0.6789\n",
      "time elapsed in epoch: 2.079371690750122\n",
      "Epoch [17/20], LR: 0.063, Step [1540/1920], Train Loss: 0.6071, Valid Loss: 0.6798\n",
      "Epoch [17/20], LR: 0.063, Step [1544/1920], Train Loss: 0.6397, Valid Loss: 0.6803\n",
      "Epoch [17/20], LR: 0.063, Step [1548/1920], Train Loss: 0.6693, Valid Loss: 0.6802\n",
      "Epoch [17/20], LR: 0.063, Step [1552/1920], Train Loss: 0.6893, Valid Loss: 0.6799\n",
      "Epoch [17/20], LR: 0.063, Step [1556/1920], Train Loss: 0.7070, Valid Loss: 0.6791\n",
      "Epoch [17/20], LR: 0.063, Step [1560/1920], Train Loss: 0.6706, Valid Loss: 0.6791\n",
      "Epoch [17/20], LR: 0.063, Step [1564/1920], Train Loss: 0.7022, Valid Loss: 0.6788\n",
      "Epoch [17/20], LR: 0.063, Step [1568/1920], Train Loss: 0.6994, Valid Loss: 0.6787\n",
      "Epoch [17/20], LR: 0.063, Step [1572/1920], Train Loss: 0.6802, Valid Loss: 0.6787\n",
      "Epoch [17/20], LR: 0.063, Step [1576/1920], Train Loss: 0.6609, Valid Loss: 0.6786\n",
      "Epoch [17/20], LR: 0.063, Step [1580/1920], Train Loss: 0.6822, Valid Loss: 0.6786\n",
      "Epoch [17/20], LR: 0.063, Step [1584/1920], Train Loss: 0.6958, Valid Loss: 0.6786\n",
      "Epoch [17/20], LR: 0.063, Step [1588/1920], Train Loss: 0.7034, Valid Loss: 0.6787\n",
      "Epoch [17/20], LR: 0.063, Step [1592/1920], Train Loss: 0.6916, Valid Loss: 0.6788\n",
      "Epoch [17/20], LR: 0.063, Step [1596/1920], Train Loss: 0.6939, Valid Loss: 0.6789\n",
      "Epoch [17/20], LR: 0.063, Step [1600/1920], Train Loss: 0.6967, Valid Loss: 0.6791\n",
      "Epoch [17/20], LR: 0.063, Step [1604/1920], Train Loss: 0.7017, Valid Loss: 0.6795\n",
      "Epoch [17/20], LR: 0.063, Step [1608/1920], Train Loss: 0.6873, Valid Loss: 0.6793\n",
      "Epoch [17/20], LR: 0.063, Step [1612/1920], Train Loss: 0.6888, Valid Loss: 0.6793\n",
      "Epoch [17/20], LR: 0.063, Step [1616/1920], Train Loss: 0.6857, Valid Loss: 0.6795\n",
      "Epoch [17/20], LR: 0.063, Step [1620/1920], Train Loss: 0.6926, Valid Loss: 0.6797\n",
      "Epoch [17/20], LR: 0.063, Step [1624/1920], Train Loss: 0.6793, Valid Loss: 0.6793\n",
      "Epoch [17/20], LR: 0.063, Step [1628/1920], Train Loss: 0.6594, Valid Loss: 0.6787\n",
      "Epoch [17/20], LR: 0.063, Step [1632/1920], Train Loss: 0.6346, Valid Loss: 0.6785\n",
      "time elapsed in epoch: 2.1451523303985596\n",
      "Epoch [18/20], LR: 0.067, Step [1636/1920], Train Loss: 0.6078, Valid Loss: 0.6795\n",
      "Epoch [18/20], LR: 0.067, Step [1640/1920], Train Loss: 0.6412, Valid Loss: 0.6803\n",
      "Epoch [18/20], LR: 0.067, Step [1644/1920], Train Loss: 0.6801, Valid Loss: 0.6801\n",
      "Epoch [18/20], LR: 0.067, Step [1648/1920], Train Loss: 0.6867, Valid Loss: 0.6797\n",
      "Epoch [18/20], LR: 0.067, Step [1652/1920], Train Loss: 0.7053, Valid Loss: 0.6789\n",
      "Epoch [18/20], LR: 0.067, Step [1656/1920], Train Loss: 0.6721, Valid Loss: 0.6789\n",
      "Epoch [18/20], LR: 0.067, Step [1660/1920], Train Loss: 0.7009, Valid Loss: 0.6785\n",
      "Epoch [18/20], LR: 0.067, Step [1664/1920], Train Loss: 0.7012, Valid Loss: 0.6783\n",
      "Epoch [18/20], LR: 0.067, Step [1668/1920], Train Loss: 0.6798, Valid Loss: 0.6782\n",
      "Epoch [18/20], LR: 0.067, Step [1672/1920], Train Loss: 0.6774, Valid Loss: 0.6783\n",
      "Epoch [18/20], LR: 0.067, Step [1676/1920], Train Loss: 0.6763, Valid Loss: 0.6783\n",
      "Epoch [18/20], LR: 0.067, Step [1680/1920], Train Loss: 0.6994, Valid Loss: 0.6783\n",
      "Epoch [18/20], LR: 0.067, Step [1684/1920], Train Loss: 0.7020, Valid Loss: 0.6784\n",
      "Epoch [18/20], LR: 0.067, Step [1688/1920], Train Loss: 0.6887, Valid Loss: 0.6784\n",
      "Epoch [18/20], LR: 0.067, Step [1692/1920], Train Loss: 0.6965, Valid Loss: 0.6785\n",
      "Epoch [18/20], LR: 0.067, Step [1696/1920], Train Loss: 0.7010, Valid Loss: 0.6788\n",
      "Epoch [18/20], LR: 0.067, Step [1700/1920], Train Loss: 0.7045, Valid Loss: 0.6793\n",
      "Epoch [18/20], LR: 0.067, Step [1704/1920], Train Loss: 0.6791, Valid Loss: 0.6790\n",
      "Epoch [18/20], LR: 0.067, Step [1708/1920], Train Loss: 0.6843, Valid Loss: 0.6792\n",
      "Epoch [18/20], LR: 0.067, Step [1712/1920], Train Loss: 0.6946, Valid Loss: 0.6794\n",
      "Epoch [18/20], LR: 0.067, Step [1716/1920], Train Loss: 0.6906, Valid Loss: 0.6795\n",
      "Epoch [18/20], LR: 0.067, Step [1720/1920], Train Loss: 0.6805, Valid Loss: 0.6794\n",
      "Epoch [18/20], LR: 0.067, Step [1724/1920], Train Loss: 0.6599, Valid Loss: 0.6788\n",
      "Epoch [18/20], LR: 0.067, Step [1728/1920], Train Loss: 0.6288, Valid Loss: 0.6783\n",
      "time elapsed in epoch: 2.0372235774993896\n",
      "Epoch [19/20], LR: 0.071, Step [1732/1920], Train Loss: 0.6116, Valid Loss: 0.6793\n",
      "Epoch [19/20], LR: 0.071, Step [1736/1920], Train Loss: 0.6481, Valid Loss: 0.6800\n",
      "Epoch [19/20], LR: 0.071, Step [1740/1920], Train Loss: 0.6710, Valid Loss: 0.6797\n",
      "Epoch [19/20], LR: 0.071, Step [1744/1920], Train Loss: 0.6923, Valid Loss: 0.6794\n",
      "Epoch [19/20], LR: 0.071, Step [1748/1920], Train Loss: 0.7103, Valid Loss: 0.6786\n",
      "Epoch [19/20], LR: 0.071, Step [1752/1920], Train Loss: 0.6750, Valid Loss: 0.6787\n",
      "Epoch [19/20], LR: 0.071, Step [1756/1920], Train Loss: 0.6995, Valid Loss: 0.6783\n",
      "Epoch [19/20], LR: 0.071, Step [1760/1920], Train Loss: 0.6997, Valid Loss: 0.6782\n",
      "Epoch [19/20], LR: 0.071, Step [1764/1920], Train Loss: 0.6830, Valid Loss: 0.6781\n",
      "Epoch [19/20], LR: 0.071, Step [1768/1920], Train Loss: 0.6586, Valid Loss: 0.6781\n",
      "Epoch [19/20], LR: 0.071, Step [1772/1920], Train Loss: 0.6746, Valid Loss: 0.6780\n",
      "Epoch [19/20], LR: 0.071, Step [1776/1920], Train Loss: 0.7031, Valid Loss: 0.6781\n",
      "Epoch [19/20], LR: 0.071, Step [1780/1920], Train Loss: 0.6930, Valid Loss: 0.6782\n",
      "Epoch [19/20], LR: 0.071, Step [1784/1920], Train Loss: 0.6822, Valid Loss: 0.6782\n",
      "Epoch [19/20], LR: 0.071, Step [1788/1920], Train Loss: 0.6898, Valid Loss: 0.6784\n",
      "Epoch [19/20], LR: 0.071, Step [1792/1920], Train Loss: 0.6948, Valid Loss: 0.6786\n",
      "Epoch [19/20], LR: 0.071, Step [1796/1920], Train Loss: 0.7016, Valid Loss: 0.6791\n",
      "Epoch [19/20], LR: 0.071, Step [1800/1920], Train Loss: 0.6853, Valid Loss: 0.6788\n",
      "Epoch [19/20], LR: 0.071, Step [1804/1920], Train Loss: 0.6824, Valid Loss: 0.6789\n",
      "Epoch [19/20], LR: 0.071, Step [1808/1920], Train Loss: 0.6935, Valid Loss: 0.6791\n",
      "Epoch [19/20], LR: 0.071, Step [1812/1920], Train Loss: 0.6883, Valid Loss: 0.6792\n",
      "Epoch [19/20], LR: 0.071, Step [1816/1920], Train Loss: 0.6696, Valid Loss: 0.6788\n",
      "Epoch [19/20], LR: 0.071, Step [1820/1920], Train Loss: 0.6618, Valid Loss: 0.6781\n",
      "Epoch [19/20], LR: 0.071, Step [1824/1920], Train Loss: 0.6269, Valid Loss: 0.6777\n",
      "time elapsed in epoch: 2.149946451187134\n",
      "Epoch [20/20], LR: 0.075, Step [1828/1920], Train Loss: 0.6026, Valid Loss: 0.6788\n",
      "Epoch [20/20], LR: 0.075, Step [1832/1920], Train Loss: 0.6408, Valid Loss: 0.6796\n",
      "Epoch [20/20], LR: 0.075, Step [1836/1920], Train Loss: 0.6753, Valid Loss: 0.6794\n",
      "Epoch [20/20], LR: 0.075, Step [1840/1920], Train Loss: 0.6853, Valid Loss: 0.6789\n",
      "Epoch [20/20], LR: 0.075, Step [1844/1920], Train Loss: 0.7063, Valid Loss: 0.6779\n",
      "Epoch [20/20], LR: 0.075, Step [1848/1920], Train Loss: 0.6717, Valid Loss: 0.6778\n",
      "Epoch [20/20], LR: 0.075, Step [1852/1920], Train Loss: 0.7014, Valid Loss: 0.6775\n",
      "Epoch [20/20], LR: 0.075, Step [1856/1920], Train Loss: 0.7053, Valid Loss: 0.6774\n",
      "Epoch [20/20], LR: 0.075, Step [1860/1920], Train Loss: 0.6796, Valid Loss: 0.6773\n",
      "Epoch [20/20], LR: 0.075, Step [1864/1920], Train Loss: 0.6679, Valid Loss: 0.6774\n",
      "Epoch [20/20], LR: 0.075, Step [1868/1920], Train Loss: 0.6769, Valid Loss: 0.6773\n",
      "Epoch [20/20], LR: 0.075, Step [1872/1920], Train Loss: 0.7059, Valid Loss: 0.6774\n",
      "Epoch [20/20], LR: 0.075, Step [1876/1920], Train Loss: 0.7026, Valid Loss: 0.6775\n",
      "Epoch [20/20], LR: 0.075, Step [1880/1920], Train Loss: 0.6914, Valid Loss: 0.6776\n",
      "Epoch [20/20], LR: 0.075, Step [1884/1920], Train Loss: 0.6885, Valid Loss: 0.6776\n",
      "Epoch [20/20], LR: 0.075, Step [1888/1920], Train Loss: 0.7022, Valid Loss: 0.6779\n",
      "Epoch [20/20], LR: 0.075, Step [1892/1920], Train Loss: 0.7017, Valid Loss: 0.6785\n",
      "Epoch [20/20], LR: 0.075, Step [1896/1920], Train Loss: 0.6765, Valid Loss: 0.6782\n",
      "Epoch [20/20], LR: 0.075, Step [1900/1920], Train Loss: 0.6922, Valid Loss: 0.6783\n",
      "Epoch [20/20], LR: 0.075, Step [1904/1920], Train Loss: 0.6879, Valid Loss: 0.6785\n",
      "Epoch [20/20], LR: 0.075, Step [1908/1920], Train Loss: 0.6900, Valid Loss: 0.6787\n",
      "Epoch [20/20], LR: 0.075, Step [1912/1920], Train Loss: 0.6754, Valid Loss: 0.6781\n",
      "Epoch [20/20], LR: 0.075, Step [1916/1920], Train Loss: 0.6599, Valid Loss: 0.6776\n",
      "Epoch [20/20], LR: 0.075, Step [1920/1920], Train Loss: 0.6143, Valid Loss: 0.6773\n",
      "time elapsed in epoch: 2.145305871963501\n",
      "Finished Training!\n"
     ]
    }
   ],
   "source": [
    "!python train_rnn.py --flor newFlor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle-nlp-dist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "815c30a49f552e6fdb87f74e117ecdf18b0ca5a01ddc5c83796985c2fbc2bb40"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
