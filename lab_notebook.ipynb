{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to run your experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rogarcia/anaconda3/envs/kaggle-nlp-dist/lib/python3.9/site-packages/torchtext/data/utils.py:123: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
      "  warnings.warn(f'Spacy model \"{language}\" could not be loaded, trying \"{OLD_MODEL_SHORTCUTS[language]}\" instead')\n",
      "Epoch [1/20], LR: 0.000, Step [4/1920], Train Loss: 0.7350, Valid Loss: 0.6973\n",
      "Epoch [1/20], LR: 0.000, Step [8/1920], Train Loss: 0.7126, Valid Loss: 0.6972\n",
      "Epoch [1/20], LR: 0.000, Step [12/1920], Train Loss: 0.7164, Valid Loss: 0.6972\n",
      "Epoch [1/20], LR: 0.000, Step [16/1920], Train Loss: 0.7137, Valid Loss: 0.6972\n",
      "Epoch [1/20], LR: 0.000, Step [20/1920], Train Loss: 0.6837, Valid Loss: 0.6972\n",
      "Epoch [1/20], LR: 0.000, Step [24/1920], Train Loss: 0.6999, Valid Loss: 0.6972\n",
      "Epoch [1/20], LR: 0.000, Step [28/1920], Train Loss: 0.7277, Valid Loss: 0.6972\n",
      "Epoch [1/20], LR: 0.000, Step [32/1920], Train Loss: 0.7170, Valid Loss: 0.6972\n",
      "Epoch [1/20], LR: 0.000, Step [36/1920], Train Loss: 0.7239, Valid Loss: 0.6972\n",
      "Epoch [1/20], LR: 0.000, Step [40/1920], Train Loss: 0.7097, Valid Loss: 0.6972\n",
      "Epoch [1/20], LR: 0.000, Step [44/1920], Train Loss: 0.7281, Valid Loss: 0.6972\n",
      "Epoch [1/20], LR: 0.000, Step [48/1920], Train Loss: 0.7069, Valid Loss: 0.6972\n",
      "Epoch [1/20], LR: 0.000, Step [52/1920], Train Loss: 0.7306, Valid Loss: 0.6972\n",
      "Epoch [1/20], LR: 0.000, Step [56/1920], Train Loss: 0.7218, Valid Loss: 0.6972\n",
      "Epoch [1/20], LR: 0.000, Step [60/1920], Train Loss: 0.6944, Valid Loss: 0.6972\n",
      "Epoch [1/20], LR: 0.000, Step [64/1920], Train Loss: 0.7144, Valid Loss: 0.6972\n",
      "Epoch [1/20], LR: 0.000, Step [68/1920], Train Loss: 0.7156, Valid Loss: 0.6972\n",
      "Epoch [1/20], LR: 0.000, Step [72/1920], Train Loss: 0.7049, Valid Loss: 0.6972\n",
      "Epoch [1/20], LR: 0.000, Step [76/1920], Train Loss: 0.7200, Valid Loss: 0.6972\n",
      "Epoch [1/20], LR: 0.000, Step [80/1920], Train Loss: 0.7119, Valid Loss: 0.6972\n",
      "Epoch [1/20], LR: 0.000, Step [84/1920], Train Loss: 0.7126, Valid Loss: 0.6972\n",
      "Epoch [1/20], LR: 0.000, Step [88/1920], Train Loss: 0.7270, Valid Loss: 0.6971\n",
      "Epoch [1/20], LR: 0.000, Step [92/1920], Train Loss: 0.7234, Valid Loss: 0.6971\n",
      "Epoch [1/20], LR: 0.000, Step [96/1920], Train Loss: 0.7114, Valid Loss: 0.6971\n",
      "time elapsed in epoch: 1.8440802097320557\n",
      "Epoch [2/20], LR: 0.000, Step [100/1920], Train Loss: 0.7530, Valid Loss: 0.6971\n",
      "Epoch [2/20], LR: 0.000, Step [104/1920], Train Loss: 0.7307, Valid Loss: 0.6971\n",
      "Epoch [2/20], LR: 0.000, Step [108/1920], Train Loss: 0.7170, Valid Loss: 0.6971\n",
      "Epoch [2/20], LR: 0.000, Step [112/1920], Train Loss: 0.7253, Valid Loss: 0.6971\n",
      "Epoch [2/20], LR: 0.000, Step [116/1920], Train Loss: 0.7146, Valid Loss: 0.6971\n",
      "Epoch [2/20], LR: 0.000, Step [120/1920], Train Loss: 0.7099, Valid Loss: 0.6971\n",
      "Epoch [2/20], LR: 0.000, Step [124/1920], Train Loss: 0.7167, Valid Loss: 0.6971\n",
      "Epoch [2/20], LR: 0.000, Step [128/1920], Train Loss: 0.7114, Valid Loss: 0.6971\n",
      "Epoch [2/20], LR: 0.000, Step [132/1920], Train Loss: 0.7181, Valid Loss: 0.6970\n",
      "Epoch [2/20], LR: 0.000, Step [136/1920], Train Loss: 0.7144, Valid Loss: 0.6970\n",
      "Epoch [2/20], LR: 0.000, Step [140/1920], Train Loss: 0.7191, Valid Loss: 0.6970\n",
      "Epoch [2/20], LR: 0.000, Step [144/1920], Train Loss: 0.7194, Valid Loss: 0.6970\n",
      "Epoch [2/20], LR: 0.000, Step [148/1920], Train Loss: 0.6964, Valid Loss: 0.6970\n",
      "Epoch [2/20], LR: 0.000, Step [152/1920], Train Loss: 0.7014, Valid Loss: 0.6970\n",
      "Epoch [2/20], LR: 0.000, Step [156/1920], Train Loss: 0.6905, Valid Loss: 0.6970\n",
      "Epoch [2/20], LR: 0.000, Step [160/1920], Train Loss: 0.7261, Valid Loss: 0.6970\n",
      "Epoch [2/20], LR: 0.000, Step [164/1920], Train Loss: 0.6989, Valid Loss: 0.6970\n",
      "Epoch [2/20], LR: 0.000, Step [168/1920], Train Loss: 0.7082, Valid Loss: 0.6970\n",
      "Epoch [2/20], LR: 0.000, Step [172/1920], Train Loss: 0.7234, Valid Loss: 0.6970\n",
      "Epoch [2/20], LR: 0.000, Step [176/1920], Train Loss: 0.6949, Valid Loss: 0.6970\n",
      "Epoch [2/20], LR: 0.000, Step [180/1920], Train Loss: 0.7329, Valid Loss: 0.6970\n",
      "Epoch [2/20], LR: 0.000, Step [184/1920], Train Loss: 0.7218, Valid Loss: 0.6970\n",
      "Epoch [2/20], LR: 0.000, Step [188/1920], Train Loss: 0.7311, Valid Loss: 0.6970\n",
      "Epoch [2/20], LR: 0.000, Step [192/1920], Train Loss: 0.6954, Valid Loss: 0.6970\n",
      "time elapsed in epoch: 1.80979585647583\n",
      "Epoch [3/20], LR: 0.004, Step [196/1920], Train Loss: 0.7492, Valid Loss: 0.6960\n",
      "Epoch [3/20], LR: 0.004, Step [200/1920], Train Loss: 0.7346, Valid Loss: 0.6955\n",
      "Epoch [3/20], LR: 0.004, Step [204/1920], Train Loss: 0.7072, Valid Loss: 0.6951\n",
      "Epoch [3/20], LR: 0.004, Step [208/1920], Train Loss: 0.7231, Valid Loss: 0.6950\n",
      "Epoch [3/20], LR: 0.004, Step [212/1920], Train Loss: 0.6950, Valid Loss: 0.6950\n",
      "Epoch [3/20], LR: 0.004, Step [216/1920], Train Loss: 0.6868, Valid Loss: 0.6947\n",
      "Epoch [3/20], LR: 0.004, Step [220/1920], Train Loss: 0.7261, Valid Loss: 0.6946\n",
      "Epoch [3/20], LR: 0.004, Step [224/1920], Train Loss: 0.7052, Valid Loss: 0.6945\n",
      "Epoch [3/20], LR: 0.004, Step [228/1920], Train Loss: 0.7066, Valid Loss: 0.6944\n",
      "Epoch [3/20], LR: 0.004, Step [232/1920], Train Loss: 0.7149, Valid Loss: 0.6940\n",
      "Epoch [3/20], LR: 0.004, Step [236/1920], Train Loss: 0.7027, Valid Loss: 0.6938\n",
      "Epoch [3/20], LR: 0.004, Step [240/1920], Train Loss: 0.7195, Valid Loss: 0.6937\n",
      "Epoch [3/20], LR: 0.004, Step [244/1920], Train Loss: 0.6953, Valid Loss: 0.6937\n",
      "Epoch [3/20], LR: 0.004, Step [248/1920], Train Loss: 0.7123, Valid Loss: 0.6936\n",
      "Epoch [3/20], LR: 0.004, Step [252/1920], Train Loss: 0.7091, Valid Loss: 0.6936\n",
      "Epoch [3/20], LR: 0.004, Step [256/1920], Train Loss: 0.7174, Valid Loss: 0.6935\n",
      "Epoch [3/20], LR: 0.004, Step [260/1920], Train Loss: 0.7151, Valid Loss: 0.6936\n",
      "Epoch [3/20], LR: 0.004, Step [264/1920], Train Loss: 0.7028, Valid Loss: 0.6934\n",
      "Epoch [3/20], LR: 0.004, Step [268/1920], Train Loss: 0.6859, Valid Loss: 0.6933\n",
      "Epoch [3/20], LR: 0.004, Step [272/1920], Train Loss: 0.7156, Valid Loss: 0.6933\n",
      "Epoch [3/20], LR: 0.004, Step [276/1920], Train Loss: 0.7166, Valid Loss: 0.6932\n",
      "Epoch [3/20], LR: 0.004, Step [280/1920], Train Loss: 0.7049, Valid Loss: 0.6930\n",
      "Epoch [3/20], LR: 0.004, Step [284/1920], Train Loss: 0.6994, Valid Loss: 0.6926\n",
      "Epoch [3/20], LR: 0.004, Step [288/1920], Train Loss: 0.6764, Valid Loss: 0.6920\n",
      "time elapsed in epoch: 1.8557319641113281\n",
      "Epoch [4/20], LR: 0.008, Step [292/1920], Train Loss: 0.7173, Valid Loss: 0.6907\n",
      "Epoch [4/20], LR: 0.008, Step [296/1920], Train Loss: 0.6906, Valid Loss: 0.6900\n",
      "Epoch [4/20], LR: 0.008, Step [300/1920], Train Loss: 0.7073, Valid Loss: 0.6897\n",
      "Epoch [4/20], LR: 0.008, Step [304/1920], Train Loss: 0.7019, Valid Loss: 0.6894\n",
      "Epoch [4/20], LR: 0.008, Step [308/1920], Train Loss: 0.7111, Valid Loss: 0.6896\n",
      "Epoch [4/20], LR: 0.008, Step [312/1920], Train Loss: 0.6989, Valid Loss: 0.6893\n",
      "Epoch [4/20], LR: 0.008, Step [316/1920], Train Loss: 0.7097, Valid Loss: 0.6892\n",
      "Epoch [4/20], LR: 0.008, Step [320/1920], Train Loss: 0.6844, Valid Loss: 0.6894\n",
      "Epoch [4/20], LR: 0.008, Step [324/1920], Train Loss: 0.6944, Valid Loss: 0.6891\n",
      "Epoch [4/20], LR: 0.008, Step [328/1920], Train Loss: 0.6992, Valid Loss: 0.6887\n",
      "Epoch [4/20], LR: 0.008, Step [332/1920], Train Loss: 0.6902, Valid Loss: 0.6884\n",
      "Epoch [4/20], LR: 0.008, Step [336/1920], Train Loss: 0.6987, Valid Loss: 0.6883\n",
      "Epoch [4/20], LR: 0.008, Step [340/1920], Train Loss: 0.7187, Valid Loss: 0.6884\n",
      "Epoch [4/20], LR: 0.008, Step [344/1920], Train Loss: 0.7071, Valid Loss: 0.6883\n",
      "Epoch [4/20], LR: 0.008, Step [348/1920], Train Loss: 0.7074, Valid Loss: 0.6883\n",
      "Epoch [4/20], LR: 0.008, Step [352/1920], Train Loss: 0.7062, Valid Loss: 0.6883\n",
      "Epoch [4/20], LR: 0.008, Step [356/1920], Train Loss: 0.6994, Valid Loss: 0.6885\n",
      "Epoch [4/20], LR: 0.008, Step [360/1920], Train Loss: 0.6855, Valid Loss: 0.6882\n",
      "Epoch [4/20], LR: 0.008, Step [364/1920], Train Loss: 0.7107, Valid Loss: 0.6881\n",
      "Epoch [4/20], LR: 0.008, Step [368/1920], Train Loss: 0.6958, Valid Loss: 0.6881\n",
      "Epoch [4/20], LR: 0.008, Step [372/1920], Train Loss: 0.7026, Valid Loss: 0.6879\n",
      "Epoch [4/20], LR: 0.008, Step [376/1920], Train Loss: 0.7077, Valid Loss: 0.6877\n",
      "Epoch [4/20], LR: 0.008, Step [380/1920], Train Loss: 0.6859, Valid Loss: 0.6872\n",
      "Epoch [4/20], LR: 0.008, Step [384/1920], Train Loss: 0.6823, Valid Loss: 0.6867\n",
      "time elapsed in epoch: 2.02502179145813\n",
      "Epoch [5/20], LR: 0.013, Step [388/1920], Train Loss: 0.6683, Valid Loss: 0.6855\n",
      "Epoch [5/20], LR: 0.013, Step [392/1920], Train Loss: 0.6851, Valid Loss: 0.6849\n",
      "Epoch [5/20], LR: 0.013, Step [396/1920], Train Loss: 0.7025, Valid Loss: 0.6848\n",
      "Epoch [5/20], LR: 0.013, Step [400/1920], Train Loss: 0.6971, Valid Loss: 0.6847\n",
      "Epoch [5/20], LR: 0.013, Step [404/1920], Train Loss: 0.7017, Valid Loss: 0.6849\n",
      "Epoch [5/20], LR: 0.013, Step [408/1920], Train Loss: 0.6913, Valid Loss: 0.6846\n",
      "Epoch [5/20], LR: 0.013, Step [412/1920], Train Loss: 0.7151, Valid Loss: 0.6848\n",
      "Epoch [5/20], LR: 0.013, Step [416/1920], Train Loss: 0.7007, Valid Loss: 0.6850\n",
      "Epoch [5/20], LR: 0.013, Step [420/1920], Train Loss: 0.6860, Valid Loss: 0.6849\n",
      "Epoch [5/20], LR: 0.013, Step [424/1920], Train Loss: 0.6907, Valid Loss: 0.6846\n",
      "Epoch [5/20], LR: 0.013, Step [428/1920], Train Loss: 0.6933, Valid Loss: 0.6845\n",
      "Epoch [5/20], LR: 0.013, Step [432/1920], Train Loss: 0.6964, Valid Loss: 0.6846\n",
      "Epoch [5/20], LR: 0.013, Step [436/1920], Train Loss: 0.6967, Valid Loss: 0.6848\n",
      "Epoch [5/20], LR: 0.013, Step [440/1920], Train Loss: 0.6936, Valid Loss: 0.6847\n",
      "Epoch [5/20], LR: 0.013, Step [444/1920], Train Loss: 0.6836, Valid Loss: 0.6847\n",
      "Epoch [5/20], LR: 0.013, Step [448/1920], Train Loss: 0.6901, Valid Loss: 0.6848\n",
      "Epoch [5/20], LR: 0.013, Step [452/1920], Train Loss: 0.7046, Valid Loss: 0.6850\n",
      "Epoch [5/20], LR: 0.013, Step [456/1920], Train Loss: 0.6741, Valid Loss: 0.6847\n",
      "Epoch [5/20], LR: 0.013, Step [460/1920], Train Loss: 0.7034, Valid Loss: 0.6848\n",
      "Epoch [5/20], LR: 0.013, Step [464/1920], Train Loss: 0.7055, Valid Loss: 0.6849\n",
      "Epoch [5/20], LR: 0.013, Step [468/1920], Train Loss: 0.6941, Valid Loss: 0.6849\n",
      "Epoch [5/20], LR: 0.013, Step [472/1920], Train Loss: 0.6844, Valid Loss: 0.6846\n",
      "Epoch [5/20], LR: 0.013, Step [476/1920], Train Loss: 0.6876, Valid Loss: 0.6842\n",
      "Epoch [5/20], LR: 0.013, Step [480/1920], Train Loss: 0.6626, Valid Loss: 0.6836\n",
      "time elapsed in epoch: 2.0564393997192383\n",
      "Epoch [6/20], LR: 0.017, Step [484/1920], Train Loss: 0.6585, Valid Loss: 0.6826\n",
      "Epoch [6/20], LR: 0.017, Step [488/1920], Train Loss: 0.6685, Valid Loss: 0.6823\n",
      "Epoch [6/20], LR: 0.017, Step [492/1920], Train Loss: 0.6674, Valid Loss: 0.6822\n",
      "Epoch [6/20], LR: 0.017, Step [496/1920], Train Loss: 0.6899, Valid Loss: 0.6822\n",
      "Epoch [6/20], LR: 0.017, Step [500/1920], Train Loss: 0.7145, Valid Loss: 0.6825\n",
      "Epoch [6/20], LR: 0.017, Step [504/1920], Train Loss: 0.6838, Valid Loss: 0.6824\n",
      "Epoch [6/20], LR: 0.017, Step [508/1920], Train Loss: 0.6967, Valid Loss: 0.6825\n",
      "Epoch [6/20], LR: 0.017, Step [512/1920], Train Loss: 0.7013, Valid Loss: 0.6827\n",
      "Epoch [6/20], LR: 0.017, Step [516/1920], Train Loss: 0.6882, Valid Loss: 0.6826\n",
      "Epoch [6/20], LR: 0.017, Step [520/1920], Train Loss: 0.6924, Valid Loss: 0.6825\n",
      "Epoch [6/20], LR: 0.017, Step [524/1920], Train Loss: 0.6982, Valid Loss: 0.6825\n",
      "Epoch [6/20], LR: 0.017, Step [528/1920], Train Loss: 0.7047, Valid Loss: 0.6826\n",
      "Epoch [6/20], LR: 0.017, Step [532/1920], Train Loss: 0.7126, Valid Loss: 0.6829\n",
      "Epoch [6/20], LR: 0.017, Step [536/1920], Train Loss: 0.6938, Valid Loss: 0.6829\n",
      "Epoch [6/20], LR: 0.017, Step [540/1920], Train Loss: 0.7076, Valid Loss: 0.6830\n",
      "Epoch [6/20], LR: 0.017, Step [544/1920], Train Loss: 0.7100, Valid Loss: 0.6832\n",
      "Epoch [6/20], LR: 0.017, Step [548/1920], Train Loss: 0.7053, Valid Loss: 0.6834\n",
      "Epoch [6/20], LR: 0.017, Step [552/1920], Train Loss: 0.6791, Valid Loss: 0.6832\n",
      "Epoch [6/20], LR: 0.017, Step [556/1920], Train Loss: 0.6941, Valid Loss: 0.6833\n",
      "Epoch [6/20], LR: 0.017, Step [560/1920], Train Loss: 0.6950, Valid Loss: 0.6834\n",
      "Epoch [6/20], LR: 0.017, Step [564/1920], Train Loss: 0.6919, Valid Loss: 0.6835\n",
      "Epoch [6/20], LR: 0.017, Step [568/1920], Train Loss: 0.6872, Valid Loss: 0.6833\n",
      "Epoch [6/20], LR: 0.017, Step [572/1920], Train Loss: 0.6783, Valid Loss: 0.6830\n",
      "Epoch [6/20], LR: 0.017, Step [576/1920], Train Loss: 0.6543, Valid Loss: 0.6825\n",
      "time elapsed in epoch: 2.1607933044433594\n",
      "Epoch [7/20], LR: 0.021, Step [580/1920], Train Loss: 0.6430, Valid Loss: 0.6818\n",
      "Epoch [7/20], LR: 0.021, Step [584/1920], Train Loss: 0.6663, Valid Loss: 0.6816\n",
      "Epoch [7/20], LR: 0.021, Step [588/1920], Train Loss: 0.6773, Valid Loss: 0.6816\n",
      "Epoch [7/20], LR: 0.021, Step [592/1920], Train Loss: 0.6806, Valid Loss: 0.6816\n",
      "Epoch [7/20], LR: 0.021, Step [596/1920], Train Loss: 0.7126, Valid Loss: 0.6818\n",
      "Epoch [7/20], LR: 0.021, Step [600/1920], Train Loss: 0.6829, Valid Loss: 0.6818\n",
      "Epoch [7/20], LR: 0.021, Step [604/1920], Train Loss: 0.6925, Valid Loss: 0.6818\n",
      "Epoch [7/20], LR: 0.021, Step [608/1920], Train Loss: 0.7193, Valid Loss: 0.6821\n",
      "Epoch [7/20], LR: 0.021, Step [612/1920], Train Loss: 0.7016, Valid Loss: 0.6821\n",
      "Epoch [7/20], LR: 0.021, Step [616/1920], Train Loss: 0.6759, Valid Loss: 0.6819\n",
      "Epoch [7/20], LR: 0.021, Step [620/1920], Train Loss: 0.6879, Valid Loss: 0.6819\n",
      "Epoch [7/20], LR: 0.021, Step [624/1920], Train Loss: 0.7027, Valid Loss: 0.6821\n",
      "Epoch [7/20], LR: 0.021, Step [628/1920], Train Loss: 0.7107, Valid Loss: 0.6823\n",
      "Epoch [7/20], LR: 0.021, Step [632/1920], Train Loss: 0.6897, Valid Loss: 0.6823\n",
      "Epoch [7/20], LR: 0.021, Step [636/1920], Train Loss: 0.7042, Valid Loss: 0.6824\n",
      "Epoch [7/20], LR: 0.021, Step [640/1920], Train Loss: 0.6999, Valid Loss: 0.6825\n",
      "Epoch [7/20], LR: 0.021, Step [644/1920], Train Loss: 0.6977, Valid Loss: 0.6828\n",
      "Epoch [7/20], LR: 0.021, Step [648/1920], Train Loss: 0.6855, Valid Loss: 0.6827\n",
      "Epoch [7/20], LR: 0.021, Step [652/1920], Train Loss: 0.6850, Valid Loss: 0.6827\n",
      "Epoch [7/20], LR: 0.021, Step [656/1920], Train Loss: 0.7012, Valid Loss: 0.6828\n",
      "Epoch [7/20], LR: 0.021, Step [660/1920], Train Loss: 0.6932, Valid Loss: 0.6829\n",
      "Epoch [7/20], LR: 0.021, Step [664/1920], Train Loss: 0.6808, Valid Loss: 0.6827\n",
      "Epoch [7/20], LR: 0.021, Step [668/1920], Train Loss: 0.6682, Valid Loss: 0.6823\n",
      "Epoch [7/20], LR: 0.021, Step [672/1920], Train Loss: 0.6485, Valid Loss: 0.6819\n",
      "time elapsed in epoch: 2.0217297077178955\n",
      "Epoch [8/20], LR: 0.025, Step [676/1920], Train Loss: 0.6459, Valid Loss: 0.6815\n",
      "Epoch [8/20], LR: 0.025, Step [680/1920], Train Loss: 0.6598, Valid Loss: 0.6814\n",
      "Epoch [8/20], LR: 0.025, Step [684/1920], Train Loss: 0.6751, Valid Loss: 0.6814\n",
      "Epoch [8/20], LR: 0.025, Step [688/1920], Train Loss: 0.6852, Valid Loss: 0.6814\n",
      "Epoch [8/20], LR: 0.025, Step [692/1920], Train Loss: 0.7098, Valid Loss: 0.6815\n",
      "Epoch [8/20], LR: 0.025, Step [696/1920], Train Loss: 0.6738, Valid Loss: 0.6814\n",
      "Epoch [8/20], LR: 0.025, Step [700/1920], Train Loss: 0.7065, Valid Loss: 0.6815\n",
      "Epoch [8/20], LR: 0.025, Step [704/1920], Train Loss: 0.7042, Valid Loss: 0.6816\n",
      "Epoch [8/20], LR: 0.025, Step [708/1920], Train Loss: 0.6839, Valid Loss: 0.6816\n",
      "Epoch [8/20], LR: 0.025, Step [712/1920], Train Loss: 0.6757, Valid Loss: 0.6815\n",
      "Epoch [8/20], LR: 0.025, Step [716/1920], Train Loss: 0.6798, Valid Loss: 0.6814\n",
      "Epoch [8/20], LR: 0.025, Step [720/1920], Train Loss: 0.6992, Valid Loss: 0.6815\n",
      "Epoch [8/20], LR: 0.025, Step [724/1920], Train Loss: 0.7093, Valid Loss: 0.6816\n",
      "Epoch [8/20], LR: 0.025, Step [728/1920], Train Loss: 0.6954, Valid Loss: 0.6817\n",
      "Epoch [8/20], LR: 0.025, Step [732/1920], Train Loss: 0.6914, Valid Loss: 0.6818\n",
      "Epoch [8/20], LR: 0.025, Step [736/1920], Train Loss: 0.7097, Valid Loss: 0.6820\n",
      "Epoch [8/20], LR: 0.025, Step [740/1920], Train Loss: 0.7057, Valid Loss: 0.6824\n",
      "Epoch [8/20], LR: 0.025, Step [744/1920], Train Loss: 0.6804, Valid Loss: 0.6822\n",
      "Epoch [8/20], LR: 0.025, Step [748/1920], Train Loss: 0.6892, Valid Loss: 0.6822\n",
      "Epoch [8/20], LR: 0.025, Step [752/1920], Train Loss: 0.6956, Valid Loss: 0.6824\n",
      "Epoch [8/20], LR: 0.025, Step [756/1920], Train Loss: 0.6909, Valid Loss: 0.6824\n",
      "Epoch [8/20], LR: 0.025, Step [760/1920], Train Loss: 0.6906, Valid Loss: 0.6823\n",
      "Epoch [8/20], LR: 0.025, Step [764/1920], Train Loss: 0.6576, Valid Loss: 0.6819\n",
      "Epoch [8/20], LR: 0.025, Step [768/1920], Train Loss: 0.6439, Valid Loss: 0.6814\n",
      "time elapsed in epoch: 2.137728452682495\n",
      "Epoch [9/20], LR: 0.029, Step [772/1920], Train Loss: 0.6421, Valid Loss: 0.6811\n",
      "Epoch [9/20], LR: 0.029, Step [776/1920], Train Loss: 0.6518, Valid Loss: 0.6811\n",
      "Epoch [9/20], LR: 0.029, Step [780/1920], Train Loss: 0.6793, Valid Loss: 0.6810\n",
      "Epoch [9/20], LR: 0.029, Step [784/1920], Train Loss: 0.6896, Valid Loss: 0.6810\n",
      "Epoch [9/20], LR: 0.029, Step [788/1920], Train Loss: 0.7101, Valid Loss: 0.6810\n",
      "Epoch [9/20], LR: 0.029, Step [792/1920], Train Loss: 0.6733, Valid Loss: 0.6810\n",
      "Epoch [9/20], LR: 0.029, Step [796/1920], Train Loss: 0.6991, Valid Loss: 0.6810\n",
      "Epoch [9/20], LR: 0.029, Step [800/1920], Train Loss: 0.7032, Valid Loss: 0.6811\n",
      "Epoch [9/20], LR: 0.029, Step [804/1920], Train Loss: 0.6812, Valid Loss: 0.6811\n",
      "Epoch [9/20], LR: 0.029, Step [808/1920], Train Loss: 0.6759, Valid Loss: 0.6811\n",
      "Epoch [9/20], LR: 0.029, Step [812/1920], Train Loss: 0.6827, Valid Loss: 0.6811\n",
      "Epoch [9/20], LR: 0.029, Step [816/1920], Train Loss: 0.7024, Valid Loss: 0.6812\n",
      "Epoch [9/20], LR: 0.029, Step [820/1920], Train Loss: 0.7040, Valid Loss: 0.6813\n",
      "Epoch [9/20], LR: 0.029, Step [824/1920], Train Loss: 0.6946, Valid Loss: 0.6814\n",
      "Epoch [9/20], LR: 0.029, Step [828/1920], Train Loss: 0.6903, Valid Loss: 0.6815\n",
      "Epoch [9/20], LR: 0.029, Step [832/1920], Train Loss: 0.7016, Valid Loss: 0.6817\n",
      "Epoch [9/20], LR: 0.029, Step [836/1920], Train Loss: 0.7007, Valid Loss: 0.6819\n",
      "Epoch [9/20], LR: 0.029, Step [840/1920], Train Loss: 0.6812, Valid Loss: 0.6818\n",
      "Epoch [9/20], LR: 0.029, Step [844/1920], Train Loss: 0.6857, Valid Loss: 0.6818\n",
      "Epoch [9/20], LR: 0.029, Step [848/1920], Train Loss: 0.6931, Valid Loss: 0.6819\n",
      "Epoch [9/20], LR: 0.029, Step [852/1920], Train Loss: 0.6891, Valid Loss: 0.6820\n",
      "Epoch [9/20], LR: 0.029, Step [856/1920], Train Loss: 0.6771, Valid Loss: 0.6818\n",
      "Epoch [9/20], LR: 0.029, Step [860/1920], Train Loss: 0.6677, Valid Loss: 0.6815\n",
      "Epoch [9/20], LR: 0.029, Step [864/1920], Train Loss: 0.6405, Valid Loss: 0.6811\n",
      "time elapsed in epoch: 2.0551605224609375\n",
      "Epoch [10/20], LR: 0.033, Step [868/1920], Train Loss: 0.6244, Valid Loss: 0.6811\n",
      "Epoch [10/20], LR: 0.033, Step [872/1920], Train Loss: 0.6572, Valid Loss: 0.6813\n",
      "Epoch [10/20], LR: 0.033, Step [876/1920], Train Loss: 0.6771, Valid Loss: 0.6813\n",
      "Epoch [10/20], LR: 0.033, Step [880/1920], Train Loss: 0.6852, Valid Loss: 0.6812\n",
      "Epoch [10/20], LR: 0.033, Step [884/1920], Train Loss: 0.7111, Valid Loss: 0.6810\n",
      "Epoch [10/20], LR: 0.033, Step [888/1920], Train Loss: 0.6740, Valid Loss: 0.6810\n",
      "Epoch [10/20], LR: 0.033, Step [892/1920], Train Loss: 0.6939, Valid Loss: 0.6809\n",
      "Epoch [10/20], LR: 0.033, Step [896/1920], Train Loss: 0.7066, Valid Loss: 0.6809\n",
      "Epoch [10/20], LR: 0.033, Step [900/1920], Train Loss: 0.6868, Valid Loss: 0.6809\n",
      "Epoch [10/20], LR: 0.033, Step [904/1920], Train Loss: 0.6724, Valid Loss: 0.6808\n",
      "Epoch [10/20], LR: 0.033, Step [908/1920], Train Loss: 0.6864, Valid Loss: 0.6808\n",
      "Epoch [10/20], LR: 0.033, Step [912/1920], Train Loss: 0.7039, Valid Loss: 0.6809\n",
      "Epoch [10/20], LR: 0.033, Step [916/1920], Train Loss: 0.7031, Valid Loss: 0.6811\n",
      "Epoch [10/20], LR: 0.033, Step [920/1920], Train Loss: 0.6916, Valid Loss: 0.6812\n",
      "Epoch [10/20], LR: 0.033, Step [924/1920], Train Loss: 0.7034, Valid Loss: 0.6813\n",
      "Epoch [10/20], LR: 0.033, Step [928/1920], Train Loss: 0.6963, Valid Loss: 0.6815\n",
      "Epoch [10/20], LR: 0.033, Step [932/1920], Train Loss: 0.7120, Valid Loss: 0.6818\n",
      "Epoch [10/20], LR: 0.033, Step [936/1920], Train Loss: 0.6822, Valid Loss: 0.6818\n",
      "Epoch [10/20], LR: 0.033, Step [940/1920], Train Loss: 0.6821, Valid Loss: 0.6818\n",
      "Epoch [10/20], LR: 0.033, Step [944/1920], Train Loss: 0.6917, Valid Loss: 0.6819\n",
      "Epoch [10/20], LR: 0.033, Step [948/1920], Train Loss: 0.6959, Valid Loss: 0.6820\n",
      "Epoch [10/20], LR: 0.033, Step [952/1920], Train Loss: 0.6736, Valid Loss: 0.6817\n",
      "Epoch [10/20], LR: 0.033, Step [956/1920], Train Loss: 0.6634, Valid Loss: 0.6813\n",
      "Epoch [10/20], LR: 0.033, Step [960/1920], Train Loss: 0.6403, Valid Loss: 0.6809\n",
      "time elapsed in epoch: 2.0522778034210205\n",
      "Epoch [11/20], LR: 0.038, Step [964/1920], Train Loss: 0.6219, Valid Loss: 0.6811\n",
      "Epoch [11/20], LR: 0.038, Step [968/1920], Train Loss: 0.6450, Valid Loss: 0.6816\n",
      "Epoch [11/20], LR: 0.038, Step [972/1920], Train Loss: 0.6830, Valid Loss: 0.6814\n",
      "Epoch [11/20], LR: 0.038, Step [976/1920], Train Loss: 0.6900, Valid Loss: 0.6814\n",
      "Epoch [11/20], LR: 0.038, Step [980/1920], Train Loss: 0.7035, Valid Loss: 0.6810\n",
      "Epoch [11/20], LR: 0.038, Step [984/1920], Train Loss: 0.6876, Valid Loss: 0.6808\n",
      "Epoch [11/20], LR: 0.038, Step [988/1920], Train Loss: 0.6994, Valid Loss: 0.6807\n",
      "Epoch [11/20], LR: 0.038, Step [992/1920], Train Loss: 0.7031, Valid Loss: 0.6807\n",
      "Epoch [11/20], LR: 0.038, Step [996/1920], Train Loss: 0.6850, Valid Loss: 0.6807\n",
      "Epoch [11/20], LR: 0.038, Step [1000/1920], Train Loss: 0.6720, Valid Loss: 0.6807\n",
      "Epoch [11/20], LR: 0.038, Step [1004/1920], Train Loss: 0.6818, Valid Loss: 0.6807\n",
      "Epoch [11/20], LR: 0.038, Step [1008/1920], Train Loss: 0.7105, Valid Loss: 0.6807\n",
      "Epoch [11/20], LR: 0.038, Step [1012/1920], Train Loss: 0.7069, Valid Loss: 0.6808\n",
      "Epoch [11/20], LR: 0.038, Step [1016/1920], Train Loss: 0.6880, Valid Loss: 0.6808\n",
      "Epoch [11/20], LR: 0.038, Step [1020/1920], Train Loss: 0.6959, Valid Loss: 0.6809\n",
      "Epoch [11/20], LR: 0.038, Step [1024/1920], Train Loss: 0.6968, Valid Loss: 0.6810\n",
      "Epoch [11/20], LR: 0.038, Step [1028/1920], Train Loss: 0.7092, Valid Loss: 0.6814\n",
      "Epoch [11/20], LR: 0.038, Step [1032/1920], Train Loss: 0.6850, Valid Loss: 0.6812\n",
      "Epoch [11/20], LR: 0.038, Step [1036/1920], Train Loss: 0.6927, Valid Loss: 0.6813\n",
      "Epoch [11/20], LR: 0.038, Step [1040/1920], Train Loss: 0.6968, Valid Loss: 0.6814\n",
      "Epoch [11/20], LR: 0.038, Step [1044/1920], Train Loss: 0.6986, Valid Loss: 0.6815\n",
      "Epoch [11/20], LR: 0.038, Step [1048/1920], Train Loss: 0.6772, Valid Loss: 0.6812\n",
      "Epoch [11/20], LR: 0.038, Step [1052/1920], Train Loss: 0.6614, Valid Loss: 0.6809\n",
      "Epoch [11/20], LR: 0.038, Step [1056/1920], Train Loss: 0.6396, Valid Loss: 0.6805\n",
      "time elapsed in epoch: 2.079184055328369\n",
      "Epoch [12/20], LR: 0.042, Step [1060/1920], Train Loss: 0.6183, Valid Loss: 0.6806\n",
      "Epoch [12/20], LR: 0.042, Step [1064/1920], Train Loss: 0.6489, Valid Loss: 0.6812\n",
      "Epoch [12/20], LR: 0.042, Step [1068/1920], Train Loss: 0.6753, Valid Loss: 0.6812\n",
      "Epoch [12/20], LR: 0.042, Step [1072/1920], Train Loss: 0.6879, Valid Loss: 0.6810\n",
      "Epoch [12/20], LR: 0.042, Step [1076/1920], Train Loss: 0.7041, Valid Loss: 0.6807\n",
      "Epoch [12/20], LR: 0.042, Step [1080/1920], Train Loss: 0.6766, Valid Loss: 0.6806\n",
      "Epoch [12/20], LR: 0.042, Step [1084/1920], Train Loss: 0.7067, Valid Loss: 0.6805\n",
      "Epoch [12/20], LR: 0.042, Step [1088/1920], Train Loss: 0.7021, Valid Loss: 0.6803\n",
      "Epoch [12/20], LR: 0.042, Step [1092/1920], Train Loss: 0.6855, Valid Loss: 0.6802\n",
      "Epoch [12/20], LR: 0.042, Step [1096/1920], Train Loss: 0.6678, Valid Loss: 0.6801\n",
      "Epoch [12/20], LR: 0.042, Step [1100/1920], Train Loss: 0.6792, Valid Loss: 0.6801\n",
      "Epoch [12/20], LR: 0.042, Step [1104/1920], Train Loss: 0.7022, Valid Loss: 0.6802\n",
      "Epoch [12/20], LR: 0.042, Step [1108/1920], Train Loss: 0.7081, Valid Loss: 0.6803\n",
      "Epoch [12/20], LR: 0.042, Step [1112/1920], Train Loss: 0.6901, Valid Loss: 0.6804\n",
      "Epoch [12/20], LR: 0.042, Step [1116/1920], Train Loss: 0.6973, Valid Loss: 0.6806\n",
      "Epoch [12/20], LR: 0.042, Step [1120/1920], Train Loss: 0.6969, Valid Loss: 0.6808\n",
      "Epoch [12/20], LR: 0.042, Step [1124/1920], Train Loss: 0.7006, Valid Loss: 0.6813\n",
      "Epoch [12/20], LR: 0.042, Step [1128/1920], Train Loss: 0.6862, Valid Loss: 0.6810\n",
      "Epoch [12/20], LR: 0.042, Step [1132/1920], Train Loss: 0.6875, Valid Loss: 0.6811\n",
      "Epoch [12/20], LR: 0.042, Step [1136/1920], Train Loss: 0.6912, Valid Loss: 0.6814\n",
      "Epoch [12/20], LR: 0.042, Step [1140/1920], Train Loss: 0.6967, Valid Loss: 0.6815\n",
      "Epoch [12/20], LR: 0.042, Step [1144/1920], Train Loss: 0.6727, Valid Loss: 0.6811\n",
      "Epoch [12/20], LR: 0.042, Step [1148/1920], Train Loss: 0.6559, Valid Loss: 0.6804\n",
      "Epoch [12/20], LR: 0.042, Step [1152/1920], Train Loss: 0.6408, Valid Loss: 0.6799\n",
      "time elapsed in epoch: 2.063098907470703\n",
      "Epoch [13/20], LR: 0.046, Step [1156/1920], Train Loss: 0.6113, Valid Loss: 0.6802\n",
      "Epoch [13/20], LR: 0.046, Step [1160/1920], Train Loss: 0.6482, Valid Loss: 0.6805\n",
      "Epoch [13/20], LR: 0.046, Step [1164/1920], Train Loss: 0.6778, Valid Loss: 0.6803\n",
      "Epoch [13/20], LR: 0.046, Step [1168/1920], Train Loss: 0.6848, Valid Loss: 0.6801\n",
      "Epoch [13/20], LR: 0.046, Step [1172/1920], Train Loss: 0.7082, Valid Loss: 0.6798\n",
      "Epoch [13/20], LR: 0.046, Step [1176/1920], Train Loss: 0.6752, Valid Loss: 0.6798\n",
      "Epoch [13/20], LR: 0.046, Step [1180/1920], Train Loss: 0.7041, Valid Loss: 0.6798\n",
      "Epoch [13/20], LR: 0.046, Step [1184/1920], Train Loss: 0.7016, Valid Loss: 0.6798\n",
      "Epoch [13/20], LR: 0.046, Step [1188/1920], Train Loss: 0.6884, Valid Loss: 0.6798\n",
      "Epoch [13/20], LR: 0.046, Step [1192/1920], Train Loss: 0.6718, Valid Loss: 0.6798\n",
      "Epoch [13/20], LR: 0.046, Step [1196/1920], Train Loss: 0.6833, Valid Loss: 0.6798\n",
      "Epoch [13/20], LR: 0.046, Step [1200/1920], Train Loss: 0.6997, Valid Loss: 0.6798\n",
      "Epoch [13/20], LR: 0.046, Step [1204/1920], Train Loss: 0.7017, Valid Loss: 0.6800\n",
      "Epoch [13/20], LR: 0.046, Step [1208/1920], Train Loss: 0.6868, Valid Loss: 0.6799\n",
      "Epoch [13/20], LR: 0.046, Step [1212/1920], Train Loss: 0.6968, Valid Loss: 0.6800\n",
      "Epoch [13/20], LR: 0.046, Step [1216/1920], Train Loss: 0.6901, Valid Loss: 0.6801\n",
      "Epoch [13/20], LR: 0.046, Step [1220/1920], Train Loss: 0.7009, Valid Loss: 0.6805\n",
      "Epoch [13/20], LR: 0.046, Step [1224/1920], Train Loss: 0.6902, Valid Loss: 0.6804\n",
      "Epoch [13/20], LR: 0.046, Step [1228/1920], Train Loss: 0.6865, Valid Loss: 0.6804\n",
      "Epoch [13/20], LR: 0.046, Step [1232/1920], Train Loss: 0.6921, Valid Loss: 0.6806\n",
      "Epoch [13/20], LR: 0.046, Step [1236/1920], Train Loss: 0.6988, Valid Loss: 0.6808\n",
      "Epoch [13/20], LR: 0.046, Step [1240/1920], Train Loss: 0.6785, Valid Loss: 0.6806\n",
      "Epoch [13/20], LR: 0.046, Step [1244/1920], Train Loss: 0.6628, Valid Loss: 0.6801\n",
      "Epoch [13/20], LR: 0.046, Step [1248/1920], Train Loss: 0.6260, Valid Loss: 0.6798\n",
      "time elapsed in epoch: 2.2072861194610596\n",
      "Epoch [14/20], LR: 0.050, Step [1252/1920], Train Loss: 0.6109, Valid Loss: 0.6805\n",
      "Epoch [14/20], LR: 0.050, Step [1256/1920], Train Loss: 0.6409, Valid Loss: 0.6809\n",
      "Epoch [14/20], LR: 0.050, Step [1260/1920], Train Loss: 0.6733, Valid Loss: 0.6809\n",
      "Epoch [14/20], LR: 0.050, Step [1264/1920], Train Loss: 0.6865, Valid Loss: 0.6806\n",
      "Epoch [14/20], LR: 0.050, Step [1268/1920], Train Loss: 0.7083, Valid Loss: 0.6802\n",
      "Epoch [14/20], LR: 0.050, Step [1272/1920], Train Loss: 0.6769, Valid Loss: 0.6802\n",
      "Epoch [14/20], LR: 0.050, Step [1276/1920], Train Loss: 0.7038, Valid Loss: 0.6799\n",
      "Epoch [14/20], LR: 0.050, Step [1280/1920], Train Loss: 0.7062, Valid Loss: 0.6797\n",
      "Epoch [14/20], LR: 0.050, Step [1284/1920], Train Loss: 0.6853, Valid Loss: 0.6796\n",
      "Epoch [14/20], LR: 0.050, Step [1288/1920], Train Loss: 0.6685, Valid Loss: 0.6796\n",
      "Epoch [14/20], LR: 0.050, Step [1292/1920], Train Loss: 0.6769, Valid Loss: 0.6796\n",
      "Epoch [14/20], LR: 0.050, Step [1296/1920], Train Loss: 0.6963, Valid Loss: 0.6795\n",
      "Epoch [14/20], LR: 0.050, Step [1300/1920], Train Loss: 0.7046, Valid Loss: 0.6797\n",
      "Epoch [14/20], LR: 0.050, Step [1304/1920], Train Loss: 0.6940, Valid Loss: 0.6798\n",
      "Epoch [14/20], LR: 0.050, Step [1308/1920], Train Loss: 0.6983, Valid Loss: 0.6800\n",
      "Epoch [14/20], LR: 0.050, Step [1312/1920], Train Loss: 0.6938, Valid Loss: 0.6801\n",
      "Epoch [14/20], LR: 0.050, Step [1316/1920], Train Loss: 0.7009, Valid Loss: 0.6804\n",
      "Epoch [14/20], LR: 0.050, Step [1320/1920], Train Loss: 0.6861, Valid Loss: 0.6802\n",
      "Epoch [14/20], LR: 0.050, Step [1324/1920], Train Loss: 0.6930, Valid Loss: 0.6803\n",
      "Epoch [14/20], LR: 0.050, Step [1328/1920], Train Loss: 0.6975, Valid Loss: 0.6804\n",
      "Epoch [14/20], LR: 0.050, Step [1332/1920], Train Loss: 0.6980, Valid Loss: 0.6806\n",
      "Epoch [14/20], LR: 0.050, Step [1336/1920], Train Loss: 0.6816, Valid Loss: 0.6804\n",
      "Epoch [14/20], LR: 0.050, Step [1340/1920], Train Loss: 0.6679, Valid Loss: 0.6801\n",
      "Epoch [14/20], LR: 0.050, Step [1344/1920], Train Loss: 0.6322, Valid Loss: 0.6799\n",
      "time elapsed in epoch: 1.9826021194458008\n",
      "Epoch [15/20], LR: 0.054, Step [1348/1920], Train Loss: 0.6094, Valid Loss: 0.6809\n",
      "Epoch [15/20], LR: 0.054, Step [1352/1920], Train Loss: 0.6429, Valid Loss: 0.6815\n",
      "Epoch [15/20], LR: 0.054, Step [1356/1920], Train Loss: 0.6796, Valid Loss: 0.6812\n",
      "Epoch [15/20], LR: 0.054, Step [1360/1920], Train Loss: 0.6888, Valid Loss: 0.6812\n",
      "Epoch [15/20], LR: 0.054, Step [1364/1920], Train Loss: 0.7160, Valid Loss: 0.6805\n",
      "Epoch [15/20], LR: 0.054, Step [1368/1920], Train Loss: 0.6768, Valid Loss: 0.6802\n",
      "Epoch [15/20], LR: 0.054, Step [1372/1920], Train Loss: 0.6978, Valid Loss: 0.6801\n",
      "Epoch [15/20], LR: 0.054, Step [1376/1920], Train Loss: 0.7034, Valid Loss: 0.6800\n",
      "Epoch [15/20], LR: 0.054, Step [1380/1920], Train Loss: 0.6874, Valid Loss: 0.6800\n",
      "Epoch [15/20], LR: 0.054, Step [1384/1920], Train Loss: 0.6647, Valid Loss: 0.6799\n",
      "Epoch [15/20], LR: 0.054, Step [1388/1920], Train Loss: 0.6801, Valid Loss: 0.6799\n",
      "Epoch [15/20], LR: 0.054, Step [1392/1920], Train Loss: 0.7013, Valid Loss: 0.6797\n",
      "Epoch [15/20], LR: 0.054, Step [1396/1920], Train Loss: 0.7034, Valid Loss: 0.6799\n",
      "Epoch [15/20], LR: 0.054, Step [1400/1920], Train Loss: 0.6878, Valid Loss: 0.6799\n",
      "Epoch [15/20], LR: 0.054, Step [1404/1920], Train Loss: 0.6992, Valid Loss: 0.6801\n",
      "Epoch [15/20], LR: 0.054, Step [1408/1920], Train Loss: 0.6975, Valid Loss: 0.6804\n",
      "Epoch [15/20], LR: 0.054, Step [1412/1920], Train Loss: 0.7018, Valid Loss: 0.6808\n",
      "Epoch [15/20], LR: 0.054, Step [1416/1920], Train Loss: 0.6777, Valid Loss: 0.6803\n",
      "Epoch [15/20], LR: 0.054, Step [1420/1920], Train Loss: 0.6849, Valid Loss: 0.6804\n",
      "Epoch [15/20], LR: 0.054, Step [1424/1920], Train Loss: 0.6909, Valid Loss: 0.6806\n",
      "Epoch [15/20], LR: 0.054, Step [1428/1920], Train Loss: 0.6923, Valid Loss: 0.6807\n",
      "Epoch [15/20], LR: 0.054, Step [1432/1920], Train Loss: 0.6759, Valid Loss: 0.6803\n",
      "Epoch [15/20], LR: 0.054, Step [1436/1920], Train Loss: 0.6545, Valid Loss: 0.6799\n",
      "Epoch [15/20], LR: 0.054, Step [1440/1920], Train Loss: 0.6327, Valid Loss: 0.6794\n",
      "time elapsed in epoch: 1.828176498413086\n",
      "Epoch [16/20], LR: 0.058, Step [1444/1920], Train Loss: 0.6122, Valid Loss: 0.6801\n",
      "Epoch [16/20], LR: 0.058, Step [1448/1920], Train Loss: 0.6530, Valid Loss: 0.6807\n",
      "Epoch [16/20], LR: 0.058, Step [1452/1920], Train Loss: 0.6780, Valid Loss: 0.6806\n",
      "Epoch [16/20], LR: 0.058, Step [1456/1920], Train Loss: 0.6801, Valid Loss: 0.6804\n",
      "Epoch [16/20], LR: 0.058, Step [1460/1920], Train Loss: 0.7113, Valid Loss: 0.6796\n",
      "Epoch [16/20], LR: 0.058, Step [1464/1920], Train Loss: 0.6765, Valid Loss: 0.6796\n",
      "Epoch [16/20], LR: 0.058, Step [1468/1920], Train Loss: 0.7000, Valid Loss: 0.6795\n",
      "Epoch [16/20], LR: 0.058, Step [1472/1920], Train Loss: 0.6959, Valid Loss: 0.6792\n",
      "Epoch [16/20], LR: 0.058, Step [1476/1920], Train Loss: 0.6798, Valid Loss: 0.6791\n",
      "Epoch [16/20], LR: 0.058, Step [1480/1920], Train Loss: 0.6628, Valid Loss: 0.6791\n",
      "Epoch [16/20], LR: 0.058, Step [1484/1920], Train Loss: 0.6807, Valid Loss: 0.6792\n",
      "Epoch [16/20], LR: 0.058, Step [1488/1920], Train Loss: 0.6992, Valid Loss: 0.6792\n",
      "Epoch [16/20], LR: 0.058, Step [1492/1920], Train Loss: 0.6999, Valid Loss: 0.6794\n",
      "Epoch [16/20], LR: 0.058, Step [1496/1920], Train Loss: 0.6879, Valid Loss: 0.6795\n",
      "Epoch [16/20], LR: 0.058, Step [1500/1920], Train Loss: 0.6943, Valid Loss: 0.6797\n",
      "Epoch [16/20], LR: 0.058, Step [1504/1920], Train Loss: 0.6974, Valid Loss: 0.6799\n",
      "Epoch [16/20], LR: 0.058, Step [1508/1920], Train Loss: 0.7064, Valid Loss: 0.6806\n",
      "Epoch [16/20], LR: 0.058, Step [1512/1920], Train Loss: 0.6784, Valid Loss: 0.6801\n",
      "Epoch [16/20], LR: 0.058, Step [1516/1920], Train Loss: 0.6869, Valid Loss: 0.6801\n",
      "Epoch [16/20], LR: 0.058, Step [1520/1920], Train Loss: 0.6846, Valid Loss: 0.6805\n",
      "Epoch [16/20], LR: 0.058, Step [1524/1920], Train Loss: 0.6980, Valid Loss: 0.6804\n",
      "Epoch [16/20], LR: 0.058, Step [1528/1920], Train Loss: 0.6796, Valid Loss: 0.6800\n",
      "Epoch [16/20], LR: 0.058, Step [1532/1920], Train Loss: 0.6653, Valid Loss: 0.6794\n",
      "Epoch [16/20], LR: 0.058, Step [1536/1920], Train Loss: 0.6316, Valid Loss: 0.6790\n",
      "time elapsed in epoch: 2.0957701206207275\n",
      "Epoch [17/20], LR: 0.063, Step [1540/1920], Train Loss: 0.6079, Valid Loss: 0.6801\n",
      "Epoch [17/20], LR: 0.063, Step [1544/1920], Train Loss: 0.6416, Valid Loss: 0.6811\n",
      "Epoch [17/20], LR: 0.063, Step [1548/1920], Train Loss: 0.6735, Valid Loss: 0.6808\n",
      "Epoch [17/20], LR: 0.063, Step [1552/1920], Train Loss: 0.6869, Valid Loss: 0.6802\n",
      "Epoch [17/20], LR: 0.063, Step [1556/1920], Train Loss: 0.7130, Valid Loss: 0.6794\n",
      "Epoch [17/20], LR: 0.063, Step [1560/1920], Train Loss: 0.6806, Valid Loss: 0.6793\n",
      "Epoch [17/20], LR: 0.063, Step [1564/1920], Train Loss: 0.6999, Valid Loss: 0.6790\n",
      "Epoch [17/20], LR: 0.063, Step [1568/1920], Train Loss: 0.7033, Valid Loss: 0.6788\n",
      "Epoch [17/20], LR: 0.063, Step [1572/1920], Train Loss: 0.6835, Valid Loss: 0.6789\n",
      "Epoch [17/20], LR: 0.063, Step [1576/1920], Train Loss: 0.6694, Valid Loss: 0.6790\n",
      "Epoch [17/20], LR: 0.063, Step [1580/1920], Train Loss: 0.6811, Valid Loss: 0.6790\n",
      "Epoch [17/20], LR: 0.063, Step [1584/1920], Train Loss: 0.7029, Valid Loss: 0.6790\n",
      "Epoch [17/20], LR: 0.063, Step [1588/1920], Train Loss: 0.7048, Valid Loss: 0.6790\n",
      "Epoch [17/20], LR: 0.063, Step [1592/1920], Train Loss: 0.6850, Valid Loss: 0.6790\n",
      "Epoch [17/20], LR: 0.063, Step [1596/1920], Train Loss: 0.6882, Valid Loss: 0.6790\n",
      "Epoch [17/20], LR: 0.063, Step [1600/1920], Train Loss: 0.6984, Valid Loss: 0.6793\n",
      "Epoch [17/20], LR: 0.063, Step [1604/1920], Train Loss: 0.7109, Valid Loss: 0.6800\n",
      "Epoch [17/20], LR: 0.063, Step [1608/1920], Train Loss: 0.6805, Valid Loss: 0.6796\n",
      "Epoch [17/20], LR: 0.063, Step [1612/1920], Train Loss: 0.6897, Valid Loss: 0.6797\n",
      "Epoch [17/20], LR: 0.063, Step [1616/1920], Train Loss: 0.6907, Valid Loss: 0.6799\n",
      "Epoch [17/20], LR: 0.063, Step [1620/1920], Train Loss: 0.6893, Valid Loss: 0.6801\n",
      "Epoch [17/20], LR: 0.063, Step [1624/1920], Train Loss: 0.6791, Valid Loss: 0.6794\n",
      "Epoch [17/20], LR: 0.063, Step [1628/1920], Train Loss: 0.6559, Valid Loss: 0.6787\n",
      "Epoch [17/20], LR: 0.063, Step [1632/1920], Train Loss: 0.6119, Valid Loss: 0.6781\n",
      "time elapsed in epoch: 2.136263608932495\n",
      "Epoch [18/20], LR: 0.067, Step [1636/1920], Train Loss: 0.6100, Valid Loss: 0.6795\n",
      "Epoch [18/20], LR: 0.067, Step [1640/1920], Train Loss: 0.6359, Valid Loss: 0.6805\n",
      "Epoch [18/20], LR: 0.067, Step [1644/1920], Train Loss: 0.6732, Valid Loss: 0.6803\n",
      "Epoch [18/20], LR: 0.067, Step [1648/1920], Train Loss: 0.6811, Valid Loss: 0.6797\n",
      "Epoch [18/20], LR: 0.067, Step [1652/1920], Train Loss: 0.7187, Valid Loss: 0.6789\n",
      "Epoch [18/20], LR: 0.067, Step [1656/1920], Train Loss: 0.6735, Valid Loss: 0.6787\n",
      "Epoch [18/20], LR: 0.067, Step [1660/1920], Train Loss: 0.6990, Valid Loss: 0.6782\n",
      "Epoch [18/20], LR: 0.067, Step [1664/1920], Train Loss: 0.6960, Valid Loss: 0.6781\n",
      "Epoch [18/20], LR: 0.067, Step [1668/1920], Train Loss: 0.6933, Valid Loss: 0.6783\n",
      "Epoch [18/20], LR: 0.067, Step [1672/1920], Train Loss: 0.6653, Valid Loss: 0.6782\n",
      "Epoch [18/20], LR: 0.067, Step [1676/1920], Train Loss: 0.6829, Valid Loss: 0.6783\n",
      "Epoch [18/20], LR: 0.067, Step [1680/1920], Train Loss: 0.6991, Valid Loss: 0.6781\n",
      "Epoch [18/20], LR: 0.067, Step [1684/1920], Train Loss: 0.7073, Valid Loss: 0.6784\n",
      "Epoch [18/20], LR: 0.067, Step [1688/1920], Train Loss: 0.6841, Valid Loss: 0.6784\n",
      "Epoch [18/20], LR: 0.067, Step [1692/1920], Train Loss: 0.6922, Valid Loss: 0.6785\n",
      "Epoch [18/20], LR: 0.067, Step [1696/1920], Train Loss: 0.7031, Valid Loss: 0.6789\n",
      "Epoch [18/20], LR: 0.067, Step [1700/1920], Train Loss: 0.7089, Valid Loss: 0.6797\n",
      "Epoch [18/20], LR: 0.067, Step [1704/1920], Train Loss: 0.6821, Valid Loss: 0.6793\n",
      "Epoch [18/20], LR: 0.067, Step [1708/1920], Train Loss: 0.6830, Valid Loss: 0.6793\n",
      "Epoch [18/20], LR: 0.067, Step [1712/1920], Train Loss: 0.6969, Valid Loss: 0.6796\n",
      "Epoch [18/20], LR: 0.067, Step [1716/1920], Train Loss: 0.6911, Valid Loss: 0.6798\n",
      "Epoch [18/20], LR: 0.067, Step [1720/1920], Train Loss: 0.6819, Valid Loss: 0.6796\n",
      "Epoch [18/20], LR: 0.067, Step [1724/1920], Train Loss: 0.6665, Valid Loss: 0.6789\n",
      "Epoch [18/20], LR: 0.067, Step [1728/1920], Train Loss: 0.6305, Valid Loss: 0.6787\n",
      "time elapsed in epoch: 1.911574363708496\n",
      "Epoch [19/20], LR: 0.071, Step [1732/1920], Train Loss: 0.6054, Valid Loss: 0.6802\n",
      "Epoch [19/20], LR: 0.071, Step [1736/1920], Train Loss: 0.6337, Valid Loss: 0.6808\n",
      "Epoch [19/20], LR: 0.071, Step [1740/1920], Train Loss: 0.6756, Valid Loss: 0.6805\n",
      "Epoch [19/20], LR: 0.071, Step [1744/1920], Train Loss: 0.6869, Valid Loss: 0.6800\n",
      "Epoch [19/20], LR: 0.071, Step [1748/1920], Train Loss: 0.7174, Valid Loss: 0.6790\n",
      "Epoch [19/20], LR: 0.071, Step [1752/1920], Train Loss: 0.6767, Valid Loss: 0.6790\n",
      "Epoch [19/20], LR: 0.071, Step [1756/1920], Train Loss: 0.6968, Valid Loss: 0.6784\n",
      "Epoch [19/20], LR: 0.071, Step [1760/1920], Train Loss: 0.7030, Valid Loss: 0.6782\n",
      "Epoch [19/20], LR: 0.071, Step [1764/1920], Train Loss: 0.6884, Valid Loss: 0.6783\n",
      "Epoch [19/20], LR: 0.071, Step [1768/1920], Train Loss: 0.6707, Valid Loss: 0.6783\n",
      "Epoch [19/20], LR: 0.071, Step [1772/1920], Train Loss: 0.6762, Valid Loss: 0.6785\n",
      "Epoch [19/20], LR: 0.071, Step [1776/1920], Train Loss: 0.7017, Valid Loss: 0.6783\n",
      "Epoch [19/20], LR: 0.071, Step [1780/1920], Train Loss: 0.7036, Valid Loss: 0.6785\n",
      "Epoch [19/20], LR: 0.071, Step [1784/1920], Train Loss: 0.6895, Valid Loss: 0.6785\n",
      "Epoch [19/20], LR: 0.071, Step [1788/1920], Train Loss: 0.6922, Valid Loss: 0.6785\n",
      "Epoch [19/20], LR: 0.071, Step [1792/1920], Train Loss: 0.6935, Valid Loss: 0.6789\n",
      "Epoch [19/20], LR: 0.071, Step [1796/1920], Train Loss: 0.7024, Valid Loss: 0.6796\n",
      "Epoch [19/20], LR: 0.071, Step [1800/1920], Train Loss: 0.6734, Valid Loss: 0.6792\n",
      "Epoch [19/20], LR: 0.071, Step [1804/1920], Train Loss: 0.6898, Valid Loss: 0.6791\n",
      "Epoch [19/20], LR: 0.071, Step [1808/1920], Train Loss: 0.6909, Valid Loss: 0.6793\n",
      "Epoch [19/20], LR: 0.071, Step [1812/1920], Train Loss: 0.6872, Valid Loss: 0.6796\n",
      "Epoch [19/20], LR: 0.071, Step [1816/1920], Train Loss: 0.6800, Valid Loss: 0.6790\n",
      "Epoch [19/20], LR: 0.071, Step [1820/1920], Train Loss: 0.6595, Valid Loss: 0.6784\n",
      "Epoch [19/20], LR: 0.071, Step [1824/1920], Train Loss: 0.6298, Valid Loss: 0.6779\n",
      "time elapsed in epoch: 2.1054961681365967\n",
      "Epoch [20/20], LR: 0.075, Step [1828/1920], Train Loss: 0.6059, Valid Loss: 0.6796\n",
      "Epoch [20/20], LR: 0.075, Step [1832/1920], Train Loss: 0.6373, Valid Loss: 0.6807\n",
      "Epoch [20/20], LR: 0.075, Step [1836/1920], Train Loss: 0.6670, Valid Loss: 0.6803\n",
      "Epoch [20/20], LR: 0.075, Step [1840/1920], Train Loss: 0.6859, Valid Loss: 0.6796\n",
      "Epoch [20/20], LR: 0.075, Step [1844/1920], Train Loss: 0.7103, Valid Loss: 0.6782\n",
      "Epoch [20/20], LR: 0.075, Step [1848/1920], Train Loss: 0.6657, Valid Loss: 0.6777\n",
      "Epoch [20/20], LR: 0.075, Step [1852/1920], Train Loss: 0.7016, Valid Loss: 0.6775\n",
      "Epoch [20/20], LR: 0.075, Step [1856/1920], Train Loss: 0.7035, Valid Loss: 0.6772\n",
      "Epoch [20/20], LR: 0.075, Step [1860/1920], Train Loss: 0.6853, Valid Loss: 0.6773\n",
      "Epoch [20/20], LR: 0.075, Step [1864/1920], Train Loss: 0.6725, Valid Loss: 0.6775\n",
      "Epoch [20/20], LR: 0.075, Step [1868/1920], Train Loss: 0.6747, Valid Loss: 0.6774\n",
      "Epoch [20/20], LR: 0.075, Step [1872/1920], Train Loss: 0.7006, Valid Loss: 0.6774\n",
      "Epoch [20/20], LR: 0.075, Step [1876/1920], Train Loss: 0.6977, Valid Loss: 0.6774\n",
      "Epoch [20/20], LR: 0.075, Step [1880/1920], Train Loss: 0.6906, Valid Loss: 0.6776\n",
      "Epoch [20/20], LR: 0.075, Step [1884/1920], Train Loss: 0.6884, Valid Loss: 0.6776\n",
      "Epoch [20/20], LR: 0.075, Step [1888/1920], Train Loss: 0.6990, Valid Loss: 0.6783\n",
      "Epoch [20/20], LR: 0.075, Step [1892/1920], Train Loss: 0.6976, Valid Loss: 0.6789\n",
      "Epoch [20/20], LR: 0.075, Step [1896/1920], Train Loss: 0.6774, Valid Loss: 0.6784\n",
      "Epoch [20/20], LR: 0.075, Step [1900/1920], Train Loss: 0.6877, Valid Loss: 0.6784\n",
      "Epoch [20/20], LR: 0.075, Step [1904/1920], Train Loss: 0.6978, Valid Loss: 0.6787\n",
      "Epoch [20/20], LR: 0.075, Step [1908/1920], Train Loss: 0.6934, Valid Loss: 0.6789\n",
      "Epoch [20/20], LR: 0.075, Step [1912/1920], Train Loss: 0.6805, Valid Loss: 0.6784\n",
      "Epoch [20/20], LR: 0.075, Step [1916/1920], Train Loss: 0.6571, Valid Loss: 0.6775\n",
      "Epoch [20/20], LR: 0.075, Step [1920/1920], Train Loss: 0.6182, Valid Loss: 0.6771\n",
      "time elapsed in epoch: 2.258077383041382\n",
      "Finished Training!\n"
     ]
    }
   ],
   "source": [
    "!python train_rnn.py --flor noCommitHex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle-nlp-dist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "815c30a49f552e6fdb87f74e117ecdf18b0ca5a01ddc5c83796985c2fbc2bb40"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
