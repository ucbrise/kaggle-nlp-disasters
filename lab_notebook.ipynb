{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to run your experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rogarcia/anaconda3/envs/kaggle-nlp-dist/lib/python3.9/site-packages/torchtext/data/utils.py:123: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
      "  warnings.warn(f'Spacy model \"{language}\" could not be loaded, trying \"{OLD_MODEL_SHORTCUTS[language]}\" instead')\n",
      "Epoch [1/20], LR: 0.000, Step [4/1920], Train Loss: 0.6440, Valid Loss: 0.6804\n",
      "Epoch [1/20], LR: 0.000, Step [8/1920], Train Loss: 0.6735, Valid Loss: 0.6804\n",
      "Epoch [1/20], LR: 0.000, Step [12/1920], Train Loss: 0.6798, Valid Loss: 0.6804\n",
      "Epoch [1/20], LR: 0.000, Step [16/1920], Train Loss: 0.6908, Valid Loss: 0.6804\n",
      "Epoch [1/20], LR: 0.000, Step [20/1920], Train Loss: 0.6936, Valid Loss: 0.6804\n",
      "Epoch [1/20], LR: 0.000, Step [24/1920], Train Loss: 0.6785, Valid Loss: 0.6804\n",
      "Epoch [1/20], LR: 0.000, Step [28/1920], Train Loss: 0.6936, Valid Loss: 0.6804\n",
      "Epoch [1/20], LR: 0.000, Step [32/1920], Train Loss: 0.6975, Valid Loss: 0.6804\n",
      "Epoch [1/20], LR: 0.000, Step [36/1920], Train Loss: 0.6823, Valid Loss: 0.6804\n",
      "Epoch [1/20], LR: 0.000, Step [40/1920], Train Loss: 0.6803, Valid Loss: 0.6804\n",
      "Epoch [1/20], LR: 0.000, Step [44/1920], Train Loss: 0.6816, Valid Loss: 0.6804\n",
      "Epoch [1/20], LR: 0.000, Step [48/1920], Train Loss: 0.7010, Valid Loss: 0.6804\n",
      "Epoch [1/20], LR: 0.000, Step [52/1920], Train Loss: 0.6972, Valid Loss: 0.6804\n",
      "Epoch [1/20], LR: 0.000, Step [56/1920], Train Loss: 0.6951, Valid Loss: 0.6804\n",
      "Epoch [1/20], LR: 0.000, Step [60/1920], Train Loss: 0.6914, Valid Loss: 0.6804\n",
      "Epoch [1/20], LR: 0.000, Step [64/1920], Train Loss: 0.6897, Valid Loss: 0.6804\n",
      "Epoch [1/20], LR: 0.000, Step [68/1920], Train Loss: 0.7017, Valid Loss: 0.6804\n",
      "Epoch [1/20], LR: 0.000, Step [72/1920], Train Loss: 0.6783, Valid Loss: 0.6804\n",
      "Epoch [1/20], LR: 0.000, Step [76/1920], Train Loss: 0.6871, Valid Loss: 0.6804\n",
      "Epoch [1/20], LR: 0.000, Step [80/1920], Train Loss: 0.6881, Valid Loss: 0.6804\n",
      "Epoch [1/20], LR: 0.000, Step [84/1920], Train Loss: 0.6996, Valid Loss: 0.6804\n",
      "Epoch [1/20], LR: 0.000, Step [88/1920], Train Loss: 0.6715, Valid Loss: 0.6804\n",
      "Epoch [1/20], LR: 0.000, Step [92/1920], Train Loss: 0.6624, Valid Loss: 0.6804\n",
      "Epoch [1/20], LR: 0.000, Step [96/1920], Train Loss: 0.6512, Valid Loss: 0.6804\n",
      "time elapsed in epoch: 2.4903178215026855\n",
      "Epoch [2/20], LR: 0.000, Step [100/1920], Train Loss: 0.6475, Valid Loss: 0.6804\n",
      "Epoch [2/20], LR: 0.000, Step [104/1920], Train Loss: 0.6650, Valid Loss: 0.6804\n",
      "Epoch [2/20], LR: 0.000, Step [108/1920], Train Loss: 0.6653, Valid Loss: 0.6804\n",
      "Epoch [2/20], LR: 0.000, Step [112/1920], Train Loss: 0.6876, Valid Loss: 0.6804\n",
      "Epoch [2/20], LR: 0.000, Step [116/1920], Train Loss: 0.6841, Valid Loss: 0.6804\n",
      "Epoch [2/20], LR: 0.000, Step [120/1920], Train Loss: 0.6812, Valid Loss: 0.6804\n",
      "Epoch [2/20], LR: 0.000, Step [124/1920], Train Loss: 0.6977, Valid Loss: 0.6804\n",
      "Epoch [2/20], LR: 0.000, Step [128/1920], Train Loss: 0.6974, Valid Loss: 0.6804\n",
      "Epoch [2/20], LR: 0.000, Step [132/1920], Train Loss: 0.6984, Valid Loss: 0.6804\n",
      "Epoch [2/20], LR: 0.000, Step [136/1920], Train Loss: 0.6750, Valid Loss: 0.6804\n",
      "Epoch [2/20], LR: 0.000, Step [140/1920], Train Loss: 0.6886, Valid Loss: 0.6804\n",
      "Epoch [2/20], LR: 0.000, Step [144/1920], Train Loss: 0.7016, Valid Loss: 0.6804\n",
      "Epoch [2/20], LR: 0.000, Step [148/1920], Train Loss: 0.6953, Valid Loss: 0.6804\n",
      "Epoch [2/20], LR: 0.000, Step [152/1920], Train Loss: 0.6768, Valid Loss: 0.6804\n",
      "Epoch [2/20], LR: 0.000, Step [156/1920], Train Loss: 0.7001, Valid Loss: 0.6804\n",
      "Epoch [2/20], LR: 0.000, Step [160/1920], Train Loss: 0.7006, Valid Loss: 0.6804\n",
      "Epoch [2/20], LR: 0.000, Step [164/1920], Train Loss: 0.7028, Valid Loss: 0.6804\n",
      "Epoch [2/20], LR: 0.000, Step [168/1920], Train Loss: 0.6746, Valid Loss: 0.6804\n",
      "Epoch [2/20], LR: 0.000, Step [172/1920], Train Loss: 0.6892, Valid Loss: 0.6804\n",
      "Epoch [2/20], LR: 0.000, Step [176/1920], Train Loss: 0.6931, Valid Loss: 0.6804\n",
      "Epoch [2/20], LR: 0.000, Step [180/1920], Train Loss: 0.6915, Valid Loss: 0.6804\n",
      "Epoch [2/20], LR: 0.000, Step [184/1920], Train Loss: 0.6807, Valid Loss: 0.6804\n",
      "Epoch [2/20], LR: 0.000, Step [188/1920], Train Loss: 0.6607, Valid Loss: 0.6804\n",
      "Epoch [2/20], LR: 0.000, Step [192/1920], Train Loss: 0.6546, Valid Loss: 0.6804\n",
      "time elapsed in epoch: 2.231257438659668\n",
      "Epoch [3/20], LR: 0.004, Step [196/1920], Train Loss: 0.6494, Valid Loss: 0.6801\n",
      "Epoch [3/20], LR: 0.004, Step [200/1920], Train Loss: 0.6636, Valid Loss: 0.6800\n",
      "Epoch [3/20], LR: 0.004, Step [204/1920], Train Loss: 0.6781, Valid Loss: 0.6799\n",
      "Epoch [3/20], LR: 0.004, Step [208/1920], Train Loss: 0.6860, Valid Loss: 0.6799\n",
      "Epoch [3/20], LR: 0.004, Step [212/1920], Train Loss: 0.7064, Valid Loss: 0.6800\n",
      "Epoch [3/20], LR: 0.004, Step [216/1920], Train Loss: 0.6932, Valid Loss: 0.6799\n",
      "Epoch [3/20], LR: 0.004, Step [220/1920], Train Loss: 0.6850, Valid Loss: 0.6800\n",
      "Epoch [3/20], LR: 0.004, Step [224/1920], Train Loss: 0.7013, Valid Loss: 0.6800\n",
      "Epoch [3/20], LR: 0.004, Step [228/1920], Train Loss: 0.6871, Valid Loss: 0.6800\n",
      "Epoch [3/20], LR: 0.004, Step [232/1920], Train Loss: 0.6742, Valid Loss: 0.6799\n",
      "Epoch [3/20], LR: 0.004, Step [236/1920], Train Loss: 0.6812, Valid Loss: 0.6799\n",
      "Epoch [3/20], LR: 0.004, Step [240/1920], Train Loss: 0.7056, Valid Loss: 0.6799\n",
      "Epoch [3/20], LR: 0.004, Step [244/1920], Train Loss: 0.6922, Valid Loss: 0.6799\n",
      "Epoch [3/20], LR: 0.004, Step [248/1920], Train Loss: 0.6853, Valid Loss: 0.6799\n",
      "Epoch [3/20], LR: 0.004, Step [252/1920], Train Loss: 0.6901, Valid Loss: 0.6799\n",
      "Epoch [3/20], LR: 0.004, Step [256/1920], Train Loss: 0.6938, Valid Loss: 0.6799\n",
      "Epoch [3/20], LR: 0.004, Step [260/1920], Train Loss: 0.6887, Valid Loss: 0.6799\n",
      "Epoch [3/20], LR: 0.004, Step [264/1920], Train Loss: 0.6836, Valid Loss: 0.6799\n",
      "Epoch [3/20], LR: 0.004, Step [268/1920], Train Loss: 0.6838, Valid Loss: 0.6799\n",
      "Epoch [3/20], LR: 0.004, Step [272/1920], Train Loss: 0.6890, Valid Loss: 0.6799\n",
      "Epoch [3/20], LR: 0.004, Step [276/1920], Train Loss: 0.6977, Valid Loss: 0.6799\n",
      "Epoch [3/20], LR: 0.004, Step [280/1920], Train Loss: 0.6854, Valid Loss: 0.6799\n",
      "Epoch [3/20], LR: 0.004, Step [284/1920], Train Loss: 0.6698, Valid Loss: 0.6797\n",
      "Epoch [3/20], LR: 0.004, Step [288/1920], Train Loss: 0.6537, Valid Loss: 0.6796\n",
      "time elapsed in epoch: 2.8057425022125244\n",
      "Epoch [4/20], LR: 0.008, Step [292/1920], Train Loss: 0.6357, Valid Loss: 0.6792\n",
      "Epoch [4/20], LR: 0.008, Step [296/1920], Train Loss: 0.6550, Valid Loss: 0.6790\n",
      "Epoch [4/20], LR: 0.008, Step [300/1920], Train Loss: 0.6672, Valid Loss: 0.6789\n",
      "Epoch [4/20], LR: 0.008, Step [304/1920], Train Loss: 0.6867, Valid Loss: 0.6789\n",
      "Epoch [4/20], LR: 0.008, Step [308/1920], Train Loss: 0.6960, Valid Loss: 0.6789\n",
      "Epoch [4/20], LR: 0.008, Step [312/1920], Train Loss: 0.6770, Valid Loss: 0.6789\n",
      "Epoch [4/20], LR: 0.008, Step [316/1920], Train Loss: 0.7050, Valid Loss: 0.6789\n",
      "Epoch [4/20], LR: 0.008, Step [320/1920], Train Loss: 0.7069, Valid Loss: 0.6790\n",
      "Epoch [4/20], LR: 0.008, Step [324/1920], Train Loss: 0.6875, Valid Loss: 0.6790\n",
      "Epoch [4/20], LR: 0.008, Step [328/1920], Train Loss: 0.6765, Valid Loss: 0.6789\n",
      "Epoch [4/20], LR: 0.008, Step [332/1920], Train Loss: 0.6833, Valid Loss: 0.6789\n",
      "Epoch [4/20], LR: 0.008, Step [336/1920], Train Loss: 0.7015, Valid Loss: 0.6789\n",
      "Epoch [4/20], LR: 0.008, Step [340/1920], Train Loss: 0.7002, Valid Loss: 0.6789\n",
      "Epoch [4/20], LR: 0.008, Step [344/1920], Train Loss: 0.6728, Valid Loss: 0.6789\n",
      "Epoch [4/20], LR: 0.008, Step [348/1920], Train Loss: 0.6939, Valid Loss: 0.6789\n",
      "Epoch [4/20], LR: 0.008, Step [352/1920], Train Loss: 0.6940, Valid Loss: 0.6789\n",
      "Epoch [4/20], LR: 0.008, Step [356/1920], Train Loss: 0.7063, Valid Loss: 0.6790\n",
      "Epoch [4/20], LR: 0.008, Step [360/1920], Train Loss: 0.6796, Valid Loss: 0.6789\n",
      "Epoch [4/20], LR: 0.008, Step [364/1920], Train Loss: 0.6932, Valid Loss: 0.6790\n",
      "Epoch [4/20], LR: 0.008, Step [368/1920], Train Loss: 0.7022, Valid Loss: 0.6790\n",
      "Epoch [4/20], LR: 0.008, Step [372/1920], Train Loss: 0.6932, Valid Loss: 0.6790\n",
      "Epoch [4/20], LR: 0.008, Step [376/1920], Train Loss: 0.6761, Valid Loss: 0.6790\n",
      "Epoch [4/20], LR: 0.008, Step [380/1920], Train Loss: 0.6602, Valid Loss: 0.6788\n",
      "Epoch [4/20], LR: 0.008, Step [384/1920], Train Loss: 0.6342, Valid Loss: 0.6786\n",
      "time elapsed in epoch: 2.9150023460388184\n",
      "Epoch [5/20], LR: 0.013, Step [388/1920], Train Loss: 0.6224, Valid Loss: 0.6782\n",
      "Epoch [5/20], LR: 0.013, Step [392/1920], Train Loss: 0.6538, Valid Loss: 0.6780\n",
      "Epoch [5/20], LR: 0.013, Step [396/1920], Train Loss: 0.6704, Valid Loss: 0.6780\n",
      "Epoch [5/20], LR: 0.013, Step [400/1920], Train Loss: 0.6818, Valid Loss: 0.6780\n",
      "Epoch [5/20], LR: 0.013, Step [404/1920], Train Loss: 0.7077, Valid Loss: 0.6781\n",
      "Epoch [5/20], LR: 0.013, Step [408/1920], Train Loss: 0.6868, Valid Loss: 0.6780\n",
      "Epoch [5/20], LR: 0.013, Step [412/1920], Train Loss: 0.6924, Valid Loss: 0.6781\n",
      "Epoch [5/20], LR: 0.013, Step [416/1920], Train Loss: 0.7078, Valid Loss: 0.6782\n",
      "Epoch [5/20], LR: 0.013, Step [420/1920], Train Loss: 0.6769, Valid Loss: 0.6781\n",
      "Epoch [5/20], LR: 0.013, Step [424/1920], Train Loss: 0.6722, Valid Loss: 0.6780\n",
      "Epoch [5/20], LR: 0.013, Step [428/1920], Train Loss: 0.6999, Valid Loss: 0.6780\n",
      "Epoch [5/20], LR: 0.013, Step [432/1920], Train Loss: 0.7006, Valid Loss: 0.6781\n",
      "Epoch [5/20], LR: 0.013, Step [436/1920], Train Loss: 0.7080, Valid Loss: 0.6782\n",
      "Epoch [5/20], LR: 0.013, Step [440/1920], Train Loss: 0.6861, Valid Loss: 0.6782\n",
      "Epoch [5/20], LR: 0.013, Step [444/1920], Train Loss: 0.6959, Valid Loss: 0.6783\n",
      "Epoch [5/20], LR: 0.013, Step [448/1920], Train Loss: 0.7052, Valid Loss: 0.6783\n",
      "Epoch [5/20], LR: 0.013, Step [452/1920], Train Loss: 0.7029, Valid Loss: 0.6784\n",
      "Epoch [5/20], LR: 0.013, Step [456/1920], Train Loss: 0.6786, Valid Loss: 0.6784\n",
      "Epoch [5/20], LR: 0.013, Step [460/1920], Train Loss: 0.6979, Valid Loss: 0.6784\n",
      "Epoch [5/20], LR: 0.013, Step [464/1920], Train Loss: 0.6907, Valid Loss: 0.6785\n",
      "Epoch [5/20], LR: 0.013, Step [468/1920], Train Loss: 0.6947, Valid Loss: 0.6785\n",
      "Epoch [5/20], LR: 0.013, Step [472/1920], Train Loss: 0.6815, Valid Loss: 0.6785\n",
      "Epoch [5/20], LR: 0.013, Step [476/1920], Train Loss: 0.6684, Valid Loss: 0.6783\n",
      "Epoch [5/20], LR: 0.013, Step [480/1920], Train Loss: 0.6423, Valid Loss: 0.6780\n",
      "time elapsed in epoch: 2.7368195056915283\n",
      "Epoch [6/20], LR: 0.017, Step [484/1920], Train Loss: 0.6166, Valid Loss: 0.6777\n",
      "Epoch [6/20], LR: 0.017, Step [488/1920], Train Loss: 0.6491, Valid Loss: 0.6776\n",
      "Epoch [6/20], LR: 0.017, Step [492/1920], Train Loss: 0.6740, Valid Loss: 0.6776\n",
      "Epoch [6/20], LR: 0.017, Step [496/1920], Train Loss: 0.6791, Valid Loss: 0.6776\n",
      "Epoch [6/20], LR: 0.017, Step [500/1920], Train Loss: 0.7085, Valid Loss: 0.6776\n",
      "Epoch [6/20], LR: 0.017, Step [504/1920], Train Loss: 0.6752, Valid Loss: 0.6776\n",
      "Epoch [6/20], LR: 0.017, Step [508/1920], Train Loss: 0.6967, Valid Loss: 0.6776\n",
      "Epoch [6/20], LR: 0.017, Step [512/1920], Train Loss: 0.7053, Valid Loss: 0.6777\n",
      "Epoch [6/20], LR: 0.017, Step [516/1920], Train Loss: 0.6871, Valid Loss: 0.6777\n",
      "Epoch [6/20], LR: 0.017, Step [520/1920], Train Loss: 0.6709, Valid Loss: 0.6776\n",
      "Epoch [6/20], LR: 0.017, Step [524/1920], Train Loss: 0.6802, Valid Loss: 0.6776\n",
      "Epoch [6/20], LR: 0.017, Step [528/1920], Train Loss: 0.7042, Valid Loss: 0.6777\n",
      "Epoch [6/20], LR: 0.017, Step [532/1920], Train Loss: 0.7000, Valid Loss: 0.6778\n",
      "Epoch [6/20], LR: 0.017, Step [536/1920], Train Loss: 0.6906, Valid Loss: 0.6778\n",
      "Epoch [6/20], LR: 0.017, Step [540/1920], Train Loss: 0.6884, Valid Loss: 0.6778\n",
      "Epoch [6/20], LR: 0.017, Step [544/1920], Train Loss: 0.6978, Valid Loss: 0.6779\n",
      "Epoch [6/20], LR: 0.017, Step [548/1920], Train Loss: 0.7148, Valid Loss: 0.6780\n",
      "Epoch [6/20], LR: 0.017, Step [552/1920], Train Loss: 0.6781, Valid Loss: 0.6779\n",
      "Epoch [6/20], LR: 0.017, Step [556/1920], Train Loss: 0.6891, Valid Loss: 0.6779\n",
      "Epoch [6/20], LR: 0.017, Step [560/1920], Train Loss: 0.6874, Valid Loss: 0.6779\n",
      "Epoch [6/20], LR: 0.017, Step [564/1920], Train Loss: 0.6890, Valid Loss: 0.6780\n",
      "Epoch [6/20], LR: 0.017, Step [568/1920], Train Loss: 0.6745, Valid Loss: 0.6779\n",
      "Epoch [6/20], LR: 0.017, Step [572/1920], Train Loss: 0.6472, Valid Loss: 0.6777\n",
      "Epoch [6/20], LR: 0.017, Step [576/1920], Train Loss: 0.6274, Valid Loss: 0.6774\n",
      "time elapsed in epoch: 2.8330676555633545\n",
      "Epoch [7/20], LR: 0.021, Step [580/1920], Train Loss: 0.6158, Valid Loss: 0.6772\n",
      "Epoch [7/20], LR: 0.021, Step [584/1920], Train Loss: 0.6552, Valid Loss: 0.6772\n",
      "Epoch [7/20], LR: 0.021, Step [588/1920], Train Loss: 0.6742, Valid Loss: 0.6772\n",
      "Epoch [7/20], LR: 0.021, Step [592/1920], Train Loss: 0.6856, Valid Loss: 0.6772\n",
      "Epoch [7/20], LR: 0.021, Step [596/1920], Train Loss: 0.7000, Valid Loss: 0.6772\n",
      "Epoch [7/20], LR: 0.021, Step [600/1920], Train Loss: 0.6828, Valid Loss: 0.6771\n",
      "Epoch [7/20], LR: 0.021, Step [604/1920], Train Loss: 0.6954, Valid Loss: 0.6772\n",
      "Epoch [7/20], LR: 0.021, Step [608/1920], Train Loss: 0.7049, Valid Loss: 0.6772\n",
      "Epoch [7/20], LR: 0.021, Step [612/1920], Train Loss: 0.6918, Valid Loss: 0.6772\n",
      "Epoch [7/20], LR: 0.021, Step [616/1920], Train Loss: 0.6671, Valid Loss: 0.6771\n",
      "Epoch [7/20], LR: 0.021, Step [620/1920], Train Loss: 0.6776, Valid Loss: 0.6771\n",
      "Epoch [7/20], LR: 0.021, Step [624/1920], Train Loss: 0.6992, Valid Loss: 0.6772\n",
      "Epoch [7/20], LR: 0.021, Step [628/1920], Train Loss: 0.6987, Valid Loss: 0.6773\n",
      "Epoch [7/20], LR: 0.021, Step [632/1920], Train Loss: 0.6879, Valid Loss: 0.6773\n",
      "Epoch [7/20], LR: 0.021, Step [636/1920], Train Loss: 0.6844, Valid Loss: 0.6774\n",
      "Epoch [7/20], LR: 0.021, Step [640/1920], Train Loss: 0.7028, Valid Loss: 0.6774\n",
      "Epoch [7/20], LR: 0.021, Step [644/1920], Train Loss: 0.6991, Valid Loss: 0.6775\n",
      "Epoch [7/20], LR: 0.021, Step [648/1920], Train Loss: 0.6716, Valid Loss: 0.6774\n",
      "Epoch [7/20], LR: 0.021, Step [652/1920], Train Loss: 0.6861, Valid Loss: 0.6775\n",
      "Epoch [7/20], LR: 0.021, Step [656/1920], Train Loss: 0.6928, Valid Loss: 0.6775\n",
      "Epoch [7/20], LR: 0.021, Step [660/1920], Train Loss: 0.6945, Valid Loss: 0.6776\n",
      "Epoch [7/20], LR: 0.021, Step [664/1920], Train Loss: 0.6798, Valid Loss: 0.6775\n",
      "Epoch [7/20], LR: 0.021, Step [668/1920], Train Loss: 0.6543, Valid Loss: 0.6773\n",
      "Epoch [7/20], LR: 0.021, Step [672/1920], Train Loss: 0.6283, Valid Loss: 0.6770\n",
      "time elapsed in epoch: 2.573244333267212\n",
      "Epoch [8/20], LR: 0.025, Step [676/1920], Train Loss: 0.6133, Valid Loss: 0.6769\n",
      "Epoch [8/20], LR: 0.025, Step [680/1920], Train Loss: 0.6509, Valid Loss: 0.6770\n",
      "Epoch [8/20], LR: 0.025, Step [684/1920], Train Loss: 0.6675, Valid Loss: 0.6770\n",
      "Epoch [8/20], LR: 0.025, Step [688/1920], Train Loss: 0.6822, Valid Loss: 0.6770\n",
      "Epoch [8/20], LR: 0.025, Step [692/1920], Train Loss: 0.7078, Valid Loss: 0.6769\n",
      "Epoch [8/20], LR: 0.025, Step [696/1920], Train Loss: 0.6764, Valid Loss: 0.6769\n",
      "Epoch [8/20], LR: 0.025, Step [700/1920], Train Loss: 0.6989, Valid Loss: 0.6768\n",
      "Epoch [8/20], LR: 0.025, Step [704/1920], Train Loss: 0.7100, Valid Loss: 0.6769\n",
      "Epoch [8/20], LR: 0.025, Step [708/1920], Train Loss: 0.6838, Valid Loss: 0.6769\n",
      "Epoch [8/20], LR: 0.025, Step [712/1920], Train Loss: 0.6621, Valid Loss: 0.6768\n",
      "Epoch [8/20], LR: 0.025, Step [716/1920], Train Loss: 0.6796, Valid Loss: 0.6768\n",
      "Epoch [8/20], LR: 0.025, Step [720/1920], Train Loss: 0.6979, Valid Loss: 0.6769\n",
      "Epoch [8/20], LR: 0.025, Step [724/1920], Train Loss: 0.7030, Valid Loss: 0.6770\n",
      "Epoch [8/20], LR: 0.025, Step [728/1920], Train Loss: 0.6794, Valid Loss: 0.6769\n",
      "Epoch [8/20], LR: 0.025, Step [732/1920], Train Loss: 0.6865, Valid Loss: 0.6770\n",
      "Epoch [8/20], LR: 0.025, Step [736/1920], Train Loss: 0.7021, Valid Loss: 0.6771\n",
      "Epoch [8/20], LR: 0.025, Step [740/1920], Train Loss: 0.7003, Valid Loss: 0.6773\n",
      "Epoch [8/20], LR: 0.025, Step [744/1920], Train Loss: 0.6751, Valid Loss: 0.6772\n",
      "Epoch [8/20], LR: 0.025, Step [748/1920], Train Loss: 0.6813, Valid Loss: 0.6772\n",
      "Epoch [8/20], LR: 0.025, Step [752/1920], Train Loss: 0.6915, Valid Loss: 0.6773\n",
      "Epoch [8/20], LR: 0.025, Step [756/1920], Train Loss: 0.6863, Valid Loss: 0.6774\n",
      "Epoch [8/20], LR: 0.025, Step [760/1920], Train Loss: 0.6759, Valid Loss: 0.6772\n",
      "Epoch [8/20], LR: 0.025, Step [764/1920], Train Loss: 0.6525, Valid Loss: 0.6770\n",
      "Epoch [8/20], LR: 0.025, Step [768/1920], Train Loss: 0.6364, Valid Loss: 0.6767\n",
      "time elapsed in epoch: 2.6228251457214355\n",
      "Epoch [9/20], LR: 0.029, Step [772/1920], Train Loss: 0.6113, Valid Loss: 0.6766\n",
      "Epoch [9/20], LR: 0.029, Step [776/1920], Train Loss: 0.6512, Valid Loss: 0.6767\n",
      "Epoch [9/20], LR: 0.029, Step [780/1920], Train Loss: 0.6714, Valid Loss: 0.6767\n",
      "Epoch [9/20], LR: 0.029, Step [784/1920], Train Loss: 0.6846, Valid Loss: 0.6766\n",
      "Epoch [9/20], LR: 0.029, Step [788/1920], Train Loss: 0.7133, Valid Loss: 0.6765\n",
      "Epoch [9/20], LR: 0.029, Step [792/1920], Train Loss: 0.6706, Valid Loss: 0.6765\n",
      "Epoch [9/20], LR: 0.029, Step [796/1920], Train Loss: 0.7028, Valid Loss: 0.6765\n",
      "Epoch [9/20], LR: 0.029, Step [800/1920], Train Loss: 0.7161, Valid Loss: 0.6766\n",
      "Epoch [9/20], LR: 0.029, Step [804/1920], Train Loss: 0.6892, Valid Loss: 0.6766\n",
      "Epoch [9/20], LR: 0.029, Step [808/1920], Train Loss: 0.6687, Valid Loss: 0.6765\n",
      "Epoch [9/20], LR: 0.029, Step [812/1920], Train Loss: 0.6808, Valid Loss: 0.6765\n",
      "Epoch [9/20], LR: 0.029, Step [816/1920], Train Loss: 0.7037, Valid Loss: 0.6766\n",
      "Epoch [9/20], LR: 0.029, Step [820/1920], Train Loss: 0.6977, Valid Loss: 0.6767\n",
      "Epoch [9/20], LR: 0.029, Step [824/1920], Train Loss: 0.6934, Valid Loss: 0.6767\n",
      "Epoch [9/20], LR: 0.029, Step [828/1920], Train Loss: 0.6888, Valid Loss: 0.6767\n",
      "Epoch [9/20], LR: 0.029, Step [832/1920], Train Loss: 0.6976, Valid Loss: 0.6768\n",
      "Epoch [9/20], LR: 0.029, Step [836/1920], Train Loss: 0.7033, Valid Loss: 0.6770\n",
      "Epoch [9/20], LR: 0.029, Step [840/1920], Train Loss: 0.6741, Valid Loss: 0.6770\n",
      "Epoch [9/20], LR: 0.029, Step [844/1920], Train Loss: 0.6918, Valid Loss: 0.6770\n",
      "Epoch [9/20], LR: 0.029, Step [848/1920], Train Loss: 0.6947, Valid Loss: 0.6770\n",
      "Epoch [9/20], LR: 0.029, Step [852/1920], Train Loss: 0.6861, Valid Loss: 0.6771\n",
      "Epoch [9/20], LR: 0.029, Step [856/1920], Train Loss: 0.6691, Valid Loss: 0.6769\n",
      "Epoch [9/20], LR: 0.029, Step [860/1920], Train Loss: 0.6505, Valid Loss: 0.6767\n",
      "Epoch [9/20], LR: 0.029, Step [864/1920], Train Loss: 0.6288, Valid Loss: 0.6764\n",
      "time elapsed in epoch: 2.7281689643859863\n",
      "Epoch [10/20], LR: 0.033, Step [868/1920], Train Loss: 0.6122, Valid Loss: 0.6764\n",
      "Epoch [10/20], LR: 0.033, Step [872/1920], Train Loss: 0.6506, Valid Loss: 0.6766\n",
      "Epoch [10/20], LR: 0.033, Step [876/1920], Train Loss: 0.6737, Valid Loss: 0.6766\n",
      "Epoch [10/20], LR: 0.033, Step [880/1920], Train Loss: 0.6855, Valid Loss: 0.6765\n",
      "Epoch [10/20], LR: 0.033, Step [884/1920], Train Loss: 0.7072, Valid Loss: 0.6763\n",
      "Epoch [10/20], LR: 0.033, Step [888/1920], Train Loss: 0.6735, Valid Loss: 0.6763\n",
      "Epoch [10/20], LR: 0.033, Step [892/1920], Train Loss: 0.6983, Valid Loss: 0.6762\n",
      "Epoch [10/20], LR: 0.033, Step [896/1920], Train Loss: 0.7047, Valid Loss: 0.6762\n",
      "Epoch [10/20], LR: 0.033, Step [900/1920], Train Loss: 0.6935, Valid Loss: 0.6762\n",
      "Epoch [10/20], LR: 0.033, Step [904/1920], Train Loss: 0.6660, Valid Loss: 0.6762\n",
      "Epoch [10/20], LR: 0.033, Step [908/1920], Train Loss: 0.6785, Valid Loss: 0.6762\n",
      "Epoch [10/20], LR: 0.033, Step [912/1920], Train Loss: 0.6999, Valid Loss: 0.6762\n",
      "Epoch [10/20], LR: 0.033, Step [916/1920], Train Loss: 0.6991, Valid Loss: 0.6763\n",
      "Epoch [10/20], LR: 0.033, Step [920/1920], Train Loss: 0.6833, Valid Loss: 0.6763\n",
      "Epoch [10/20], LR: 0.033, Step [924/1920], Train Loss: 0.6920, Valid Loss: 0.6763\n",
      "Epoch [10/20], LR: 0.033, Step [928/1920], Train Loss: 0.6944, Valid Loss: 0.6765\n",
      "Epoch [10/20], LR: 0.033, Step [932/1920], Train Loss: 0.6999, Valid Loss: 0.6766\n",
      "Epoch [10/20], LR: 0.033, Step [936/1920], Train Loss: 0.6734, Valid Loss: 0.6765\n",
      "Epoch [10/20], LR: 0.033, Step [940/1920], Train Loss: 0.6832, Valid Loss: 0.6765\n",
      "Epoch [10/20], LR: 0.033, Step [944/1920], Train Loss: 0.6879, Valid Loss: 0.6766\n",
      "Epoch [10/20], LR: 0.033, Step [948/1920], Train Loss: 0.6874, Valid Loss: 0.6767\n",
      "Epoch [10/20], LR: 0.033, Step [952/1920], Train Loss: 0.6813, Valid Loss: 0.6766\n",
      "Epoch [10/20], LR: 0.033, Step [956/1920], Train Loss: 0.6509, Valid Loss: 0.6763\n",
      "Epoch [10/20], LR: 0.033, Step [960/1920], Train Loss: 0.6224, Valid Loss: 0.6760\n",
      "time elapsed in epoch: 2.8906610012054443\n",
      "Epoch [11/20], LR: 0.038, Step [964/1920], Train Loss: 0.6112, Valid Loss: 0.6763\n",
      "Epoch [11/20], LR: 0.038, Step [968/1920], Train Loss: 0.6507, Valid Loss: 0.6766\n",
      "Epoch [11/20], LR: 0.038, Step [972/1920], Train Loss: 0.6703, Valid Loss: 0.6766\n",
      "Epoch [11/20], LR: 0.038, Step [976/1920], Train Loss: 0.6824, Valid Loss: 0.6766\n",
      "Epoch [11/20], LR: 0.038, Step [980/1920], Train Loss: 0.7073, Valid Loss: 0.6763\n",
      "Epoch [11/20], LR: 0.038, Step [984/1920], Train Loss: 0.6707, Valid Loss: 0.6762\n",
      "Epoch [11/20], LR: 0.038, Step [988/1920], Train Loss: 0.6905, Valid Loss: 0.6761\n",
      "Epoch [11/20], LR: 0.038, Step [992/1920], Train Loss: 0.7033, Valid Loss: 0.6758\n",
      "Epoch [11/20], LR: 0.038, Step [996/1920], Train Loss: 0.6852, Valid Loss: 0.6758\n",
      "Epoch [11/20], LR: 0.038, Step [1000/1920], Train Loss: 0.6681, Valid Loss: 0.6758\n",
      "Epoch [11/20], LR: 0.038, Step [1004/1920], Train Loss: 0.6763, Valid Loss: 0.6758\n",
      "Epoch [11/20], LR: 0.038, Step [1008/1920], Train Loss: 0.7018, Valid Loss: 0.6758\n",
      "Epoch [11/20], LR: 0.038, Step [1012/1920], Train Loss: 0.7007, Valid Loss: 0.6758\n",
      "Epoch [11/20], LR: 0.038, Step [1016/1920], Train Loss: 0.6873, Valid Loss: 0.6758\n",
      "Epoch [11/20], LR: 0.038, Step [1020/1920], Train Loss: 0.6925, Valid Loss: 0.6758\n",
      "Epoch [11/20], LR: 0.038, Step [1024/1920], Train Loss: 0.6886, Valid Loss: 0.6759\n",
      "Epoch [11/20], LR: 0.038, Step [1028/1920], Train Loss: 0.6959, Valid Loss: 0.6761\n",
      "Epoch [11/20], LR: 0.038, Step [1032/1920], Train Loss: 0.6766, Valid Loss: 0.6759\n",
      "Epoch [11/20], LR: 0.038, Step [1036/1920], Train Loss: 0.6863, Valid Loss: 0.6760\n",
      "Epoch [11/20], LR: 0.038, Step [1040/1920], Train Loss: 0.6932, Valid Loss: 0.6761\n",
      "Epoch [11/20], LR: 0.038, Step [1044/1920], Train Loss: 0.6858, Valid Loss: 0.6762\n",
      "Epoch [11/20], LR: 0.038, Step [1048/1920], Train Loss: 0.6844, Valid Loss: 0.6761\n",
      "Epoch [11/20], LR: 0.038, Step [1052/1920], Train Loss: 0.6570, Valid Loss: 0.6757\n",
      "Epoch [11/20], LR: 0.038, Step [1056/1920], Train Loss: 0.6171, Valid Loss: 0.6753\n",
      "time elapsed in epoch: 2.691051721572876\n",
      "Epoch [12/20], LR: 0.042, Step [1060/1920], Train Loss: 0.6038, Valid Loss: 0.6757\n",
      "Epoch [12/20], LR: 0.042, Step [1064/1920], Train Loss: 0.6354, Valid Loss: 0.6761\n",
      "Epoch [12/20], LR: 0.042, Step [1068/1920], Train Loss: 0.6751, Valid Loss: 0.6761\n",
      "Epoch [12/20], LR: 0.042, Step [1072/1920], Train Loss: 0.6865, Valid Loss: 0.6758\n",
      "Epoch [12/20], LR: 0.042, Step [1076/1920], Train Loss: 0.7078, Valid Loss: 0.6754\n",
      "Epoch [12/20], LR: 0.042, Step [1080/1920], Train Loss: 0.6735, Valid Loss: 0.6754\n",
      "Epoch [12/20], LR: 0.042, Step [1084/1920], Train Loss: 0.6954, Valid Loss: 0.6752\n",
      "Epoch [12/20], LR: 0.042, Step [1088/1920], Train Loss: 0.7114, Valid Loss: 0.6752\n",
      "Epoch [12/20], LR: 0.042, Step [1092/1920], Train Loss: 0.6833, Valid Loss: 0.6752\n",
      "Epoch [12/20], LR: 0.042, Step [1096/1920], Train Loss: 0.6622, Valid Loss: 0.6751\n",
      "Epoch [12/20], LR: 0.042, Step [1100/1920], Train Loss: 0.6847, Valid Loss: 0.6751\n",
      "Epoch [12/20], LR: 0.042, Step [1104/1920], Train Loss: 0.7060, Valid Loss: 0.6752\n",
      "Epoch [12/20], LR: 0.042, Step [1108/1920], Train Loss: 0.6909, Valid Loss: 0.6753\n",
      "Epoch [12/20], LR: 0.042, Step [1112/1920], Train Loss: 0.6896, Valid Loss: 0.6755\n",
      "Epoch [12/20], LR: 0.042, Step [1116/1920], Train Loss: 0.6918, Valid Loss: 0.6755\n",
      "Epoch [12/20], LR: 0.042, Step [1120/1920], Train Loss: 0.6879, Valid Loss: 0.6757\n",
      "Epoch [12/20], LR: 0.042, Step [1124/1920], Train Loss: 0.6974, Valid Loss: 0.6761\n",
      "Epoch [12/20], LR: 0.042, Step [1128/1920], Train Loss: 0.6778, Valid Loss: 0.6758\n",
      "Epoch [12/20], LR: 0.042, Step [1132/1920], Train Loss: 0.6918, Valid Loss: 0.6757\n",
      "Epoch [12/20], LR: 0.042, Step [1136/1920], Train Loss: 0.6834, Valid Loss: 0.6758\n",
      "Epoch [12/20], LR: 0.042, Step [1140/1920], Train Loss: 0.6888, Valid Loss: 0.6758\n",
      "Epoch [12/20], LR: 0.042, Step [1144/1920], Train Loss: 0.6804, Valid Loss: 0.6756\n",
      "Epoch [12/20], LR: 0.042, Step [1148/1920], Train Loss: 0.6558, Valid Loss: 0.6753\n",
      "Epoch [12/20], LR: 0.042, Step [1152/1920], Train Loss: 0.6341, Valid Loss: 0.6749\n",
      "time elapsed in epoch: 2.695876359939575\n",
      "Epoch [13/20], LR: 0.046, Step [1156/1920], Train Loss: 0.6002, Valid Loss: 0.6753\n",
      "Epoch [13/20], LR: 0.046, Step [1160/1920], Train Loss: 0.6356, Valid Loss: 0.6755\n",
      "Epoch [13/20], LR: 0.046, Step [1164/1920], Train Loss: 0.6676, Valid Loss: 0.6754\n",
      "Epoch [13/20], LR: 0.046, Step [1168/1920], Train Loss: 0.6840, Valid Loss: 0.6752\n",
      "Epoch [13/20], LR: 0.046, Step [1172/1920], Train Loss: 0.7043, Valid Loss: 0.6748\n",
      "Epoch [13/20], LR: 0.046, Step [1176/1920], Train Loss: 0.6733, Valid Loss: 0.6748\n",
      "Epoch [13/20], LR: 0.046, Step [1180/1920], Train Loss: 0.7025, Valid Loss: 0.6748\n",
      "Epoch [13/20], LR: 0.046, Step [1184/1920], Train Loss: 0.7037, Valid Loss: 0.6747\n",
      "Epoch [13/20], LR: 0.046, Step [1188/1920], Train Loss: 0.6796, Valid Loss: 0.6747\n",
      "Epoch [13/20], LR: 0.046, Step [1192/1920], Train Loss: 0.6656, Valid Loss: 0.6746\n",
      "Epoch [13/20], LR: 0.046, Step [1196/1920], Train Loss: 0.6793, Valid Loss: 0.6746\n",
      "Epoch [13/20], LR: 0.046, Step [1200/1920], Train Loss: 0.6980, Valid Loss: 0.6746\n",
      "Epoch [13/20], LR: 0.046, Step [1204/1920], Train Loss: 0.7031, Valid Loss: 0.6747\n",
      "Epoch [13/20], LR: 0.046, Step [1208/1920], Train Loss: 0.6905, Valid Loss: 0.6747\n",
      "Epoch [13/20], LR: 0.046, Step [1212/1920], Train Loss: 0.6881, Valid Loss: 0.6748\n",
      "Epoch [13/20], LR: 0.046, Step [1216/1920], Train Loss: 0.6974, Valid Loss: 0.6749\n",
      "Epoch [13/20], LR: 0.046, Step [1220/1920], Train Loss: 0.6887, Valid Loss: 0.6752\n",
      "Epoch [13/20], LR: 0.046, Step [1224/1920], Train Loss: 0.6722, Valid Loss: 0.6750\n",
      "Epoch [13/20], LR: 0.046, Step [1228/1920], Train Loss: 0.6824, Valid Loss: 0.6751\n",
      "Epoch [13/20], LR: 0.046, Step [1232/1920], Train Loss: 0.6873, Valid Loss: 0.6752\n",
      "Epoch [13/20], LR: 0.046, Step [1236/1920], Train Loss: 0.6890, Valid Loss: 0.6753\n",
      "Epoch [13/20], LR: 0.046, Step [1240/1920], Train Loss: 0.6771, Valid Loss: 0.6750\n",
      "Epoch [13/20], LR: 0.046, Step [1244/1920], Train Loss: 0.6480, Valid Loss: 0.6745\n",
      "Epoch [13/20], LR: 0.046, Step [1248/1920], Train Loss: 0.6150, Valid Loss: 0.6742\n",
      "time elapsed in epoch: 2.9946794509887695\n",
      "Epoch [14/20], LR: 0.050, Step [1252/1920], Train Loss: 0.6029, Valid Loss: 0.6749\n",
      "Epoch [14/20], LR: 0.050, Step [1256/1920], Train Loss: 0.6466, Valid Loss: 0.6754\n",
      "Epoch [14/20], LR: 0.050, Step [1260/1920], Train Loss: 0.6754, Valid Loss: 0.6753\n",
      "Epoch [14/20], LR: 0.050, Step [1264/1920], Train Loss: 0.6824, Valid Loss: 0.6750\n",
      "Epoch [14/20], LR: 0.050, Step [1268/1920], Train Loss: 0.7039, Valid Loss: 0.6743\n",
      "Epoch [14/20], LR: 0.050, Step [1272/1920], Train Loss: 0.6657, Valid Loss: 0.6741\n",
      "Epoch [14/20], LR: 0.050, Step [1276/1920], Train Loss: 0.6934, Valid Loss: 0.6740\n",
      "Epoch [14/20], LR: 0.050, Step [1280/1920], Train Loss: 0.7108, Valid Loss: 0.6739\n",
      "Epoch [14/20], LR: 0.050, Step [1284/1920], Train Loss: 0.6898, Valid Loss: 0.6740\n",
      "Epoch [14/20], LR: 0.050, Step [1288/1920], Train Loss: 0.6743, Valid Loss: 0.6740\n",
      "Epoch [14/20], LR: 0.050, Step [1292/1920], Train Loss: 0.6785, Valid Loss: 0.6740\n",
      "Epoch [14/20], LR: 0.050, Step [1296/1920], Train Loss: 0.6980, Valid Loss: 0.6740\n",
      "Epoch [14/20], LR: 0.050, Step [1300/1920], Train Loss: 0.7073, Valid Loss: 0.6743\n",
      "Epoch [14/20], LR: 0.050, Step [1304/1920], Train Loss: 0.6781, Valid Loss: 0.6743\n",
      "Epoch [14/20], LR: 0.050, Step [1308/1920], Train Loss: 0.6941, Valid Loss: 0.6746\n",
      "Epoch [14/20], LR: 0.050, Step [1312/1920], Train Loss: 0.6906, Valid Loss: 0.6749\n",
      "Epoch [14/20], LR: 0.050, Step [1316/1920], Train Loss: 0.6919, Valid Loss: 0.6754\n",
      "Epoch [14/20], LR: 0.050, Step [1320/1920], Train Loss: 0.6762, Valid Loss: 0.6751\n",
      "Epoch [14/20], LR: 0.050, Step [1324/1920], Train Loss: 0.6841, Valid Loss: 0.6750\n",
      "Epoch [14/20], LR: 0.050, Step [1328/1920], Train Loss: 0.6856, Valid Loss: 0.6751\n",
      "Epoch [14/20], LR: 0.050, Step [1332/1920], Train Loss: 0.6863, Valid Loss: 0.6751\n",
      "Epoch [14/20], LR: 0.050, Step [1336/1920], Train Loss: 0.6797, Valid Loss: 0.6748\n",
      "Epoch [14/20], LR: 0.050, Step [1340/1920], Train Loss: 0.6582, Valid Loss: 0.6743\n",
      "Epoch [14/20], LR: 0.050, Step [1344/1920], Train Loss: 0.6241, Valid Loss: 0.6738\n",
      "time elapsed in epoch: 2.903402328491211\n",
      "Epoch [15/20], LR: 0.054, Step [1348/1920], Train Loss: 0.5943, Valid Loss: 0.6745\n",
      "Epoch [15/20], LR: 0.054, Step [1352/1920], Train Loss: 0.6378, Valid Loss: 0.6751\n",
      "Epoch [15/20], LR: 0.054, Step [1356/1920], Train Loss: 0.6697, Valid Loss: 0.6749\n",
      "Epoch [15/20], LR: 0.054, Step [1360/1920], Train Loss: 0.6788, Valid Loss: 0.6746\n",
      "Epoch [15/20], LR: 0.054, Step [1364/1920], Train Loss: 0.7070, Valid Loss: 0.6739\n",
      "Epoch [15/20], LR: 0.054, Step [1368/1920], Train Loss: 0.6766, Valid Loss: 0.6739\n",
      "Epoch [15/20], LR: 0.054, Step [1372/1920], Train Loss: 0.6841, Valid Loss: 0.6735\n",
      "Epoch [15/20], LR: 0.054, Step [1376/1920], Train Loss: 0.7046, Valid Loss: 0.6734\n",
      "Epoch [15/20], LR: 0.054, Step [1380/1920], Train Loss: 0.6780, Valid Loss: 0.6734\n",
      "Epoch [15/20], LR: 0.054, Step [1384/1920], Train Loss: 0.6725, Valid Loss: 0.6734\n",
      "Epoch [15/20], LR: 0.054, Step [1388/1920], Train Loss: 0.6726, Valid Loss: 0.6734\n",
      "Epoch [15/20], LR: 0.054, Step [1392/1920], Train Loss: 0.7013, Valid Loss: 0.6735\n",
      "Epoch [15/20], LR: 0.054, Step [1396/1920], Train Loss: 0.7014, Valid Loss: 0.6736\n",
      "Epoch [15/20], LR: 0.054, Step [1400/1920], Train Loss: 0.6852, Valid Loss: 0.6736\n",
      "Epoch [15/20], LR: 0.054, Step [1404/1920], Train Loss: 0.6889, Valid Loss: 0.6737\n",
      "Epoch [15/20], LR: 0.054, Step [1408/1920], Train Loss: 0.6959, Valid Loss: 0.6739\n",
      "Epoch [15/20], LR: 0.054, Step [1412/1920], Train Loss: 0.6884, Valid Loss: 0.6744\n",
      "Epoch [15/20], LR: 0.054, Step [1416/1920], Train Loss: 0.6708, Valid Loss: 0.6740\n",
      "Epoch [15/20], LR: 0.054, Step [1420/1920], Train Loss: 0.6736, Valid Loss: 0.6741\n",
      "Epoch [15/20], LR: 0.054, Step [1424/1920], Train Loss: 0.6953, Valid Loss: 0.6742\n",
      "Epoch [15/20], LR: 0.054, Step [1428/1920], Train Loss: 0.6968, Valid Loss: 0.6742\n",
      "Epoch [15/20], LR: 0.054, Step [1432/1920], Train Loss: 0.6791, Valid Loss: 0.6739\n",
      "Epoch [15/20], LR: 0.054, Step [1436/1920], Train Loss: 0.6542, Valid Loss: 0.6734\n",
      "Epoch [15/20], LR: 0.054, Step [1440/1920], Train Loss: 0.6260, Valid Loss: 0.6732\n",
      "time elapsed in epoch: 2.944012403488159\n",
      "Epoch [16/20], LR: 0.058, Step [1444/1920], Train Loss: 0.6050, Valid Loss: 0.6744\n",
      "Epoch [16/20], LR: 0.058, Step [1448/1920], Train Loss: 0.6404, Valid Loss: 0.6754\n",
      "Epoch [16/20], LR: 0.058, Step [1452/1920], Train Loss: 0.6713, Valid Loss: 0.6750\n",
      "Epoch [16/20], LR: 0.058, Step [1456/1920], Train Loss: 0.6769, Valid Loss: 0.6746\n",
      "Epoch [16/20], LR: 0.058, Step [1460/1920], Train Loss: 0.7069, Valid Loss: 0.6737\n",
      "Epoch [16/20], LR: 0.058, Step [1464/1920], Train Loss: 0.6696, Valid Loss: 0.6737\n",
      "Epoch [16/20], LR: 0.058, Step [1468/1920], Train Loss: 0.7045, Valid Loss: 0.6732\n",
      "Epoch [16/20], LR: 0.058, Step [1472/1920], Train Loss: 0.7082, Valid Loss: 0.6730\n",
      "Epoch [16/20], LR: 0.058, Step [1476/1920], Train Loss: 0.6922, Valid Loss: 0.6732\n",
      "Epoch [16/20], LR: 0.058, Step [1480/1920], Train Loss: 0.6645, Valid Loss: 0.6732\n",
      "Epoch [16/20], LR: 0.058, Step [1484/1920], Train Loss: 0.6750, Valid Loss: 0.6732\n",
      "Epoch [16/20], LR: 0.058, Step [1488/1920], Train Loss: 0.7123, Valid Loss: 0.6733\n",
      "Epoch [16/20], LR: 0.058, Step [1492/1920], Train Loss: 0.7023, Valid Loss: 0.6734\n",
      "Epoch [16/20], LR: 0.058, Step [1496/1920], Train Loss: 0.6901, Valid Loss: 0.6735\n",
      "Epoch [16/20], LR: 0.058, Step [1500/1920], Train Loss: 0.6843, Valid Loss: 0.6736\n",
      "Epoch [16/20], LR: 0.058, Step [1504/1920], Train Loss: 0.6951, Valid Loss: 0.6738\n",
      "Epoch [16/20], LR: 0.058, Step [1508/1920], Train Loss: 0.6970, Valid Loss: 0.6742\n",
      "Epoch [16/20], LR: 0.058, Step [1512/1920], Train Loss: 0.6744, Valid Loss: 0.6738\n",
      "Epoch [16/20], LR: 0.058, Step [1516/1920], Train Loss: 0.6824, Valid Loss: 0.6740\n",
      "Epoch [16/20], LR: 0.058, Step [1520/1920], Train Loss: 0.6838, Valid Loss: 0.6742\n",
      "Epoch [16/20], LR: 0.058, Step [1524/1920], Train Loss: 0.6916, Valid Loss: 0.6743\n",
      "Epoch [16/20], LR: 0.058, Step [1528/1920], Train Loss: 0.6806, Valid Loss: 0.6739\n",
      "Epoch [16/20], LR: 0.058, Step [1532/1920], Train Loss: 0.6513, Valid Loss: 0.6733\n",
      "Epoch [16/20], LR: 0.058, Step [1536/1920], Train Loss: 0.6093, Valid Loss: 0.6730\n",
      "time elapsed in epoch: 2.8572635650634766\n",
      "Epoch [17/20], LR: 0.063, Step [1540/1920], Train Loss: 0.6019, Valid Loss: 0.6744\n",
      "Epoch [17/20], LR: 0.063, Step [1544/1920], Train Loss: 0.6287, Valid Loss: 0.6751\n",
      "Epoch [17/20], LR: 0.063, Step [1548/1920], Train Loss: 0.6765, Valid Loss: 0.6749\n",
      "Epoch [17/20], LR: 0.063, Step [1552/1920], Train Loss: 0.6896, Valid Loss: 0.6746\n",
      "Epoch [17/20], LR: 0.063, Step [1556/1920], Train Loss: 0.6987, Valid Loss: 0.6732\n",
      "Epoch [17/20], LR: 0.063, Step [1560/1920], Train Loss: 0.6663, Valid Loss: 0.6731\n",
      "Epoch [17/20], LR: 0.063, Step [1564/1920], Train Loss: 0.6934, Valid Loss: 0.6726\n",
      "Epoch [17/20], LR: 0.063, Step [1568/1920], Train Loss: 0.6994, Valid Loss: 0.6725\n",
      "Epoch [17/20], LR: 0.063, Step [1572/1920], Train Loss: 0.6838, Valid Loss: 0.6726\n",
      "Epoch [17/20], LR: 0.063, Step [1576/1920], Train Loss: 0.6651, Valid Loss: 0.6725\n",
      "Epoch [17/20], LR: 0.063, Step [1580/1920], Train Loss: 0.6860, Valid Loss: 0.6726\n",
      "Epoch [17/20], LR: 0.063, Step [1584/1920], Train Loss: 0.6994, Valid Loss: 0.6727\n",
      "Epoch [17/20], LR: 0.063, Step [1588/1920], Train Loss: 0.7029, Valid Loss: 0.6731\n",
      "Epoch [17/20], LR: 0.063, Step [1592/1920], Train Loss: 0.6819, Valid Loss: 0.6731\n",
      "Epoch [17/20], LR: 0.063, Step [1596/1920], Train Loss: 0.6831, Valid Loss: 0.6732\n",
      "Epoch [17/20], LR: 0.063, Step [1600/1920], Train Loss: 0.6890, Valid Loss: 0.6734\n",
      "Epoch [17/20], LR: 0.063, Step [1604/1920], Train Loss: 0.6931, Valid Loss: 0.6740\n",
      "Epoch [17/20], LR: 0.063, Step [1608/1920], Train Loss: 0.6691, Valid Loss: 0.6735\n",
      "Epoch [17/20], LR: 0.063, Step [1612/1920], Train Loss: 0.6857, Valid Loss: 0.6739\n",
      "Epoch [17/20], LR: 0.063, Step [1616/1920], Train Loss: 0.6921, Valid Loss: 0.6739\n",
      "Epoch [17/20], LR: 0.063, Step [1620/1920], Train Loss: 0.6812, Valid Loss: 0.6741\n",
      "Epoch [17/20], LR: 0.063, Step [1624/1920], Train Loss: 0.6872, Valid Loss: 0.6737\n",
      "Epoch [17/20], LR: 0.063, Step [1628/1920], Train Loss: 0.6586, Valid Loss: 0.6729\n",
      "Epoch [17/20], LR: 0.063, Step [1632/1920], Train Loss: 0.6135, Valid Loss: 0.6724\n",
      "time elapsed in epoch: 2.8247361183166504\n",
      "Epoch [18/20], LR: 0.067, Step [1636/1920], Train Loss: 0.6000, Valid Loss: 0.6736\n",
      "Epoch [18/20], LR: 0.067, Step [1640/1920], Train Loss: 0.6391, Valid Loss: 0.6744\n",
      "Epoch [18/20], LR: 0.067, Step [1644/1920], Train Loss: 0.6738, Valid Loss: 0.6741\n",
      "Epoch [18/20], LR: 0.067, Step [1648/1920], Train Loss: 0.6904, Valid Loss: 0.6735\n",
      "Epoch [18/20], LR: 0.067, Step [1652/1920], Train Loss: 0.7002, Valid Loss: 0.6725\n",
      "Epoch [18/20], LR: 0.067, Step [1656/1920], Train Loss: 0.6631, Valid Loss: 0.6723\n",
      "Epoch [18/20], LR: 0.067, Step [1660/1920], Train Loss: 0.6914, Valid Loss: 0.6720\n",
      "Epoch [18/20], LR: 0.067, Step [1664/1920], Train Loss: 0.6958, Valid Loss: 0.6720\n",
      "Epoch [18/20], LR: 0.067, Step [1668/1920], Train Loss: 0.6835, Valid Loss: 0.6721\n",
      "Epoch [18/20], LR: 0.067, Step [1672/1920], Train Loss: 0.6668, Valid Loss: 0.6720\n",
      "Epoch [18/20], LR: 0.067, Step [1676/1920], Train Loss: 0.6770, Valid Loss: 0.6720\n",
      "Epoch [18/20], LR: 0.067, Step [1680/1920], Train Loss: 0.7011, Valid Loss: 0.6722\n",
      "Epoch [18/20], LR: 0.067, Step [1684/1920], Train Loss: 0.6975, Valid Loss: 0.6723\n",
      "Epoch [18/20], LR: 0.067, Step [1688/1920], Train Loss: 0.6862, Valid Loss: 0.6723\n",
      "Epoch [18/20], LR: 0.067, Step [1692/1920], Train Loss: 0.6861, Valid Loss: 0.6725\n",
      "Epoch [18/20], LR: 0.067, Step [1696/1920], Train Loss: 0.6952, Valid Loss: 0.6728\n",
      "Epoch [18/20], LR: 0.067, Step [1700/1920], Train Loss: 0.6962, Valid Loss: 0.6735\n",
      "Epoch [18/20], LR: 0.067, Step [1704/1920], Train Loss: 0.6740, Valid Loss: 0.6729\n",
      "Epoch [18/20], LR: 0.067, Step [1708/1920], Train Loss: 0.6803, Valid Loss: 0.6729\n",
      "Epoch [18/20], LR: 0.067, Step [1712/1920], Train Loss: 0.6900, Valid Loss: 0.6732\n",
      "Epoch [18/20], LR: 0.067, Step [1716/1920], Train Loss: 0.6875, Valid Loss: 0.6731\n",
      "Epoch [18/20], LR: 0.067, Step [1720/1920], Train Loss: 0.6733, Valid Loss: 0.6724\n",
      "Epoch [18/20], LR: 0.067, Step [1724/1920], Train Loss: 0.6451, Valid Loss: 0.6717\n",
      "Epoch [18/20], LR: 0.067, Step [1728/1920], Train Loss: 0.6011, Valid Loss: 0.6715\n",
      "time elapsed in epoch: 2.723515510559082\n",
      "Epoch [19/20], LR: 0.071, Step [1732/1920], Train Loss: 0.5884, Valid Loss: 0.6730\n",
      "Epoch [19/20], LR: 0.071, Step [1736/1920], Train Loss: 0.6301, Valid Loss: 0.6739\n",
      "Epoch [19/20], LR: 0.071, Step [1740/1920], Train Loss: 0.6690, Valid Loss: 0.6732\n",
      "Epoch [19/20], LR: 0.071, Step [1744/1920], Train Loss: 0.6786, Valid Loss: 0.6725\n",
      "Epoch [19/20], LR: 0.071, Step [1748/1920], Train Loss: 0.7016, Valid Loss: 0.6714\n",
      "Epoch [19/20], LR: 0.071, Step [1752/1920], Train Loss: 0.6687, Valid Loss: 0.6712\n",
      "Epoch [19/20], LR: 0.071, Step [1756/1920], Train Loss: 0.6870, Valid Loss: 0.6709\n",
      "Epoch [19/20], LR: 0.071, Step [1760/1920], Train Loss: 0.7019, Valid Loss: 0.6709\n",
      "Epoch [19/20], LR: 0.071, Step [1764/1920], Train Loss: 0.6781, Valid Loss: 0.6709\n",
      "Epoch [19/20], LR: 0.071, Step [1768/1920], Train Loss: 0.6699, Valid Loss: 0.6710\n",
      "Epoch [19/20], LR: 0.071, Step [1772/1920], Train Loss: 0.6715, Valid Loss: 0.6709\n",
      "Epoch [19/20], LR: 0.071, Step [1776/1920], Train Loss: 0.7177, Valid Loss: 0.6712\n",
      "Epoch [19/20], LR: 0.071, Step [1780/1920], Train Loss: 0.6951, Valid Loss: 0.6714\n",
      "Epoch [19/20], LR: 0.071, Step [1784/1920], Train Loss: 0.6893, Valid Loss: 0.6714\n",
      "Epoch [19/20], LR: 0.071, Step [1788/1920], Train Loss: 0.6804, Valid Loss: 0.6714\n",
      "Epoch [19/20], LR: 0.071, Step [1792/1920], Train Loss: 0.6886, Valid Loss: 0.6717\n",
      "Epoch [19/20], LR: 0.071, Step [1796/1920], Train Loss: 0.6901, Valid Loss: 0.6723\n",
      "Epoch [19/20], LR: 0.071, Step [1800/1920], Train Loss: 0.6785, Valid Loss: 0.6718\n",
      "Epoch [19/20], LR: 0.071, Step [1804/1920], Train Loss: 0.6877, Valid Loss: 0.6719\n",
      "Epoch [19/20], LR: 0.071, Step [1808/1920], Train Loss: 0.6846, Valid Loss: 0.6723\n",
      "Epoch [19/20], LR: 0.071, Step [1812/1920], Train Loss: 0.6876, Valid Loss: 0.6725\n",
      "Epoch [19/20], LR: 0.071, Step [1816/1920], Train Loss: 0.6809, Valid Loss: 0.6720\n",
      "Epoch [19/20], LR: 0.071, Step [1820/1920], Train Loss: 0.6536, Valid Loss: 0.6713\n",
      "Epoch [19/20], LR: 0.071, Step [1824/1920], Train Loss: 0.6290, Valid Loss: 0.6714\n",
      "time elapsed in epoch: 2.6017048358917236\n",
      "Epoch [20/20], LR: 0.075, Step [1828/1920], Train Loss: 0.5839, Valid Loss: 0.6738\n",
      "Epoch [20/20], LR: 0.075, Step [1832/1920], Train Loss: 0.6456, Valid Loss: 0.6751\n",
      "Epoch [20/20], LR: 0.075, Step [1836/1920], Train Loss: 0.6744, Valid Loss: 0.6741\n",
      "Epoch [20/20], LR: 0.075, Step [1840/1920], Train Loss: 0.6958, Valid Loss: 0.6733\n",
      "Epoch [20/20], LR: 0.075, Step [1844/1920], Train Loss: 0.7109, Valid Loss: 0.6717\n",
      "Epoch [20/20], LR: 0.075, Step [1848/1920], Train Loss: 0.6703, Valid Loss: 0.6716\n",
      "Epoch [20/20], LR: 0.075, Step [1852/1920], Train Loss: 0.6969, Valid Loss: 0.6710\n",
      "Epoch [20/20], LR: 0.075, Step [1856/1920], Train Loss: 0.6998, Valid Loss: 0.6710\n",
      "Epoch [20/20], LR: 0.075, Step [1860/1920], Train Loss: 0.6843, Valid Loss: 0.6710\n",
      "Epoch [20/20], LR: 0.075, Step [1864/1920], Train Loss: 0.6674, Valid Loss: 0.6710\n",
      "Epoch [20/20], LR: 0.075, Step [1868/1920], Train Loss: 0.6743, Valid Loss: 0.6710\n",
      "Epoch [20/20], LR: 0.075, Step [1872/1920], Train Loss: 0.6995, Valid Loss: 0.6710\n",
      "Epoch [20/20], LR: 0.075, Step [1876/1920], Train Loss: 0.6952, Valid Loss: 0.6712\n",
      "Epoch [20/20], LR: 0.075, Step [1880/1920], Train Loss: 0.6866, Valid Loss: 0.6712\n",
      "Epoch [20/20], LR: 0.075, Step [1884/1920], Train Loss: 0.6764, Valid Loss: 0.6716\n",
      "Epoch [20/20], LR: 0.075, Step [1888/1920], Train Loss: 0.6817, Valid Loss: 0.6719\n",
      "Epoch [20/20], LR: 0.075, Step [1892/1920], Train Loss: 0.6846, Valid Loss: 0.6730\n",
      "Epoch [20/20], LR: 0.075, Step [1896/1920], Train Loss: 0.6809, Valid Loss: 0.6717\n",
      "Epoch [20/20], LR: 0.075, Step [1900/1920], Train Loss: 0.6849, Valid Loss: 0.6718\n",
      "Epoch [20/20], LR: 0.075, Step [1904/1920], Train Loss: 0.6901, Valid Loss: 0.6719\n",
      "Epoch [20/20], LR: 0.075, Step [1908/1920], Train Loss: 0.6790, Valid Loss: 0.6719\n",
      "Epoch [20/20], LR: 0.075, Step [1912/1920], Train Loss: 0.6954, Valid Loss: 0.6716\n",
      "Epoch [20/20], LR: 0.075, Step [1916/1920], Train Loss: 0.6493, Valid Loss: 0.6708\n",
      "Epoch [20/20], LR: 0.075, Step [1920/1920], Train Loss: 0.6224, Valid Loss: 0.6709\n",
      "time elapsed in epoch: 2.689769744873047\n",
      "Finished Training!\n"
     ]
    }
   ],
   "source": [
    "!python train_rnn.py --flor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle-nlp-dist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "815c30a49f552e6fdb87f74e117ecdf18b0ca5a01ddc5c83796985c2fbc2bb40"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
