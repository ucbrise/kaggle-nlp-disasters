{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to run your experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rogarcia/anaconda3/envs/kaggle-nlp-dist/lib/python3.9/site-packages/torchtext/data/utils.py:123: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
      "  warnings.warn(f'Spacy model \"{language}\" could not be loaded, trying \"{OLD_MODEL_SHORTCUTS[language]}\" instead')\n",
      "Epoch [1/20], LR: 0.000, Step [4/1920], Train Loss: 0.6898, Valid Loss: 0.6962\n",
      "Epoch [1/20], LR: 0.000, Step [8/1920], Train Loss: 0.6899, Valid Loss: 0.6962\n",
      "Epoch [1/20], LR: 0.000, Step [12/1920], Train Loss: 0.7075, Valid Loss: 0.6962\n",
      "Epoch [1/20], LR: 0.000, Step [16/1920], Train Loss: 0.7186, Valid Loss: 0.6962\n",
      "Epoch [1/20], LR: 0.000, Step [20/1920], Train Loss: 0.7038, Valid Loss: 0.6962\n",
      "Epoch [1/20], LR: 0.000, Step [24/1920], Train Loss: 0.7040, Valid Loss: 0.6961\n",
      "Epoch [1/20], LR: 0.000, Step [28/1920], Train Loss: 0.7023, Valid Loss: 0.6961\n",
      "Epoch [1/20], LR: 0.000, Step [32/1920], Train Loss: 0.6922, Valid Loss: 0.6961\n",
      "Epoch [1/20], LR: 0.000, Step [36/1920], Train Loss: 0.7055, Valid Loss: 0.6961\n",
      "Epoch [1/20], LR: 0.000, Step [40/1920], Train Loss: 0.7007, Valid Loss: 0.6961\n",
      "Epoch [1/20], LR: 0.000, Step [44/1920], Train Loss: 0.6906, Valid Loss: 0.6961\n",
      "Epoch [1/20], LR: 0.000, Step [48/1920], Train Loss: 0.7007, Valid Loss: 0.6961\n",
      "Epoch [1/20], LR: 0.000, Step [52/1920], Train Loss: 0.6901, Valid Loss: 0.6961\n",
      "Epoch [1/20], LR: 0.000, Step [56/1920], Train Loss: 0.7125, Valid Loss: 0.6961\n",
      "Epoch [1/20], LR: 0.000, Step [60/1920], Train Loss: 0.6923, Valid Loss: 0.6961\n",
      "Epoch [1/20], LR: 0.000, Step [64/1920], Train Loss: 0.6913, Valid Loss: 0.6961\n",
      "Epoch [1/20], LR: 0.000, Step [68/1920], Train Loss: 0.7099, Valid Loss: 0.6961\n",
      "Epoch [1/20], LR: 0.000, Step [72/1920], Train Loss: 0.7022, Valid Loss: 0.6961\n",
      "Epoch [1/20], LR: 0.000, Step [76/1920], Train Loss: 0.7169, Valid Loss: 0.6961\n",
      "Epoch [1/20], LR: 0.000, Step [80/1920], Train Loss: 0.7038, Valid Loss: 0.6961\n",
      "Epoch [1/20], LR: 0.000, Step [84/1920], Train Loss: 0.6867, Valid Loss: 0.6961\n",
      "Epoch [1/20], LR: 0.000, Step [88/1920], Train Loss: 0.7049, Valid Loss: 0.6961\n",
      "Epoch [1/20], LR: 0.000, Step [92/1920], Train Loss: 0.7029, Valid Loss: 0.6961\n",
      "Epoch [1/20], LR: 0.000, Step [96/1920], Train Loss: 0.7143, Valid Loss: 0.6961\n",
      "time elapsed in epoch: 2.0308916568756104\n",
      "Epoch [2/20], LR: 0.000, Step [100/1920], Train Loss: 0.7052, Valid Loss: 0.6961\n",
      "Epoch [2/20], LR: 0.000, Step [104/1920], Train Loss: 0.7182, Valid Loss: 0.6960\n",
      "Epoch [2/20], LR: 0.000, Step [108/1920], Train Loss: 0.7104, Valid Loss: 0.6960\n",
      "Epoch [2/20], LR: 0.000, Step [112/1920], Train Loss: 0.7065, Valid Loss: 0.6960\n",
      "Epoch [2/20], LR: 0.000, Step [116/1920], Train Loss: 0.7082, Valid Loss: 0.6960\n",
      "Epoch [2/20], LR: 0.000, Step [120/1920], Train Loss: 0.7092, Valid Loss: 0.6960\n",
      "Epoch [2/20], LR: 0.000, Step [124/1920], Train Loss: 0.6840, Valid Loss: 0.6960\n",
      "Epoch [2/20], LR: 0.000, Step [128/1920], Train Loss: 0.7111, Valid Loss: 0.6960\n",
      "Epoch [2/20], LR: 0.000, Step [132/1920], Train Loss: 0.7079, Valid Loss: 0.6960\n",
      "Epoch [2/20], LR: 0.000, Step [136/1920], Train Loss: 0.6920, Valid Loss: 0.6960\n",
      "Epoch [2/20], LR: 0.000, Step [140/1920], Train Loss: 0.7001, Valid Loss: 0.6960\n",
      "Epoch [2/20], LR: 0.000, Step [144/1920], Train Loss: 0.6919, Valid Loss: 0.6960\n",
      "Epoch [2/20], LR: 0.000, Step [148/1920], Train Loss: 0.6969, Valid Loss: 0.6960\n",
      "Epoch [2/20], LR: 0.000, Step [152/1920], Train Loss: 0.7151, Valid Loss: 0.6960\n",
      "Epoch [2/20], LR: 0.000, Step [156/1920], Train Loss: 0.6949, Valid Loss: 0.6960\n",
      "Epoch [2/20], LR: 0.000, Step [160/1920], Train Loss: 0.7089, Valid Loss: 0.6960\n",
      "Epoch [2/20], LR: 0.000, Step [164/1920], Train Loss: 0.6973, Valid Loss: 0.6960\n",
      "Epoch [2/20], LR: 0.000, Step [168/1920], Train Loss: 0.6944, Valid Loss: 0.6960\n",
      "Epoch [2/20], LR: 0.000, Step [172/1920], Train Loss: 0.6916, Valid Loss: 0.6960\n",
      "Epoch [2/20], LR: 0.000, Step [176/1920], Train Loss: 0.7066, Valid Loss: 0.6960\n",
      "Epoch [2/20], LR: 0.000, Step [180/1920], Train Loss: 0.7113, Valid Loss: 0.6960\n",
      "Epoch [2/20], LR: 0.000, Step [184/1920], Train Loss: 0.7087, Valid Loss: 0.6960\n",
      "Epoch [2/20], LR: 0.000, Step [188/1920], Train Loss: 0.7147, Valid Loss: 0.6960\n",
      "Epoch [2/20], LR: 0.000, Step [192/1920], Train Loss: 0.7250, Valid Loss: 0.6960\n",
      "time elapsed in epoch: 1.9718928337097168\n",
      "Epoch [3/20], LR: 0.004, Step [196/1920], Train Loss: 0.7027, Valid Loss: 0.6953\n",
      "Epoch [3/20], LR: 0.004, Step [200/1920], Train Loss: 0.7209, Valid Loss: 0.6949\n",
      "Epoch [3/20], LR: 0.004, Step [204/1920], Train Loss: 0.6975, Valid Loss: 0.6947\n",
      "Epoch [3/20], LR: 0.004, Step [208/1920], Train Loss: 0.7103, Valid Loss: 0.6945\n",
      "Epoch [3/20], LR: 0.004, Step [212/1920], Train Loss: 0.7005, Valid Loss: 0.6945\n",
      "Epoch [3/20], LR: 0.004, Step [216/1920], Train Loss: 0.7014, Valid Loss: 0.6943\n",
      "Epoch [3/20], LR: 0.004, Step [220/1920], Train Loss: 0.6971, Valid Loss: 0.6943\n",
      "Epoch [3/20], LR: 0.004, Step [224/1920], Train Loss: 0.7154, Valid Loss: 0.6944\n",
      "Epoch [3/20], LR: 0.004, Step [228/1920], Train Loss: 0.7180, Valid Loss: 0.6943\n",
      "Epoch [3/20], LR: 0.004, Step [232/1920], Train Loss: 0.7131, Valid Loss: 0.6940\n",
      "Epoch [3/20], LR: 0.004, Step [236/1920], Train Loss: 0.7078, Valid Loss: 0.6938\n",
      "Epoch [3/20], LR: 0.004, Step [240/1920], Train Loss: 0.7229, Valid Loss: 0.6938\n",
      "Epoch [3/20], LR: 0.004, Step [244/1920], Train Loss: 0.7034, Valid Loss: 0.6938\n",
      "Epoch [3/20], LR: 0.004, Step [248/1920], Train Loss: 0.7114, Valid Loss: 0.6938\n",
      "Epoch [3/20], LR: 0.004, Step [252/1920], Train Loss: 0.6880, Valid Loss: 0.6937\n",
      "Epoch [3/20], LR: 0.004, Step [256/1920], Train Loss: 0.6965, Valid Loss: 0.6937\n",
      "Epoch [3/20], LR: 0.004, Step [260/1920], Train Loss: 0.7043, Valid Loss: 0.6938\n",
      "Epoch [3/20], LR: 0.004, Step [264/1920], Train Loss: 0.6936, Valid Loss: 0.6936\n",
      "Epoch [3/20], LR: 0.004, Step [268/1920], Train Loss: 0.7046, Valid Loss: 0.6935\n",
      "Epoch [3/20], LR: 0.004, Step [272/1920], Train Loss: 0.7176, Valid Loss: 0.6935\n",
      "Epoch [3/20], LR: 0.004, Step [276/1920], Train Loss: 0.7117, Valid Loss: 0.6935\n",
      "Epoch [3/20], LR: 0.004, Step [280/1920], Train Loss: 0.7086, Valid Loss: 0.6933\n",
      "Epoch [3/20], LR: 0.004, Step [284/1920], Train Loss: 0.6881, Valid Loss: 0.6930\n",
      "Epoch [3/20], LR: 0.004, Step [288/1920], Train Loss: 0.6954, Valid Loss: 0.6925\n",
      "time elapsed in epoch: 2.113510847091675\n",
      "Epoch [4/20], LR: 0.008, Step [292/1920], Train Loss: 0.6943, Valid Loss: 0.6913\n",
      "Epoch [4/20], LR: 0.008, Step [296/1920], Train Loss: 0.6898, Valid Loss: 0.6907\n",
      "Epoch [4/20], LR: 0.008, Step [300/1920], Train Loss: 0.6914, Valid Loss: 0.6905\n",
      "Epoch [4/20], LR: 0.008, Step [304/1920], Train Loss: 0.6884, Valid Loss: 0.6903\n",
      "Epoch [4/20], LR: 0.008, Step [308/1920], Train Loss: 0.7079, Valid Loss: 0.6904\n",
      "Epoch [4/20], LR: 0.008, Step [312/1920], Train Loss: 0.6927, Valid Loss: 0.6901\n",
      "Epoch [4/20], LR: 0.008, Step [316/1920], Train Loss: 0.6837, Valid Loss: 0.6900\n",
      "Epoch [4/20], LR: 0.008, Step [320/1920], Train Loss: 0.6968, Valid Loss: 0.6901\n",
      "Epoch [4/20], LR: 0.008, Step [324/1920], Train Loss: 0.6931, Valid Loss: 0.6900\n",
      "Epoch [4/20], LR: 0.008, Step [328/1920], Train Loss: 0.6983, Valid Loss: 0.6897\n",
      "Epoch [4/20], LR: 0.008, Step [332/1920], Train Loss: 0.6967, Valid Loss: 0.6895\n",
      "Epoch [4/20], LR: 0.008, Step [336/1920], Train Loss: 0.7051, Valid Loss: 0.6895\n",
      "Epoch [4/20], LR: 0.008, Step [340/1920], Train Loss: 0.7046, Valid Loss: 0.6896\n",
      "Epoch [4/20], LR: 0.008, Step [344/1920], Train Loss: 0.7041, Valid Loss: 0.6894\n",
      "Epoch [4/20], LR: 0.008, Step [348/1920], Train Loss: 0.7025, Valid Loss: 0.6894\n",
      "Epoch [4/20], LR: 0.008, Step [352/1920], Train Loss: 0.7063, Valid Loss: 0.6895\n",
      "Epoch [4/20], LR: 0.008, Step [356/1920], Train Loss: 0.7143, Valid Loss: 0.6896\n",
      "Epoch [4/20], LR: 0.008, Step [360/1920], Train Loss: 0.6987, Valid Loss: 0.6894\n",
      "Epoch [4/20], LR: 0.008, Step [364/1920], Train Loss: 0.6858, Valid Loss: 0.6893\n",
      "Epoch [4/20], LR: 0.008, Step [368/1920], Train Loss: 0.7013, Valid Loss: 0.6894\n",
      "Epoch [4/20], LR: 0.008, Step [372/1920], Train Loss: 0.6977, Valid Loss: 0.6893\n",
      "Epoch [4/20], LR: 0.008, Step [376/1920], Train Loss: 0.7026, Valid Loss: 0.6891\n",
      "Epoch [4/20], LR: 0.008, Step [380/1920], Train Loss: 0.6866, Valid Loss: 0.6886\n",
      "Epoch [4/20], LR: 0.008, Step [384/1920], Train Loss: 0.6718, Valid Loss: 0.6878\n",
      "time elapsed in epoch: 2.165177822113037\n",
      "Epoch [5/20], LR: 0.013, Step [388/1920], Train Loss: 0.6773, Valid Loss: 0.6867\n",
      "Epoch [5/20], LR: 0.013, Step [392/1920], Train Loss: 0.6768, Valid Loss: 0.6861\n",
      "Epoch [5/20], LR: 0.013, Step [396/1920], Train Loss: 0.6944, Valid Loss: 0.6859\n",
      "Epoch [5/20], LR: 0.013, Step [400/1920], Train Loss: 0.7032, Valid Loss: 0.6857\n",
      "Epoch [5/20], LR: 0.013, Step [404/1920], Train Loss: 0.7027, Valid Loss: 0.6858\n",
      "Epoch [5/20], LR: 0.013, Step [408/1920], Train Loss: 0.6879, Valid Loss: 0.6856\n",
      "Epoch [5/20], LR: 0.013, Step [412/1920], Train Loss: 0.7011, Valid Loss: 0.6856\n",
      "Epoch [5/20], LR: 0.013, Step [416/1920], Train Loss: 0.6916, Valid Loss: 0.6857\n",
      "Epoch [5/20], LR: 0.013, Step [420/1920], Train Loss: 0.6875, Valid Loss: 0.6856\n",
      "Epoch [5/20], LR: 0.013, Step [424/1920], Train Loss: 0.6862, Valid Loss: 0.6854\n",
      "Epoch [5/20], LR: 0.013, Step [428/1920], Train Loss: 0.6967, Valid Loss: 0.6852\n",
      "Epoch [5/20], LR: 0.013, Step [432/1920], Train Loss: 0.6922, Valid Loss: 0.6853\n",
      "Epoch [5/20], LR: 0.013, Step [436/1920], Train Loss: 0.7132, Valid Loss: 0.6855\n",
      "Epoch [5/20], LR: 0.013, Step [440/1920], Train Loss: 0.6953, Valid Loss: 0.6854\n",
      "Epoch [5/20], LR: 0.013, Step [444/1920], Train Loss: 0.7065, Valid Loss: 0.6855\n",
      "Epoch [5/20], LR: 0.013, Step [448/1920], Train Loss: 0.7013, Valid Loss: 0.6856\n",
      "Epoch [5/20], LR: 0.013, Step [452/1920], Train Loss: 0.6937, Valid Loss: 0.6858\n",
      "Epoch [5/20], LR: 0.013, Step [456/1920], Train Loss: 0.6873, Valid Loss: 0.6857\n",
      "Epoch [5/20], LR: 0.013, Step [460/1920], Train Loss: 0.6913, Valid Loss: 0.6857\n",
      "Epoch [5/20], LR: 0.013, Step [464/1920], Train Loss: 0.6937, Valid Loss: 0.6858\n",
      "Epoch [5/20], LR: 0.013, Step [468/1920], Train Loss: 0.6989, Valid Loss: 0.6858\n",
      "Epoch [5/20], LR: 0.013, Step [472/1920], Train Loss: 0.6995, Valid Loss: 0.6856\n",
      "Epoch [5/20], LR: 0.013, Step [476/1920], Train Loss: 0.6818, Valid Loss: 0.6852\n",
      "Epoch [5/20], LR: 0.013, Step [480/1920], Train Loss: 0.6653, Valid Loss: 0.6846\n",
      "time elapsed in epoch: 2.305913209915161\n",
      "Epoch [6/20], LR: 0.017, Step [484/1920], Train Loss: 0.6463, Valid Loss: 0.6837\n",
      "Epoch [6/20], LR: 0.017, Step [488/1920], Train Loss: 0.6736, Valid Loss: 0.6833\n",
      "Epoch [6/20], LR: 0.017, Step [492/1920], Train Loss: 0.6853, Valid Loss: 0.6832\n",
      "Epoch [6/20], LR: 0.017, Step [496/1920], Train Loss: 0.6985, Valid Loss: 0.6832\n",
      "Epoch [6/20], LR: 0.017, Step [500/1920], Train Loss: 0.6984, Valid Loss: 0.6833\n",
      "Epoch [6/20], LR: 0.017, Step [504/1920], Train Loss: 0.6892, Valid Loss: 0.6832\n",
      "Epoch [6/20], LR: 0.017, Step [508/1920], Train Loss: 0.6860, Valid Loss: 0.6833\n",
      "Epoch [6/20], LR: 0.017, Step [512/1920], Train Loss: 0.7075, Valid Loss: 0.6835\n",
      "Epoch [6/20], LR: 0.017, Step [516/1920], Train Loss: 0.6808, Valid Loss: 0.6835\n",
      "Epoch [6/20], LR: 0.017, Step [520/1920], Train Loss: 0.6814, Valid Loss: 0.6833\n",
      "Epoch [6/20], LR: 0.017, Step [524/1920], Train Loss: 0.6898, Valid Loss: 0.6832\n",
      "Epoch [6/20], LR: 0.017, Step [528/1920], Train Loss: 0.7038, Valid Loss: 0.6833\n",
      "Epoch [6/20], LR: 0.017, Step [532/1920], Train Loss: 0.7110, Valid Loss: 0.6835\n",
      "Epoch [6/20], LR: 0.017, Step [536/1920], Train Loss: 0.6976, Valid Loss: 0.6835\n",
      "Epoch [6/20], LR: 0.017, Step [540/1920], Train Loss: 0.6987, Valid Loss: 0.6835\n",
      "Epoch [6/20], LR: 0.017, Step [544/1920], Train Loss: 0.6950, Valid Loss: 0.6837\n",
      "Epoch [6/20], LR: 0.017, Step [548/1920], Train Loss: 0.6979, Valid Loss: 0.6839\n",
      "Epoch [6/20], LR: 0.017, Step [552/1920], Train Loss: 0.6948, Valid Loss: 0.6838\n",
      "Epoch [6/20], LR: 0.017, Step [556/1920], Train Loss: 0.6887, Valid Loss: 0.6838\n",
      "Epoch [6/20], LR: 0.017, Step [560/1920], Train Loss: 0.6978, Valid Loss: 0.6839\n",
      "Epoch [6/20], LR: 0.017, Step [564/1920], Train Loss: 0.7037, Valid Loss: 0.6841\n",
      "Epoch [6/20], LR: 0.017, Step [568/1920], Train Loss: 0.6965, Valid Loss: 0.6839\n",
      "Epoch [6/20], LR: 0.017, Step [572/1920], Train Loss: 0.6661, Valid Loss: 0.6835\n",
      "Epoch [6/20], LR: 0.017, Step [576/1920], Train Loss: 0.6424, Valid Loss: 0.6828\n",
      "time elapsed in epoch: 2.355746030807495\n",
      "Epoch [7/20], LR: 0.021, Step [580/1920], Train Loss: 0.6445, Valid Loss: 0.6822\n",
      "Epoch [7/20], LR: 0.021, Step [584/1920], Train Loss: 0.6771, Valid Loss: 0.6820\n",
      "Epoch [7/20], LR: 0.021, Step [588/1920], Train Loss: 0.6821, Valid Loss: 0.6819\n",
      "Epoch [7/20], LR: 0.021, Step [592/1920], Train Loss: 0.6899, Valid Loss: 0.6819\n",
      "Epoch [7/20], LR: 0.021, Step [596/1920], Train Loss: 0.7065, Valid Loss: 0.6820\n",
      "Epoch [7/20], LR: 0.021, Step [600/1920], Train Loss: 0.6866, Valid Loss: 0.6820\n",
      "Epoch [7/20], LR: 0.021, Step [604/1920], Train Loss: 0.6929, Valid Loss: 0.6821\n",
      "Epoch [7/20], LR: 0.021, Step [608/1920], Train Loss: 0.7054, Valid Loss: 0.6822\n",
      "Epoch [7/20], LR: 0.021, Step [612/1920], Train Loss: 0.6885, Valid Loss: 0.6822\n",
      "Epoch [7/20], LR: 0.021, Step [616/1920], Train Loss: 0.6759, Valid Loss: 0.6821\n",
      "Epoch [7/20], LR: 0.021, Step [620/1920], Train Loss: 0.6872, Valid Loss: 0.6820\n",
      "Epoch [7/20], LR: 0.021, Step [624/1920], Train Loss: 0.6863, Valid Loss: 0.6821\n",
      "Epoch [7/20], LR: 0.021, Step [628/1920], Train Loss: 0.7087, Valid Loss: 0.6823\n",
      "Epoch [7/20], LR: 0.021, Step [632/1920], Train Loss: 0.6992, Valid Loss: 0.6823\n",
      "Epoch [7/20], LR: 0.021, Step [636/1920], Train Loss: 0.6980, Valid Loss: 0.6824\n",
      "Epoch [7/20], LR: 0.021, Step [640/1920], Train Loss: 0.7008, Valid Loss: 0.6825\n",
      "Epoch [7/20], LR: 0.021, Step [644/1920], Train Loss: 0.7073, Valid Loss: 0.6828\n",
      "Epoch [7/20], LR: 0.021, Step [648/1920], Train Loss: 0.6874, Valid Loss: 0.6827\n",
      "Epoch [7/20], LR: 0.021, Step [652/1920], Train Loss: 0.6996, Valid Loss: 0.6827\n",
      "Epoch [7/20], LR: 0.021, Step [656/1920], Train Loss: 0.7106, Valid Loss: 0.6828\n",
      "Epoch [7/20], LR: 0.021, Step [660/1920], Train Loss: 0.6973, Valid Loss: 0.6829\n",
      "Epoch [7/20], LR: 0.021, Step [664/1920], Train Loss: 0.6841, Valid Loss: 0.6828\n",
      "Epoch [7/20], LR: 0.021, Step [668/1920], Train Loss: 0.6613, Valid Loss: 0.6823\n",
      "Epoch [7/20], LR: 0.021, Step [672/1920], Train Loss: 0.6536, Valid Loss: 0.6819\n",
      "time elapsed in epoch: 2.336236000061035\n",
      "Epoch [8/20], LR: 0.025, Step [676/1920], Train Loss: 0.6262, Valid Loss: 0.6815\n",
      "Epoch [8/20], LR: 0.025, Step [680/1920], Train Loss: 0.6463, Valid Loss: 0.6814\n",
      "Epoch [8/20], LR: 0.025, Step [684/1920], Train Loss: 0.6804, Valid Loss: 0.6814\n",
      "Epoch [8/20], LR: 0.025, Step [688/1920], Train Loss: 0.6864, Valid Loss: 0.6814\n",
      "Epoch [8/20], LR: 0.025, Step [692/1920], Train Loss: 0.7085, Valid Loss: 0.6814\n",
      "Epoch [8/20], LR: 0.025, Step [696/1920], Train Loss: 0.6778, Valid Loss: 0.6814\n",
      "Epoch [8/20], LR: 0.025, Step [700/1920], Train Loss: 0.6996, Valid Loss: 0.6814\n",
      "Epoch [8/20], LR: 0.025, Step [704/1920], Train Loss: 0.7004, Valid Loss: 0.6815\n",
      "Epoch [8/20], LR: 0.025, Step [708/1920], Train Loss: 0.6895, Valid Loss: 0.6815\n",
      "Epoch [8/20], LR: 0.025, Step [712/1920], Train Loss: 0.6763, Valid Loss: 0.6814\n",
      "Epoch [8/20], LR: 0.025, Step [716/1920], Train Loss: 0.6828, Valid Loss: 0.6814\n",
      "Epoch [8/20], LR: 0.025, Step [720/1920], Train Loss: 0.7058, Valid Loss: 0.6815\n",
      "Epoch [8/20], LR: 0.025, Step [724/1920], Train Loss: 0.6981, Valid Loss: 0.6816\n",
      "Epoch [8/20], LR: 0.025, Step [728/1920], Train Loss: 0.6876, Valid Loss: 0.6816\n",
      "Epoch [8/20], LR: 0.025, Step [732/1920], Train Loss: 0.6902, Valid Loss: 0.6817\n",
      "Epoch [8/20], LR: 0.025, Step [736/1920], Train Loss: 0.6933, Valid Loss: 0.6818\n",
      "Epoch [8/20], LR: 0.025, Step [740/1920], Train Loss: 0.7121, Valid Loss: 0.6820\n",
      "Epoch [8/20], LR: 0.025, Step [744/1920], Train Loss: 0.6821, Valid Loss: 0.6820\n",
      "Epoch [8/20], LR: 0.025, Step [748/1920], Train Loss: 0.6975, Valid Loss: 0.6821\n",
      "Epoch [8/20], LR: 0.025, Step [752/1920], Train Loss: 0.6956, Valid Loss: 0.6822\n",
      "Epoch [8/20], LR: 0.025, Step [756/1920], Train Loss: 0.6907, Valid Loss: 0.6822\n",
      "Epoch [8/20], LR: 0.025, Step [760/1920], Train Loss: 0.6775, Valid Loss: 0.6820\n",
      "Epoch [8/20], LR: 0.025, Step [764/1920], Train Loss: 0.6576, Valid Loss: 0.6816\n",
      "Epoch [8/20], LR: 0.025, Step [768/1920], Train Loss: 0.6324, Valid Loss: 0.6812\n",
      "time elapsed in epoch: 2.171442747116089\n",
      "Epoch [9/20], LR: 0.029, Step [772/1920], Train Loss: 0.6199, Valid Loss: 0.6811\n",
      "Epoch [9/20], LR: 0.029, Step [776/1920], Train Loss: 0.6597, Valid Loss: 0.6811\n",
      "Epoch [9/20], LR: 0.029, Step [780/1920], Train Loss: 0.6793, Valid Loss: 0.6811\n",
      "Epoch [9/20], LR: 0.029, Step [784/1920], Train Loss: 0.6946, Valid Loss: 0.6810\n",
      "Epoch [9/20], LR: 0.029, Step [788/1920], Train Loss: 0.7080, Valid Loss: 0.6809\n",
      "Epoch [9/20], LR: 0.029, Step [792/1920], Train Loss: 0.6718, Valid Loss: 0.6809\n",
      "Epoch [9/20], LR: 0.029, Step [796/1920], Train Loss: 0.6949, Valid Loss: 0.6809\n",
      "Epoch [9/20], LR: 0.029, Step [800/1920], Train Loss: 0.7094, Valid Loss: 0.6810\n",
      "Epoch [9/20], LR: 0.029, Step [804/1920], Train Loss: 0.6851, Valid Loss: 0.6810\n",
      "Epoch [9/20], LR: 0.029, Step [808/1920], Train Loss: 0.6692, Valid Loss: 0.6809\n",
      "Epoch [9/20], LR: 0.029, Step [812/1920], Train Loss: 0.6890, Valid Loss: 0.6809\n",
      "Epoch [9/20], LR: 0.029, Step [816/1920], Train Loss: 0.6985, Valid Loss: 0.6809\n",
      "Epoch [9/20], LR: 0.029, Step [820/1920], Train Loss: 0.7070, Valid Loss: 0.6810\n",
      "Epoch [9/20], LR: 0.029, Step [824/1920], Train Loss: 0.6999, Valid Loss: 0.6810\n",
      "Epoch [9/20], LR: 0.029, Step [828/1920], Train Loss: 0.6913, Valid Loss: 0.6811\n",
      "Epoch [9/20], LR: 0.029, Step [832/1920], Train Loss: 0.6966, Valid Loss: 0.6812\n",
      "Epoch [9/20], LR: 0.029, Step [836/1920], Train Loss: 0.7003, Valid Loss: 0.6814\n",
      "Epoch [9/20], LR: 0.029, Step [840/1920], Train Loss: 0.6818, Valid Loss: 0.6813\n",
      "Epoch [9/20], LR: 0.029, Step [844/1920], Train Loss: 0.6925, Valid Loss: 0.6814\n",
      "Epoch [9/20], LR: 0.029, Step [848/1920], Train Loss: 0.6989, Valid Loss: 0.6815\n",
      "Epoch [9/20], LR: 0.029, Step [852/1920], Train Loss: 0.6916, Valid Loss: 0.6817\n",
      "Epoch [9/20], LR: 0.029, Step [856/1920], Train Loss: 0.6832, Valid Loss: 0.6815\n",
      "Epoch [9/20], LR: 0.029, Step [860/1920], Train Loss: 0.6626, Valid Loss: 0.6811\n",
      "Epoch [9/20], LR: 0.029, Step [864/1920], Train Loss: 0.6417, Valid Loss: 0.6807\n",
      "time elapsed in epoch: 2.0161004066467285\n",
      "Epoch [10/20], LR: 0.033, Step [868/1920], Train Loss: 0.6235, Valid Loss: 0.6808\n",
      "Epoch [10/20], LR: 0.033, Step [872/1920], Train Loss: 0.6462, Valid Loss: 0.6809\n",
      "Epoch [10/20], LR: 0.033, Step [876/1920], Train Loss: 0.6793, Valid Loss: 0.6809\n",
      "Epoch [10/20], LR: 0.033, Step [880/1920], Train Loss: 0.6918, Valid Loss: 0.6808\n",
      "Epoch [10/20], LR: 0.033, Step [884/1920], Train Loss: 0.7075, Valid Loss: 0.6807\n",
      "Epoch [10/20], LR: 0.033, Step [888/1920], Train Loss: 0.6805, Valid Loss: 0.6806\n",
      "Epoch [10/20], LR: 0.033, Step [892/1920], Train Loss: 0.6965, Valid Loss: 0.6806\n",
      "Epoch [10/20], LR: 0.033, Step [896/1920], Train Loss: 0.7040, Valid Loss: 0.6806\n",
      "Epoch [10/20], LR: 0.033, Step [900/1920], Train Loss: 0.6883, Valid Loss: 0.6806\n",
      "Epoch [10/20], LR: 0.033, Step [904/1920], Train Loss: 0.6729, Valid Loss: 0.6805\n",
      "Epoch [10/20], LR: 0.033, Step [908/1920], Train Loss: 0.6822, Valid Loss: 0.6805\n",
      "Epoch [10/20], LR: 0.033, Step [912/1920], Train Loss: 0.6986, Valid Loss: 0.6805\n",
      "Epoch [10/20], LR: 0.033, Step [916/1920], Train Loss: 0.7051, Valid Loss: 0.6806\n",
      "Epoch [10/20], LR: 0.033, Step [920/1920], Train Loss: 0.6922, Valid Loss: 0.6807\n",
      "Epoch [10/20], LR: 0.033, Step [924/1920], Train Loss: 0.6936, Valid Loss: 0.6807\n",
      "Epoch [10/20], LR: 0.033, Step [928/1920], Train Loss: 0.6974, Valid Loss: 0.6809\n",
      "Epoch [10/20], LR: 0.033, Step [932/1920], Train Loss: 0.7042, Valid Loss: 0.6812\n",
      "Epoch [10/20], LR: 0.033, Step [936/1920], Train Loss: 0.6857, Valid Loss: 0.6811\n",
      "Epoch [10/20], LR: 0.033, Step [940/1920], Train Loss: 0.6936, Valid Loss: 0.6812\n",
      "Epoch [10/20], LR: 0.033, Step [944/1920], Train Loss: 0.6920, Valid Loss: 0.6813\n",
      "Epoch [10/20], LR: 0.033, Step [948/1920], Train Loss: 0.6900, Valid Loss: 0.6815\n",
      "Epoch [10/20], LR: 0.033, Step [952/1920], Train Loss: 0.6784, Valid Loss: 0.6812\n",
      "Epoch [10/20], LR: 0.033, Step [956/1920], Train Loss: 0.6563, Valid Loss: 0.6808\n",
      "Epoch [10/20], LR: 0.033, Step [960/1920], Train Loss: 0.6364, Valid Loss: 0.6805\n",
      "time elapsed in epoch: 2.2774195671081543\n",
      "Epoch [11/20], LR: 0.038, Step [964/1920], Train Loss: 0.6133, Valid Loss: 0.6805\n",
      "Epoch [11/20], LR: 0.038, Step [968/1920], Train Loss: 0.6465, Valid Loss: 0.6806\n",
      "Epoch [11/20], LR: 0.038, Step [972/1920], Train Loss: 0.6757, Valid Loss: 0.6806\n",
      "Epoch [11/20], LR: 0.038, Step [976/1920], Train Loss: 0.6911, Valid Loss: 0.6806\n",
      "Epoch [11/20], LR: 0.038, Step [980/1920], Train Loss: 0.7168, Valid Loss: 0.6803\n",
      "Epoch [11/20], LR: 0.038, Step [984/1920], Train Loss: 0.6747, Valid Loss: 0.6803\n",
      "Epoch [11/20], LR: 0.038, Step [988/1920], Train Loss: 0.7013, Valid Loss: 0.6803\n",
      "Epoch [11/20], LR: 0.038, Step [992/1920], Train Loss: 0.6990, Valid Loss: 0.6802\n",
      "Epoch [11/20], LR: 0.038, Step [996/1920], Train Loss: 0.6799, Valid Loss: 0.6802\n",
      "Epoch [11/20], LR: 0.038, Step [1000/1920], Train Loss: 0.6682, Valid Loss: 0.6802\n",
      "Epoch [11/20], LR: 0.038, Step [1004/1920], Train Loss: 0.6849, Valid Loss: 0.6802\n",
      "Epoch [11/20], LR: 0.038, Step [1008/1920], Train Loss: 0.7006, Valid Loss: 0.6802\n",
      "Epoch [11/20], LR: 0.038, Step [1012/1920], Train Loss: 0.7026, Valid Loss: 0.6803\n",
      "Epoch [11/20], LR: 0.038, Step [1016/1920], Train Loss: 0.6906, Valid Loss: 0.6803\n",
      "Epoch [11/20], LR: 0.038, Step [1020/1920], Train Loss: 0.6925, Valid Loss: 0.6804\n",
      "Epoch [11/20], LR: 0.038, Step [1024/1920], Train Loss: 0.7021, Valid Loss: 0.6806\n",
      "Epoch [11/20], LR: 0.038, Step [1028/1920], Train Loss: 0.7017, Valid Loss: 0.6810\n",
      "Epoch [11/20], LR: 0.038, Step [1032/1920], Train Loss: 0.6812, Valid Loss: 0.6808\n",
      "Epoch [11/20], LR: 0.038, Step [1036/1920], Train Loss: 0.6896, Valid Loss: 0.6809\n",
      "Epoch [11/20], LR: 0.038, Step [1040/1920], Train Loss: 0.6941, Valid Loss: 0.6810\n",
      "Epoch [11/20], LR: 0.038, Step [1044/1920], Train Loss: 0.6930, Valid Loss: 0.6811\n",
      "Epoch [11/20], LR: 0.038, Step [1048/1920], Train Loss: 0.6764, Valid Loss: 0.6808\n",
      "Epoch [11/20], LR: 0.038, Step [1052/1920], Train Loss: 0.6590, Valid Loss: 0.6804\n",
      "Epoch [11/20], LR: 0.038, Step [1056/1920], Train Loss: 0.6381, Valid Loss: 0.6800\n",
      "time elapsed in epoch: 2.3003828525543213\n",
      "Epoch [12/20], LR: 0.042, Step [1060/1920], Train Loss: 0.6097, Valid Loss: 0.6802\n",
      "Epoch [12/20], LR: 0.042, Step [1064/1920], Train Loss: 0.6437, Valid Loss: 0.6805\n",
      "Epoch [12/20], LR: 0.042, Step [1068/1920], Train Loss: 0.6800, Valid Loss: 0.6804\n",
      "Epoch [12/20], LR: 0.042, Step [1072/1920], Train Loss: 0.6822, Valid Loss: 0.6803\n",
      "Epoch [12/20], LR: 0.042, Step [1076/1920], Train Loss: 0.7002, Valid Loss: 0.6800\n",
      "Epoch [12/20], LR: 0.042, Step [1080/1920], Train Loss: 0.6803, Valid Loss: 0.6800\n",
      "Epoch [12/20], LR: 0.042, Step [1084/1920], Train Loss: 0.7002, Valid Loss: 0.6799\n",
      "Epoch [12/20], LR: 0.042, Step [1088/1920], Train Loss: 0.7024, Valid Loss: 0.6799\n",
      "Epoch [12/20], LR: 0.042, Step [1092/1920], Train Loss: 0.6827, Valid Loss: 0.6799\n",
      "Epoch [12/20], LR: 0.042, Step [1096/1920], Train Loss: 0.6690, Valid Loss: 0.6798\n",
      "Epoch [12/20], LR: 0.042, Step [1100/1920], Train Loss: 0.6875, Valid Loss: 0.6798\n",
      "Epoch [12/20], LR: 0.042, Step [1104/1920], Train Loss: 0.6995, Valid Loss: 0.6799\n",
      "Epoch [12/20], LR: 0.042, Step [1108/1920], Train Loss: 0.6991, Valid Loss: 0.6801\n",
      "Epoch [12/20], LR: 0.042, Step [1112/1920], Train Loss: 0.6907, Valid Loss: 0.6801\n",
      "Epoch [12/20], LR: 0.042, Step [1116/1920], Train Loss: 0.6929, Valid Loss: 0.6802\n",
      "Epoch [12/20], LR: 0.042, Step [1120/1920], Train Loss: 0.6985, Valid Loss: 0.6804\n",
      "Epoch [12/20], LR: 0.042, Step [1124/1920], Train Loss: 0.7031, Valid Loss: 0.6808\n",
      "Epoch [12/20], LR: 0.042, Step [1128/1920], Train Loss: 0.6838, Valid Loss: 0.6808\n",
      "Epoch [12/20], LR: 0.042, Step [1132/1920], Train Loss: 0.6876, Valid Loss: 0.6809\n",
      "Epoch [12/20], LR: 0.042, Step [1136/1920], Train Loss: 0.6925, Valid Loss: 0.6810\n",
      "Epoch [12/20], LR: 0.042, Step [1140/1920], Train Loss: 0.6907, Valid Loss: 0.6812\n",
      "Epoch [12/20], LR: 0.042, Step [1144/1920], Train Loss: 0.6786, Valid Loss: 0.6808\n",
      "Epoch [12/20], LR: 0.042, Step [1148/1920], Train Loss: 0.6538, Valid Loss: 0.6803\n",
      "Epoch [12/20], LR: 0.042, Step [1152/1920], Train Loss: 0.6299, Valid Loss: 0.6797\n",
      "time elapsed in epoch: 2.4426019191741943\n",
      "Epoch [13/20], LR: 0.046, Step [1156/1920], Train Loss: 0.6083, Valid Loss: 0.6800\n",
      "Epoch [13/20], LR: 0.046, Step [1160/1920], Train Loss: 0.6441, Valid Loss: 0.6804\n",
      "Epoch [13/20], LR: 0.046, Step [1164/1920], Train Loss: 0.6789, Valid Loss: 0.6803\n",
      "Epoch [13/20], LR: 0.046, Step [1168/1920], Train Loss: 0.6823, Valid Loss: 0.6802\n",
      "Epoch [13/20], LR: 0.046, Step [1172/1920], Train Loss: 0.7091, Valid Loss: 0.6798\n",
      "Epoch [13/20], LR: 0.046, Step [1176/1920], Train Loss: 0.6725, Valid Loss: 0.6797\n",
      "Epoch [13/20], LR: 0.046, Step [1180/1920], Train Loss: 0.6960, Valid Loss: 0.6796\n",
      "Epoch [13/20], LR: 0.046, Step [1184/1920], Train Loss: 0.7031, Valid Loss: 0.6796\n",
      "Epoch [13/20], LR: 0.046, Step [1188/1920], Train Loss: 0.6852, Valid Loss: 0.6796\n",
      "Epoch [13/20], LR: 0.046, Step [1192/1920], Train Loss: 0.6683, Valid Loss: 0.6795\n",
      "Epoch [13/20], LR: 0.046, Step [1196/1920], Train Loss: 0.6792, Valid Loss: 0.6795\n",
      "Epoch [13/20], LR: 0.046, Step [1200/1920], Train Loss: 0.7043, Valid Loss: 0.6796\n",
      "Epoch [13/20], LR: 0.046, Step [1204/1920], Train Loss: 0.7035, Valid Loss: 0.6798\n",
      "Epoch [13/20], LR: 0.046, Step [1208/1920], Train Loss: 0.6875, Valid Loss: 0.6798\n",
      "Epoch [13/20], LR: 0.046, Step [1212/1920], Train Loss: 0.6940, Valid Loss: 0.6799\n",
      "Epoch [13/20], LR: 0.046, Step [1216/1920], Train Loss: 0.6977, Valid Loss: 0.6801\n",
      "Epoch [13/20], LR: 0.046, Step [1220/1920], Train Loss: 0.7010, Valid Loss: 0.6805\n",
      "Epoch [13/20], LR: 0.046, Step [1224/1920], Train Loss: 0.6844, Valid Loss: 0.6803\n",
      "Epoch [13/20], LR: 0.046, Step [1228/1920], Train Loss: 0.6844, Valid Loss: 0.6803\n",
      "Epoch [13/20], LR: 0.046, Step [1232/1920], Train Loss: 0.6991, Valid Loss: 0.6806\n",
      "Epoch [13/20], LR: 0.046, Step [1236/1920], Train Loss: 0.6888, Valid Loss: 0.6806\n",
      "Epoch [13/20], LR: 0.046, Step [1240/1920], Train Loss: 0.6762, Valid Loss: 0.6803\n",
      "Epoch [13/20], LR: 0.046, Step [1244/1920], Train Loss: 0.6551, Valid Loss: 0.6798\n",
      "Epoch [13/20], LR: 0.046, Step [1248/1920], Train Loss: 0.6300, Valid Loss: 0.6794\n",
      "time elapsed in epoch: 2.936174154281616\n",
      "Epoch [14/20], LR: 0.050, Step [1252/1920], Train Loss: 0.6067, Valid Loss: 0.6799\n",
      "Epoch [14/20], LR: 0.050, Step [1256/1920], Train Loss: 0.6412, Valid Loss: 0.6804\n",
      "Epoch [14/20], LR: 0.050, Step [1260/1920], Train Loss: 0.6779, Valid Loss: 0.6804\n",
      "Epoch [14/20], LR: 0.050, Step [1264/1920], Train Loss: 0.6882, Valid Loss: 0.6801\n",
      "Epoch [14/20], LR: 0.050, Step [1268/1920], Train Loss: 0.7089, Valid Loss: 0.6796\n",
      "Epoch [14/20], LR: 0.050, Step [1272/1920], Train Loss: 0.6724, Valid Loss: 0.6795\n",
      "Epoch [14/20], LR: 0.050, Step [1276/1920], Train Loss: 0.6979, Valid Loss: 0.6794\n",
      "Epoch [14/20], LR: 0.050, Step [1280/1920], Train Loss: 0.7051, Valid Loss: 0.6793\n",
      "Epoch [14/20], LR: 0.050, Step [1284/1920], Train Loss: 0.6824, Valid Loss: 0.6793\n",
      "Epoch [14/20], LR: 0.050, Step [1288/1920], Train Loss: 0.6658, Valid Loss: 0.6793\n",
      "Epoch [14/20], LR: 0.050, Step [1292/1920], Train Loss: 0.6842, Valid Loss: 0.6793\n",
      "Epoch [14/20], LR: 0.050, Step [1296/1920], Train Loss: 0.7031, Valid Loss: 0.6793\n",
      "Epoch [14/20], LR: 0.050, Step [1300/1920], Train Loss: 0.6948, Valid Loss: 0.6795\n",
      "Epoch [14/20], LR: 0.050, Step [1304/1920], Train Loss: 0.6869, Valid Loss: 0.6795\n",
      "Epoch [14/20], LR: 0.050, Step [1308/1920], Train Loss: 0.6920, Valid Loss: 0.6795\n",
      "Epoch [14/20], LR: 0.050, Step [1312/1920], Train Loss: 0.7003, Valid Loss: 0.6798\n",
      "Epoch [14/20], LR: 0.050, Step [1316/1920], Train Loss: 0.6996, Valid Loss: 0.6803\n",
      "Epoch [14/20], LR: 0.050, Step [1320/1920], Train Loss: 0.6756, Valid Loss: 0.6799\n",
      "Epoch [14/20], LR: 0.050, Step [1324/1920], Train Loss: 0.6812, Valid Loss: 0.6799\n",
      "Epoch [14/20], LR: 0.050, Step [1328/1920], Train Loss: 0.6945, Valid Loss: 0.6803\n",
      "Epoch [14/20], LR: 0.050, Step [1332/1920], Train Loss: 0.6900, Valid Loss: 0.6803\n",
      "Epoch [14/20], LR: 0.050, Step [1336/1920], Train Loss: 0.6814, Valid Loss: 0.6800\n",
      "Epoch [14/20], LR: 0.050, Step [1340/1920], Train Loss: 0.6604, Valid Loss: 0.6795\n",
      "Epoch [14/20], LR: 0.050, Step [1344/1920], Train Loss: 0.6328, Valid Loss: 0.6791\n",
      "time elapsed in epoch: 3.123643636703491\n",
      "Epoch [15/20], LR: 0.054, Step [1348/1920], Train Loss: 0.6087, Valid Loss: 0.6797\n",
      "Epoch [15/20], LR: 0.054, Step [1352/1920], Train Loss: 0.6424, Valid Loss: 0.6802\n",
      "Epoch [15/20], LR: 0.054, Step [1356/1920], Train Loss: 0.6703, Valid Loss: 0.6800\n",
      "Epoch [15/20], LR: 0.054, Step [1360/1920], Train Loss: 0.6880, Valid Loss: 0.6797\n",
      "Epoch [15/20], LR: 0.054, Step [1364/1920], Train Loss: 0.7152, Valid Loss: 0.6791\n",
      "Epoch [15/20], LR: 0.054, Step [1368/1920], Train Loss: 0.6721, Valid Loss: 0.6791\n",
      "Epoch [15/20], LR: 0.054, Step [1372/1920], Train Loss: 0.7005, Valid Loss: 0.6790\n",
      "Epoch [15/20], LR: 0.054, Step [1376/1920], Train Loss: 0.7029, Valid Loss: 0.6790\n",
      "Epoch [15/20], LR: 0.054, Step [1380/1920], Train Loss: 0.6844, Valid Loss: 0.6790\n",
      "Epoch [15/20], LR: 0.054, Step [1384/1920], Train Loss: 0.6644, Valid Loss: 0.6789\n",
      "Epoch [15/20], LR: 0.054, Step [1388/1920], Train Loss: 0.6795, Valid Loss: 0.6789\n",
      "Epoch [15/20], LR: 0.054, Step [1392/1920], Train Loss: 0.7024, Valid Loss: 0.6790\n",
      "Epoch [15/20], LR: 0.054, Step [1396/1920], Train Loss: 0.7001, Valid Loss: 0.6792\n",
      "Epoch [15/20], LR: 0.054, Step [1400/1920], Train Loss: 0.6847, Valid Loss: 0.6792\n",
      "Epoch [15/20], LR: 0.054, Step [1404/1920], Train Loss: 0.6873, Valid Loss: 0.6794\n",
      "Epoch [15/20], LR: 0.054, Step [1408/1920], Train Loss: 0.7019, Valid Loss: 0.6797\n",
      "Epoch [15/20], LR: 0.054, Step [1412/1920], Train Loss: 0.7024, Valid Loss: 0.6803\n",
      "Epoch [15/20], LR: 0.054, Step [1416/1920], Train Loss: 0.6828, Valid Loss: 0.6799\n",
      "Epoch [15/20], LR: 0.054, Step [1420/1920], Train Loss: 0.6913, Valid Loss: 0.6800\n",
      "Epoch [15/20], LR: 0.054, Step [1424/1920], Train Loss: 0.6977, Valid Loss: 0.6803\n",
      "Epoch [15/20], LR: 0.054, Step [1428/1920], Train Loss: 0.6861, Valid Loss: 0.6806\n",
      "Epoch [15/20], LR: 0.054, Step [1432/1920], Train Loss: 0.6788, Valid Loss: 0.6803\n",
      "Epoch [15/20], LR: 0.054, Step [1436/1920], Train Loss: 0.6605, Valid Loss: 0.6795\n",
      "Epoch [15/20], LR: 0.054, Step [1440/1920], Train Loss: 0.6311, Valid Loss: 0.6789\n",
      "time elapsed in epoch: 2.688127040863037\n",
      "Epoch [16/20], LR: 0.058, Step [1444/1920], Train Loss: 0.6076, Valid Loss: 0.6793\n",
      "Epoch [16/20], LR: 0.058, Step [1448/1920], Train Loss: 0.6355, Valid Loss: 0.6798\n",
      "Epoch [16/20], LR: 0.058, Step [1452/1920], Train Loss: 0.6707, Valid Loss: 0.6797\n",
      "Epoch [16/20], LR: 0.058, Step [1456/1920], Train Loss: 0.6899, Valid Loss: 0.6795\n",
      "Epoch [16/20], LR: 0.058, Step [1460/1920], Train Loss: 0.7067, Valid Loss: 0.6788\n",
      "Epoch [16/20], LR: 0.058, Step [1464/1920], Train Loss: 0.6722, Valid Loss: 0.6788\n",
      "Epoch [16/20], LR: 0.058, Step [1468/1920], Train Loss: 0.7003, Valid Loss: 0.6786\n",
      "Epoch [16/20], LR: 0.058, Step [1472/1920], Train Loss: 0.7011, Valid Loss: 0.6786\n",
      "Epoch [16/20], LR: 0.058, Step [1476/1920], Train Loss: 0.6818, Valid Loss: 0.6786\n",
      "Epoch [16/20], LR: 0.058, Step [1480/1920], Train Loss: 0.6672, Valid Loss: 0.6785\n",
      "Epoch [16/20], LR: 0.058, Step [1484/1920], Train Loss: 0.6827, Valid Loss: 0.6785\n",
      "Epoch [16/20], LR: 0.058, Step [1488/1920], Train Loss: 0.6985, Valid Loss: 0.6786\n",
      "Epoch [16/20], LR: 0.058, Step [1492/1920], Train Loss: 0.6983, Valid Loss: 0.6787\n",
      "Epoch [16/20], LR: 0.058, Step [1496/1920], Train Loss: 0.6872, Valid Loss: 0.6788\n",
      "Epoch [16/20], LR: 0.058, Step [1500/1920], Train Loss: 0.6945, Valid Loss: 0.6789\n",
      "Epoch [16/20], LR: 0.058, Step [1504/1920], Train Loss: 0.6983, Valid Loss: 0.6792\n",
      "Epoch [16/20], LR: 0.058, Step [1508/1920], Train Loss: 0.7045, Valid Loss: 0.6798\n",
      "Epoch [16/20], LR: 0.058, Step [1512/1920], Train Loss: 0.6829, Valid Loss: 0.6795\n",
      "Epoch [16/20], LR: 0.058, Step [1516/1920], Train Loss: 0.6883, Valid Loss: 0.6797\n",
      "Epoch [16/20], LR: 0.058, Step [1520/1920], Train Loss: 0.6917, Valid Loss: 0.6800\n",
      "Epoch [16/20], LR: 0.058, Step [1524/1920], Train Loss: 0.6864, Valid Loss: 0.6801\n",
      "Epoch [16/20], LR: 0.058, Step [1528/1920], Train Loss: 0.6801, Valid Loss: 0.6796\n",
      "Epoch [16/20], LR: 0.058, Step [1532/1920], Train Loss: 0.6572, Valid Loss: 0.6788\n",
      "Epoch [16/20], LR: 0.058, Step [1536/1920], Train Loss: 0.6263, Valid Loss: 0.6783\n",
      "time elapsed in epoch: 2.7109248638153076\n",
      "Epoch [17/20], LR: 0.063, Step [1540/1920], Train Loss: 0.6111, Valid Loss: 0.6793\n",
      "Epoch [17/20], LR: 0.063, Step [1544/1920], Train Loss: 0.6351, Valid Loss: 0.6798\n",
      "Epoch [17/20], LR: 0.063, Step [1548/1920], Train Loss: 0.6792, Valid Loss: 0.6798\n",
      "Epoch [17/20], LR: 0.063, Step [1552/1920], Train Loss: 0.6911, Valid Loss: 0.6795\n",
      "Epoch [17/20], LR: 0.063, Step [1556/1920], Train Loss: 0.7069, Valid Loss: 0.6787\n",
      "Epoch [17/20], LR: 0.063, Step [1560/1920], Train Loss: 0.6705, Valid Loss: 0.6786\n",
      "Epoch [17/20], LR: 0.063, Step [1564/1920], Train Loss: 0.6988, Valid Loss: 0.6783\n",
      "Epoch [17/20], LR: 0.063, Step [1568/1920], Train Loss: 0.7015, Valid Loss: 0.6782\n",
      "Epoch [17/20], LR: 0.063, Step [1572/1920], Train Loss: 0.6854, Valid Loss: 0.6782\n",
      "Epoch [17/20], LR: 0.063, Step [1576/1920], Train Loss: 0.6663, Valid Loss: 0.6781\n",
      "Epoch [17/20], LR: 0.063, Step [1580/1920], Train Loss: 0.6869, Valid Loss: 0.6782\n",
      "Epoch [17/20], LR: 0.063, Step [1584/1920], Train Loss: 0.7048, Valid Loss: 0.6782\n",
      "Epoch [17/20], LR: 0.063, Step [1588/1920], Train Loss: 0.6917, Valid Loss: 0.6784\n",
      "Epoch [17/20], LR: 0.063, Step [1592/1920], Train Loss: 0.6919, Valid Loss: 0.6785\n",
      "Epoch [17/20], LR: 0.063, Step [1596/1920], Train Loss: 0.6924, Valid Loss: 0.6787\n",
      "Epoch [17/20], LR: 0.063, Step [1600/1920], Train Loss: 0.7031, Valid Loss: 0.6791\n",
      "Epoch [17/20], LR: 0.063, Step [1604/1920], Train Loss: 0.6996, Valid Loss: 0.6798\n",
      "Epoch [17/20], LR: 0.063, Step [1608/1920], Train Loss: 0.6808, Valid Loss: 0.6792\n",
      "Epoch [17/20], LR: 0.063, Step [1612/1920], Train Loss: 0.6916, Valid Loss: 0.6793\n",
      "Epoch [17/20], LR: 0.063, Step [1616/1920], Train Loss: 0.6890, Valid Loss: 0.6796\n",
      "Epoch [17/20], LR: 0.063, Step [1620/1920], Train Loss: 0.6966, Valid Loss: 0.6798\n",
      "Epoch [17/20], LR: 0.063, Step [1624/1920], Train Loss: 0.6840, Valid Loss: 0.6794\n",
      "Epoch [17/20], LR: 0.063, Step [1628/1920], Train Loss: 0.6563, Valid Loss: 0.6786\n",
      "Epoch [17/20], LR: 0.063, Step [1632/1920], Train Loss: 0.6264, Valid Loss: 0.6782\n",
      "time elapsed in epoch: 2.522477865219116\n",
      "Epoch [18/20], LR: 0.067, Step [1636/1920], Train Loss: 0.5988, Valid Loss: 0.6796\n",
      "Epoch [18/20], LR: 0.067, Step [1640/1920], Train Loss: 0.6346, Valid Loss: 0.6805\n",
      "Epoch [18/20], LR: 0.067, Step [1644/1920], Train Loss: 0.6707, Valid Loss: 0.6800\n",
      "Epoch [18/20], LR: 0.067, Step [1648/1920], Train Loss: 0.6869, Valid Loss: 0.6794\n",
      "Epoch [18/20], LR: 0.067, Step [1652/1920], Train Loss: 0.7139, Valid Loss: 0.6784\n",
      "Epoch [18/20], LR: 0.067, Step [1656/1920], Train Loss: 0.6739, Valid Loss: 0.6783\n",
      "Epoch [18/20], LR: 0.067, Step [1660/1920], Train Loss: 0.6926, Valid Loss: 0.6780\n",
      "Epoch [18/20], LR: 0.067, Step [1664/1920], Train Loss: 0.6967, Valid Loss: 0.6779\n",
      "Epoch [18/20], LR: 0.067, Step [1668/1920], Train Loss: 0.6847, Valid Loss: 0.6779\n",
      "Epoch [18/20], LR: 0.067, Step [1672/1920], Train Loss: 0.6597, Valid Loss: 0.6778\n",
      "Epoch [18/20], LR: 0.067, Step [1676/1920], Train Loss: 0.6783, Valid Loss: 0.6778\n",
      "Epoch [18/20], LR: 0.067, Step [1680/1920], Train Loss: 0.6991, Valid Loss: 0.6778\n",
      "Epoch [18/20], LR: 0.067, Step [1684/1920], Train Loss: 0.7102, Valid Loss: 0.6781\n",
      "Epoch [18/20], LR: 0.067, Step [1688/1920], Train Loss: 0.6860, Valid Loss: 0.6782\n",
      "Epoch [18/20], LR: 0.067, Step [1692/1920], Train Loss: 0.6866, Valid Loss: 0.6782\n",
      "Epoch [18/20], LR: 0.067, Step [1696/1920], Train Loss: 0.7026, Valid Loss: 0.6786\n",
      "Epoch [18/20], LR: 0.067, Step [1700/1920], Train Loss: 0.6954, Valid Loss: 0.6794\n",
      "Epoch [18/20], LR: 0.067, Step [1704/1920], Train Loss: 0.6868, Valid Loss: 0.6791\n",
      "Epoch [18/20], LR: 0.067, Step [1708/1920], Train Loss: 0.6892, Valid Loss: 0.6789\n",
      "Epoch [18/20], LR: 0.067, Step [1712/1920], Train Loss: 0.6976, Valid Loss: 0.6793\n",
      "Epoch [18/20], LR: 0.067, Step [1716/1920], Train Loss: 0.6841, Valid Loss: 0.6794\n",
      "Epoch [18/20], LR: 0.067, Step [1720/1920], Train Loss: 0.6725, Valid Loss: 0.6789\n",
      "Epoch [18/20], LR: 0.067, Step [1724/1920], Train Loss: 0.6512, Valid Loss: 0.6780\n",
      "Epoch [18/20], LR: 0.067, Step [1728/1920], Train Loss: 0.6352, Valid Loss: 0.6777\n",
      "time elapsed in epoch: 2.811800241470337\n",
      "Epoch [19/20], LR: 0.071, Step [1732/1920], Train Loss: 0.5992, Valid Loss: 0.6789\n",
      "Epoch [19/20], LR: 0.071, Step [1736/1920], Train Loss: 0.6401, Valid Loss: 0.6799\n",
      "Epoch [19/20], LR: 0.071, Step [1740/1920], Train Loss: 0.6733, Valid Loss: 0.6794\n",
      "Epoch [19/20], LR: 0.071, Step [1744/1920], Train Loss: 0.6843, Valid Loss: 0.6789\n",
      "Epoch [19/20], LR: 0.071, Step [1748/1920], Train Loss: 0.7056, Valid Loss: 0.6778\n",
      "Epoch [19/20], LR: 0.071, Step [1752/1920], Train Loss: 0.6753, Valid Loss: 0.6779\n",
      "Epoch [19/20], LR: 0.071, Step [1756/1920], Train Loss: 0.6983, Valid Loss: 0.6774\n",
      "Epoch [19/20], LR: 0.071, Step [1760/1920], Train Loss: 0.6944, Valid Loss: 0.6773\n",
      "Epoch [19/20], LR: 0.071, Step [1764/1920], Train Loss: 0.6840, Valid Loss: 0.6774\n",
      "Epoch [19/20], LR: 0.071, Step [1768/1920], Train Loss: 0.6608, Valid Loss: 0.6772\n",
      "Epoch [19/20], LR: 0.071, Step [1772/1920], Train Loss: 0.6756, Valid Loss: 0.6772\n",
      "Epoch [19/20], LR: 0.071, Step [1776/1920], Train Loss: 0.7066, Valid Loss: 0.6773\n",
      "Epoch [19/20], LR: 0.071, Step [1780/1920], Train Loss: 0.6973, Valid Loss: 0.6777\n",
      "Epoch [19/20], LR: 0.071, Step [1784/1920], Train Loss: 0.6864, Valid Loss: 0.6777\n",
      "Epoch [19/20], LR: 0.071, Step [1788/1920], Train Loss: 0.6852, Valid Loss: 0.6778\n",
      "Epoch [19/20], LR: 0.071, Step [1792/1920], Train Loss: 0.6927, Valid Loss: 0.6782\n",
      "Epoch [19/20], LR: 0.071, Step [1796/1920], Train Loss: 0.7035, Valid Loss: 0.6791\n",
      "Epoch [19/20], LR: 0.071, Step [1800/1920], Train Loss: 0.6816, Valid Loss: 0.6784\n",
      "Epoch [19/20], LR: 0.071, Step [1804/1920], Train Loss: 0.6886, Valid Loss: 0.6784\n",
      "Epoch [19/20], LR: 0.071, Step [1808/1920], Train Loss: 0.6891, Valid Loss: 0.6787\n",
      "Epoch [19/20], LR: 0.071, Step [1812/1920], Train Loss: 0.6858, Valid Loss: 0.6790\n",
      "Epoch [19/20], LR: 0.071, Step [1816/1920], Train Loss: 0.6849, Valid Loss: 0.6780\n",
      "Epoch [19/20], LR: 0.071, Step [1820/1920], Train Loss: 0.6602, Valid Loss: 0.6774\n",
      "Epoch [19/20], LR: 0.071, Step [1824/1920], Train Loss: 0.6260, Valid Loss: 0.6773\n",
      "time elapsed in epoch: 3.017887830734253\n",
      "Epoch [20/20], LR: 0.075, Step [1828/1920], Train Loss: 0.6029, Valid Loss: 0.6791\n",
      "Epoch [20/20], LR: 0.075, Step [1832/1920], Train Loss: 0.6419, Valid Loss: 0.6798\n",
      "Epoch [20/20], LR: 0.075, Step [1836/1920], Train Loss: 0.6762, Valid Loss: 0.6792\n",
      "Epoch [20/20], LR: 0.075, Step [1840/1920], Train Loss: 0.6888, Valid Loss: 0.6787\n",
      "Epoch [20/20], LR: 0.075, Step [1844/1920], Train Loss: 0.7114, Valid Loss: 0.6776\n",
      "Epoch [20/20], LR: 0.075, Step [1848/1920], Train Loss: 0.6643, Valid Loss: 0.6773\n",
      "Epoch [20/20], LR: 0.075, Step [1852/1920], Train Loss: 0.6959, Valid Loss: 0.6770\n",
      "Epoch [20/20], LR: 0.075, Step [1856/1920], Train Loss: 0.7040, Valid Loss: 0.6771\n",
      "Epoch [20/20], LR: 0.075, Step [1860/1920], Train Loss: 0.6809, Valid Loss: 0.6770\n",
      "Epoch [20/20], LR: 0.075, Step [1864/1920], Train Loss: 0.6642, Valid Loss: 0.6770\n",
      "Epoch [20/20], LR: 0.075, Step [1868/1920], Train Loss: 0.6771, Valid Loss: 0.6769\n",
      "Epoch [20/20], LR: 0.075, Step [1872/1920], Train Loss: 0.6960, Valid Loss: 0.6771\n",
      "Epoch [20/20], LR: 0.075, Step [1876/1920], Train Loss: 0.7011, Valid Loss: 0.6774\n",
      "Epoch [20/20], LR: 0.075, Step [1880/1920], Train Loss: 0.6859, Valid Loss: 0.6774\n",
      "Epoch [20/20], LR: 0.075, Step [1884/1920], Train Loss: 0.6958, Valid Loss: 0.6776\n",
      "Epoch [20/20], LR: 0.075, Step [1888/1920], Train Loss: 0.6993, Valid Loss: 0.6779\n",
      "Epoch [20/20], LR: 0.075, Step [1892/1920], Train Loss: 0.6993, Valid Loss: 0.6789\n",
      "Epoch [20/20], LR: 0.075, Step [1896/1920], Train Loss: 0.6772, Valid Loss: 0.6782\n",
      "Epoch [20/20], LR: 0.075, Step [1900/1920], Train Loss: 0.6845, Valid Loss: 0.6785\n",
      "Epoch [20/20], LR: 0.075, Step [1904/1920], Train Loss: 0.6945, Valid Loss: 0.6787\n",
      "Epoch [20/20], LR: 0.075, Step [1908/1920], Train Loss: 0.6849, Valid Loss: 0.6788\n",
      "Epoch [20/20], LR: 0.075, Step [1912/1920], Train Loss: 0.6764, Valid Loss: 0.6782\n",
      "Epoch [20/20], LR: 0.075, Step [1916/1920], Train Loss: 0.6634, Valid Loss: 0.6771\n",
      "Epoch [20/20], LR: 0.075, Step [1920/1920], Train Loss: 0.6284, Valid Loss: 0.6767\n",
      "time elapsed in epoch: 2.7187602519989014\n",
      "Finished Training!\n",
      "The following commands were written to file `.flor/run.ipy`:\n",
      "!python train_rnn.py --flor runID\n"
     ]
    }
   ],
   "source": [
    "!python train_rnn.py --flor runID\n",
    "%save -rf .flor/run.ipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle-nlp-dist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "815c30a49f552e6fdb87f74e117ecdf18b0ca5a01ddc5c83796985c2fbc2bb40"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
